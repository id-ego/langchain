---
description: Couchbase는 클라우드, 모바일, AI 및 엣지 컴퓨팅 애플리케이션을 위한 분산 NoSQL 데이터베이스로, 성능과 확장성을
  제공합니다.
---

# Couchbase

> [Couchbase](http://couchbase.com/)는 모든 클라우드, 모바일, AI 및 엣지 컴퓨팅 애플리케이션에 대해 비할 데 없는 다재다능성, 성능, 확장성 및 재정적 가치를 제공하는 수상 경력에 빛나는 분산 NoSQL 클라우드 데이터베이스입니다.

## 설치 및 설정

`langchain-couchbase` 패키지를 설치해야 합니다.

```bash
pip install langchain-couchbase
```


## 벡터 저장소

[사용 예시](/docs/integrations/vectorstores/couchbase)를 참조하세요.

```python
from langchain_couchbase import CouchbaseVectorStore
```


## 문서 로더

[사용 예시](/docs/integrations/document_loaders/couchbase)를 참조하세요.

```python
<!--IMPORTS:[{"imported": "CouchbaseLoader", "source": "langchain_community.document_loaders.couchbase", "docs": "https://api.python.langchain.com/en/latest/document_loaders/langchain_community.document_loaders.couchbase.CouchbaseLoader.html", "title": "Couchbase"}]-->
from langchain_community.document_loaders.couchbase import CouchbaseLoader
```


## LLM 캐시

### CouchbaseCache
프롬프트와 응답을 위한 캐시로 Couchbase를 사용하세요.

[사용 예시](/docs/integrations/llm_caching/#couchbase-cache)를 참조하세요.

이 캐시를 가져오려면:
```python
from langchain_couchbase.cache import CouchbaseCache
```


LLM와 함께 이 캐시를 사용하려면:
```python
<!--IMPORTS:[{"imported": "set_llm_cache", "source": "langchain_core.globals", "docs": "https://api.python.langchain.com/en/latest/globals/langchain_core.globals.set_llm_cache.html", "title": "Couchbase"}]-->
from langchain_core.globals import set_llm_cache

cluster = couchbase_cluster_connection_object

set_llm_cache(
    CouchbaseCache(
        cluster=cluster,
        bucket_name=BUCKET_NAME,
        scope_name=SCOPE_NAME,
        collection_name=COLLECTION_NAME,
    )
)
```


### CouchbaseSemanticCache
시맨틱 캐싱은 사용자가 입력한 내용과 이전에 캐시된 입력 간의 의미적 유사성에 따라 캐시된 프롬프트를 검색할 수 있도록 합니다. 내부적으로 Couchbase를 캐시와 벡터 저장소로 모두 사용합니다. CouchbaseSemanticCache는 작동하기 위해 정의된 검색 인덱스가 필요합니다. 인덱스를 설정하는 방법에 대한 [사용 예시](/docs/integrations/vectorstores/couchbase)를 참조하세요.

[사용 예시](/docs/integrations/llm_caching/#couchbase-semantic-cache)를 참조하세요.

이 캐시를 가져오려면:
```python
from langchain_couchbase.cache import CouchbaseSemanticCache
```


LLM와 함께 이 캐시를 사용하려면:
```python
<!--IMPORTS:[{"imported": "set_llm_cache", "source": "langchain_core.globals", "docs": "https://api.python.langchain.com/en/latest/globals/langchain_core.globals.set_llm_cache.html", "title": "Couchbase"}]-->
from langchain_core.globals import set_llm_cache

# use any embedding provider...
from langchain_openai.Embeddings import OpenAIEmbeddings

embeddings = OpenAIEmbeddings()
cluster = couchbase_cluster_connection_object

set_llm_cache(
    CouchbaseSemanticCache(
        cluster=cluster,
        embedding = embeddings,
        bucket_name=BUCKET_NAME,
        scope_name=SCOPE_NAME,
        collection_name=COLLECTION_NAME,
        index_name=INDEX_NAME,
    )
)
```


## 채팅 메시지 기록
Couchbase를 채팅 메시지 저장소로 사용하세요.

[사용 예시](/docs/integrations/memory/couchbase_chat_message_history)를 참조하세요.

애플리케이션에서 채팅 메시지 기록을 사용하려면:
```python
from langchain_couchbase.chat_message_histories import CouchbaseChatMessageHistory

message_history = CouchbaseChatMessageHistory(
    cluster=cluster,
    bucket_name=BUCKET_NAME,
    scope_name=SCOPE_NAME,
    collection_name=COLLECTION_NAME,
    session_id="test-session",
)

message_history.add_user_message("hi!")
```