---
custom_edit_url: https://github.com/langchain-ai/langchain/edit/master/docs/docs/integrations/llms/ai21.ipynb
description: 이 문서는 LangChain을 사용하여 AI21 Jurassic 모델과 상호작용하는 방법과 AI21의 맥락 기반 답변 모델을
  설명합니다.
sidebar_label: AI21 Labs
---

# AI21LLM

이 예제는 LangChain을 사용하여 `AI21` 쥐라기 모델과 상호작용하는 방법을 설명합니다. Jamba 모델을 사용하려면 [ChatAI21 객체](https://python.langchain.com/v0.2/docs/integrations/chat/ai21/)를 대신 사용하세요.

[LangChain에서 AI21 모델 및 도구의 전체 목록을 확인하세요.](https://pypi.org/project/langchain-ai21/)

## 설치

```python
!pip install -qU langchain-ai21
```


## 환경 설정

[AI21 API 키](https://docs.ai21.com/)를 받아야 하며, `AI21_API_KEY` 환경 변수를 설정해야 합니다:

```python
import os
from getpass import getpass

os.environ["AI21_API_KEY"] = getpass()
```


## 사용법

```python
<!--IMPORTS:[{"imported": "AI21LLM", "source": "langchain_ai21", "docs": "https://api.python.langchain.com/en/latest/llms/langchain_ai21.llms.AI21LLM.html", "title": "AI21LLM"}, {"imported": "PromptTemplate", "source": "langchain_core.prompts", "docs": "https://api.python.langchain.com/en/latest/prompts/langchain_core.prompts.prompt.PromptTemplate.html", "title": "AI21LLM"}]-->
from langchain_ai21 import AI21LLM
from langchain_core.prompts import PromptTemplate

template = """Question: {question}

Answer: Let's think step by step."""

prompt = PromptTemplate.from_template(template)

model = AI21LLM(model="j2-ultra")

chain = prompt | model

chain.invoke({"question": "What is LangChain?"})
```


```output
'\nLangChain is a (database)\nLangChain is a database for storing and processing documents'
```


# AI21 맥락적 답변

AI21의 맥락적 답변 모델을 사용하여 텍스트나 문서를 맥락으로 받고, 질문을 제시하면 이 맥락에 전적으로 기반하여 답변을 반환합니다.

이는 질문에 대한 답변이 문서에 없을 경우, 모델이 이를 나타낸다는 것을 의미합니다 (잘못된 답변을 제공하는 대신).

```python
<!--IMPORTS:[{"imported": "AI21ContextualAnswers", "source": "langchain_ai21", "docs": "https://api.python.langchain.com/en/latest/contextual_answers/langchain_ai21.contextual_answers.AI21ContextualAnswers.html", "title": "AI21LLM"}]-->
from langchain_ai21 import AI21ContextualAnswers

tsm = AI21ContextualAnswers()

response = tsm.invoke(input={"context": "Your context", "question": "Your question"})
```


체인 및 출력 파서, 벡터 DB와 함께 사용할 수도 있습니다.

```python
<!--IMPORTS:[{"imported": "AI21ContextualAnswers", "source": "langchain_ai21", "docs": "https://api.python.langchain.com/en/latest/contextual_answers/langchain_ai21.contextual_answers.AI21ContextualAnswers.html", "title": "AI21LLM"}, {"imported": "StrOutputParser", "source": "langchain_core.output_parsers", "docs": "https://api.python.langchain.com/en/latest/output_parsers/langchain_core.output_parsers.string.StrOutputParser.html", "title": "AI21LLM"}]-->
from langchain_ai21 import AI21ContextualAnswers
from langchain_core.output_parsers import StrOutputParser

tsm = AI21ContextualAnswers()
chain = tsm | StrOutputParser()

response = chain.invoke(
    {"context": "Your context", "question": "Your question"},
)
```


## 관련

- LLM [개념 가이드](/docs/concepts/#llms)
- LLM [사용 방법 가이드](/docs/how_to/#llms)