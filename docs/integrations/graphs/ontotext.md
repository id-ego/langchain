---
custom_edit_url: https://github.com/langchain-ai/langchain/edit/master/docs/docs/integrations/graphs/ontotext.ipynb
description: Ontotext GraphDBëŠ” RDF ë° SPARQLì„ ì§€ì›í•˜ëŠ” ê·¸ë˜í”„ ë°ì´í„°ë² ì´ìŠ¤ë¡œ, ìì—°ì–´ ì¿¼ë¦¬ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
---

# Ontotext GraphDB

> [Ontotext GraphDB](https://graphdb.ontotext.com/)ëŠ” [RDF](https://www.w3.org/RDF/) ë° [SPARQL](https://www.w3.org/TR/sparql11-query/)ì„ ì¤€ìˆ˜í•˜ëŠ” ê·¸ë˜í”„ ë°ì´í„°ë² ì´ìŠ¤ ë° ì§€ì‹ ë°œê²¬ ë„êµ¬ì…ë‹ˆë‹¤.

> ì´ ë…¸íŠ¸ë¶ì€ `Ontotext GraphDB`ì— ëŒ€í•œ ìì—°ì–´ ì¿¼ë¦¬(NLQì—ì„œ SPARQLë¡œ, `text2sparql`ì´ë¼ê³ ë„ í•¨)ë¥¼ ì œê³µí•˜ê¸° ìœ„í•´ LLMì„ ì‚¬ìš©í•˜ëŠ” ë°©ë²•ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

## GraphDB LLM ê¸°ëŠ¥

`GraphDB`ëŠ” [ì—¬ê¸°](https://github.com/w3c/sparql-dev/issues/193)ì—ì„œ ì„¤ëª…ëœ ì¼ë¶€ LLM í†µí•© ê¸°ëŠ¥ì„ ì§€ì›í•©ë‹ˆë‹¤:

[gpt-queries](https://graphdb.ontotext.com/documentation/10.5/gpt-queries.html)

* ì§€ì‹ ê·¸ë˜í”„(KG)ì˜ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ LLMì— í…ìŠ¤íŠ¸, ëª©ë¡ ë˜ëŠ” í…Œì´ë¸”ì„ ìš”ì²­í•˜ëŠ” ë§¤ì§ í”„ë ˆë””ì¼€ì´íŠ¸
* ì¿¼ë¦¬ ì„¤ëª…
* ê²°ê³¼ ì„¤ëª…, ìš”ì•½, ì¬êµ¬ì„±, ë²ˆì—­

[retrieval-graphdb-connector](https://graphdb.ontotext.com/documentation/10.5/retrieval-graphdb-connector.html)

* ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ KG ì—”í‹°í‹° ì¸ë±ì‹±
* ëª¨ë“  í…ìŠ¤íŠ¸ ì„ë² ë”© ì•Œê³ ë¦¬ì¦˜ ë° ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì§€ì›
* GraphDBê°€ Elastic, Solr, Luceneì— ëŒ€í•´ ì‚¬ìš©í•˜ëŠ” ë™ì¼í•œ ê°•ë ¥í•œ ì»¤ë„¥í„°(ì¸ë±ì‹±) ì–¸ì–´ ì‚¬ìš©
* RDF ë°ì´í„°ì˜ ë³€ê²½ ì‚¬í•­ì„ KG ì—”í‹°í‹° ì¸ë±ìŠ¤ì— ìë™ìœ¼ë¡œ ë™ê¸°í™”
* ì¤‘ì²© ê°ì²´ ì§€ì›(GraphDB ë²„ì „ 10.5ì—ì„œëŠ” UI ì§€ì› ì—†ìŒ)
* KG ì—”í‹°í‹°ë¥¼ ë‹¤ìŒê³¼ ê°™ì´ í…ìŠ¤íŠ¸ë¡œ ì§ë ¬í™”(ì˜ˆ: Wines ë°ì´í„°ì…‹):

```
Franvino:
- is a RedWine.
- made from grape Merlo.
- made from grape Cabernet Franc.
- has sugar dry.
- has year 2012.
```


[talk-to-graph](https://graphdb.ontotext.com/documentation/10.5/talk-to-graph.html)

* ì •ì˜ëœ KG ì—”í‹°í‹° ì¸ë±ìŠ¤ë¥¼ ì‚¬ìš©í•˜ëŠ” ê°„ë‹¨í•œ ì±—ë´‡

ì´ íŠœí† ë¦¬ì–¼ì—ì„œëŠ” GraphDB LLM í†µí•©ì„ ì‚¬ìš©í•˜ì§€ ì•Šê³  NLQì—ì„œ SPARQL ìƒì„±ì„ ì‚¬ìš©í•  ê²ƒì…ë‹ˆë‹¤. `Star Wars API`(`SWAPI`) ì˜¨í†¨ë¡œì§€ ë° ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•  ê²ƒì´ë©°, ì´ëŠ” [ì—¬ê¸°](https://github.com/Ontotext-AD/langchain-graphdb-qa-chain-demo/blob/main/starwars-data.trig)ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## ì„¤ì •

ì‹¤í–‰ ì¤‘ì¸ GraphDB ì¸ìŠ¤í„´ìŠ¤ê°€ í•„ìš”í•©ë‹ˆë‹¤. ì´ íŠœí† ë¦¬ì–¼ì€ [GraphDB Docker ì´ë¯¸ì§€](https://hub.docker.com/r/ontotext/graphdb)ë¥¼ ì‚¬ìš©í•˜ì—¬ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ë¡œì»¬ì—ì„œ ì‹¤í–‰í•˜ëŠ” ë°©ë²•ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. Star Wars ë°ì´í„°ì…‹ìœ¼ë¡œ GraphDBë¥¼ ì±„ìš°ëŠ” ë„ì»¤ ì»´í¬ì¦ˆ ì„¤ì •ì„ ì œê³µí•©ë‹ˆë‹¤. ì´ ë…¸íŠ¸ë¶ì„ í¬í•¨í•œ ëª¨ë“  í•„ìš”í•œ íŒŒì¼ì€ [GitHub ë¦¬í¬ì§€í† ë¦¬ langchain-graphdb-qa-chain-demo](https://github.com/Ontotext-AD/langchain-graphdb-qa-chain-demo)ì—ì„œ ë‹¤ìš´ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

* [Docker](https://docs.docker.com/get-docker/)ë¥¼ ì„¤ì¹˜í•©ë‹ˆë‹¤. ì´ íŠœí† ë¦¬ì–¼ì€ [Docker Compose](https://docs.docker.com/compose/)ë¥¼ í¬í•¨í•˜ëŠ” Docker ë²„ì „ `24.0.7`ì„ ì‚¬ìš©í•˜ì—¬ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ì „ Docker ë²„ì „ì—ì„œëŠ” Docker Composeë¥¼ ë³„ë„ë¡œ ì„¤ì¹˜í•´ì•¼ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
* ë¡œì»¬ ì»´í“¨í„°ì˜ í´ë”ì— [GitHub ë¦¬í¬ì§€í† ë¦¬ langchain-graphdb-qa-chain-demo](https://github.com/Ontotext-AD/langchain-graphdb-qa-chain-demo)ë¥¼ í´ë¡ í•©ë‹ˆë‹¤.
* ë‹¤ìŒ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ë™ì¼í•œ í´ë”ì—ì„œ ì‹¤í–‰í•˜ì—¬ GraphDBë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.

```
docker build --tag graphdb .
docker compose up -d graphdb
```


ë°ì´í„°ë² ì´ìŠ¤ê°€ `http://localhost:7200/`ì—ì„œ ì‹œì‘ë  ë•Œê¹Œì§€ ëª‡ ì´ˆ ê¸°ë‹¤ë ¤ì•¼ í•©ë‹ˆë‹¤. Star Wars ë°ì´í„°ì…‹ `starwars-data.trig`ëŠ” ìë™ìœ¼ë¡œ `langchain` ë¦¬í¬ì§€í† ë¦¬ì— ë¡œë“œë©ë‹ˆë‹¤. ë¡œì»¬ SPARQL ì—”ë“œí¬ì¸íŠ¸ `http://localhost:7200/repositories/langchain`ë¥¼ ì‚¬ìš©í•˜ì—¬ ì¿¼ë¦¬ë¥¼ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ ì¢‹ì•„í•˜ëŠ” ì›¹ ë¸Œë¼ìš°ì €ì—ì„œ GraphDB ì›Œí¬ë²¤ì¹˜ë¥¼ ì—´ ìˆ˜ ìˆìŠµë‹ˆë‹¤ `http://localhost:7200/sparql`ì—ì„œ ëŒ€í™”í˜•ìœ¼ë¡œ ì¿¼ë¦¬ë¥¼ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
* ì‘ì—… í™˜ê²½ ì„¤ì •

`conda`ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²½ìš° ìƒˆ conda í™˜ê²½ì„ ìƒì„±í•˜ê³  í™œì„±í™”í•©ë‹ˆë‹¤(ì˜ˆ: `conda create -n graph_ontotext_graphdb_qa python=3.9.18`).

ë‹¤ìŒ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•©ë‹ˆë‹¤:

```
pip install jupyter==1.0.0
pip install openai==1.6.1
pip install rdflib==7.0.0
pip install langchain-openai==0.0.2
pip install langchain>=0.1.5
```


Jupyterë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤:
```
jupyter notebook
```


## ì˜¨í†¨ë¡œì§€ ì§€ì •

LLMì´ SPARQLì„ ìƒì„±í•  ìˆ˜ ìˆë„ë¡ í•˜ë ¤ë©´ ì§€ì‹ ê·¸ë˜í”„ ìŠ¤í‚¤ë§ˆ(ì˜¨í†¨ë¡œì§€)ë¥¼ ì•Œì•„ì•¼ í•©ë‹ˆë‹¤. ì´ëŠ” `OntotextGraphDBGraph` í´ë˜ìŠ¤ì˜ ë‘ ê°œì˜ ë§¤ê°œë³€ìˆ˜ ì¤‘ í•˜ë‚˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ì œê³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

* `query_ontology`: SPARQL ì—”ë“œí¬ì¸íŠ¸ì—ì„œ ì‹¤í–‰ë˜ê³  KG ìŠ¤í‚¤ë§ˆ ë¬¸ì„ ë°˜í™˜í•˜ëŠ” `CONSTRUCT` ì¿¼ë¦¬ì…ë‹ˆë‹¤. ì˜¨í†¨ë¡œì§€ë¥¼ ìì²´ ì´ë¦„ì´ ìˆëŠ” ê·¸ë˜í”„ì— ì €ì¥í•˜ëŠ” ê²ƒì´ ì¢‹ìœ¼ë©°, ì´ëŠ” ê´€ë ¨ ë¬¸ë§Œ ì‰½ê²Œ ê°€ì ¸ì˜¤ëŠ” ë° ë„ì›€ì´ ë©ë‹ˆë‹¤(ì•„ë˜ ì˜ˆì™€ ê°™ì´). `DESCRIBE` ì¿¼ë¦¬ëŠ” ì§€ì›ë˜ì§€ ì•Šìœ¼ë©°, `DESCRIBE`ëŠ” ëŒ€ì¹­ ê°„ê²° ì œí•œ ì„¤ëª…(SCBD)ì„ ë°˜í™˜í•˜ë¯€ë¡œ, ì¦‰ ë“¤ì–´ì˜¤ëŠ” í´ë˜ìŠ¤ ë§í¬ë„ í¬í•¨ë©ë‹ˆë‹¤. ë°±ë§Œ ê°œì˜ ì¸ìŠ¤í„´ìŠ¤ê°€ ìˆëŠ” ëŒ€ê·œëª¨ ê·¸ë˜í”„ì˜ ê²½ìš° ë¹„íš¨ìœ¨ì ì…ë‹ˆë‹¤. https://github.com/eclipse-rdf4j/rdf4j/issues/4857ë¥¼ í™•ì¸í•˜ì„¸ìš”.
* `local_file`: ë¡œì»¬ RDF ì˜¨í†¨ë¡œì§€ íŒŒì¼ì…ë‹ˆë‹¤. ì§€ì›ë˜ëŠ” RDF í˜•ì‹ì€ `Turtle`, `RDF/XML`, `JSON-LD`, `N-Triples`, `Notation-3`, `Trig`, `Trix`, `N-Quads`ì…ë‹ˆë‹¤.

ì–´ëŠ ìª½ì´ë“  ì˜¨í†¨ë¡œì§€ ë¤í”„ëŠ” ë‹¤ìŒì„ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤:

* í´ë˜ìŠ¤, ì†ì„±, í´ë˜ìŠ¤ì— ëŒ€í•œ ì†ì„± ì²¨ë¶€(ì‚¬ìš©: rdfs:domain, schema:domainIncludes ë˜ëŠ” OWL ì œí•œ) ë° ë¶„ë¥˜(ì¤‘ìš”í•œ ê°œì¸)ì— ëŒ€í•œ ì¶©ë¶„í•œ ì •ë³´ë¥¼ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.
* SPARQL êµ¬ì„±ì„ ë„ì™€ì£¼ì§€ ì•ŠëŠ” ì§€ë‚˜ì¹˜ê²Œ ì¥í™©í•˜ê³  ê´€ë ¨ ì—†ëŠ” ì •ì˜ ë° ì˜ˆì œë¥¼ í¬í•¨í•˜ì§€ ì•Šì•„ì•¼ í•©ë‹ˆë‹¤.

```python
<!--IMPORTS:[{"imported": "OntotextGraphDBGraph", "source": "langchain_community.graphs", "docs": "https://api.python.langchain.com/en/latest/graphs/langchain_community.graphs.ontotext_graphdb_graph.OntotextGraphDBGraph.html", "title": "Ontotext GraphDB"}]-->
from langchain_community.graphs import OntotextGraphDBGraph

# feeding the schema using a user construct query

graph = OntotextGraphDBGraph(
    query_endpoint="http://localhost:7200/repositories/langchain",
    query_ontology="CONSTRUCT {?s ?p ?o} FROM <https://swapi.co/ontology/> WHERE {?s ?p ?o}",
)
```


```python
# feeding the schema using a local RDF file

graph = OntotextGraphDBGraph(
    query_endpoint="http://localhost:7200/repositories/langchain",
    local_file="/path/to/langchain_graphdb_tutorial/starwars-ontology.nt",  # change the path here
)
```


ì–´ëŠ ìª½ì´ë“  ì˜¨í†¨ë¡œì§€(ìŠ¤í‚¤ë§ˆ)ëŠ” `Turtle`ë¡œ LLMì— ì œê³µë©ë‹ˆë‹¤. ì ì ˆí•œ ì ‘ë‘ì‚¬ê°€ ìˆëŠ” `Turtle`ì´ ê°€ì¥ ê°„ê²°í•˜ê³  LLMì´ ê¸°ì–µí•˜ê¸° ì‰½ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.

Star Wars ì˜¨í†¨ë¡œì§€ëŠ” í´ë˜ìŠ¤ì— ëŒ€í•œ ë§ì€ íŠ¹ì • íŠ¸ë¦¬í”Œì„ í¬í•¨í•˜ê³  ìˆì–´ ë‹¤ì†Œ íŠ¹ì´í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´ ì¢… `:Aleena`ê°€ `<planet/38>`ì— ì‚´ê³  ìˆìœ¼ë©°, `:Reptile`ì˜ í•˜ìœ„ í´ë˜ìŠ¤ì´ê³  íŠ¹ì • ì „í˜•ì ì¸ íŠ¹ì„±(í‰ê·  í‚¤, í‰ê·  ìˆ˜ëª…, í”¼ë¶€ìƒ‰)ì„ ê°€ì§€ë©° íŠ¹ì • ê°œì¸(ìºë¦­í„°)ì´ í•´ë‹¹ í´ë˜ìŠ¤ì˜ ëŒ€í‘œìì…ë‹ˆë‹¤:

```
@prefix : <https://swapi.co/vocabulary/> .
@prefix owl: <http://www.w3.org/2002/07/owl#> .
@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .
@prefix xsd: <http://www.w3.org/2001/XMLSchema#> .

:Aleena a owl:Class, :Species ;
    rdfs:label "Aleena" ;
    rdfs:isDefinedBy <https://swapi.co/ontology/> ;
    rdfs:subClassOf :Reptile, :Sentient ;
    :averageHeight 80.0 ;
    :averageLifespan "79" ;
    :character <https://swapi.co/resource/aleena/47> ;
    :film <https://swapi.co/resource/film/4> ;
    :language "Aleena" ;
    :planet <https://swapi.co/resource/planet/38> ;
    :skinColor "blue", "gray" .

    ...

```


ì´ íŠœí† ë¦¬ì–¼ì„ ê°„ë‹¨í•˜ê²Œ ìœ ì§€í•˜ê¸° ìœ„í•´ ë³´ì•ˆì´ ì„¤ì •ë˜ì§€ ì•Šì€ GraphDBë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. GraphDBê°€ ë³´ì•ˆì´ ì„¤ì •ëœ ê²½ìš° `OntotextGraphDBGraph` ì´ˆê¸°í™” ì „ì— í™˜ê²½ ë³€ìˆ˜ 'GRAPHDB_USERNAME' ë° 'GRAPHDB_PASSWORD'ë¥¼ ì„¤ì •í•´ì•¼ í•©ë‹ˆë‹¤.

```python
os.environ["GRAPHDB_USERNAME"] = "graphdb-user"
os.environ["GRAPHDB_PASSWORD"] = "graphdb-password"

graph = OntotextGraphDBGraph(
    query_endpoint=...,
    query_ontology=...
)
```


## StarWars ë°ì´í„°ì…‹ì— ëŒ€í•œ ì§ˆë¬¸ ì‘ë‹µ

ì´ì œ `OntotextGraphDBQAChain`ì„ ì‚¬ìš©í•˜ì—¬ ëª‡ ê°€ì§€ ì§ˆë¬¸ì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```python
<!--IMPORTS:[{"imported": "OntotextGraphDBQAChain", "source": "langchain.chains", "docs": "https://api.python.langchain.com/en/latest/chains/langchain_community.chains.graph_qa.ontotext_graphdb.OntotextGraphDBQAChain.html", "title": "Ontotext GraphDB"}, {"imported": "ChatOpenAI", "source": "langchain_openai", "docs": "https://api.python.langchain.com/en/latest/chat_models/langchain_openai.chat_models.base.ChatOpenAI.html", "title": "Ontotext GraphDB"}]-->
import os

from langchain.chains import OntotextGraphDBQAChain
from langchain_openai import ChatOpenAI

# We'll be using an OpenAI model which requires an OpenAI API Key.
# However, other models are available as well:
# https://python.langchain.com/docs/integrations/chat/

# Set the environment variable `OPENAI_API_KEY` to your OpenAI API key
os.environ["OPENAI_API_KEY"] = "sk-***"

# Any available OpenAI model can be used here.
# We use 'gpt-4-1106-preview' because of the bigger context window.
# The 'gpt-4-1106-preview' model_name will deprecate in the future and will change to 'gpt-4-turbo' or similar,
# so be sure to consult with the OpenAI API https://platform.openai.com/docs/models for the correct naming.

chain = OntotextGraphDBQAChain.from_llm(
    ChatOpenAI(temperature=0, model_name="gpt-4-1106-preview"),
    graph=graph,
    verbose=True,
)
```


ê°„ë‹¨í•œ ì§ˆë¬¸ì„ í•´ë³´ê² ìŠµë‹ˆë‹¤.

```python
chain.invoke({chain.input_key: "What is the climate on Tatooine?"})[chain.output_key]
```

```output


[1m> Entering new OntotextGraphDBQAChain chain...[0m
Generated SPARQL:
[32;1m[1;3mPREFIX : <https://swapi.co/vocabulary/>
PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>

SELECT ?climate
WHERE {
  ?planet rdfs:label "Tatooine" ;
          :climate ?climate .
}[0m

[1m> Finished chain.[0m
```


```output
'The climate on Tatooine is arid.'
```


ì¡°ê¸ˆ ë” ë³µì¡í•œ ì§ˆë¬¸ë„ í•´ë³´ê² ìŠµë‹ˆë‹¤.

```python
chain.invoke({chain.input_key: "What is the climate on Luke Skywalker's home planet?"})[
    chain.output_key
]
```

```output


[1m> Entering new OntotextGraphDBQAChain chain...[0m
Generated SPARQL:
[32;1m[1;3mPREFIX : <https://swapi.co/vocabulary/>
PREFIX owl: <http://www.w3.org/2002/07/owl#>
PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>

SELECT ?climate
WHERE {
  ?character rdfs:label "Luke Skywalker" .
  ?character :homeworld ?planet .
  ?planet :climate ?climate .
}[0m

[1m> Finished chain.[0m
```


```output
"The climate on Luke Skywalker's home planet is arid."
```


ë” ë³µì¡í•œ ì§ˆë¬¸ë„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```python
chain.invoke(
    {
        chain.input_key: "What is the average box office revenue for all the Star Wars movies?"
    }
)[chain.output_key]
```

```output


[1m> Entering new OntotextGraphDBQAChain chain...[0m
Generated SPARQL:
[32;1m[1;3mPREFIX : <https://swapi.co/vocabulary/>
PREFIX owl: <http://www.w3.org/2002/07/owl#>
PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>
PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>

SELECT (AVG(?boxOffice) AS ?averageBoxOffice)
WHERE {
  ?film a :Film .
  ?film :boxOffice ?boxOfficeValue .
  BIND(xsd:decimal(?boxOfficeValue) AS ?boxOffice)
}
[0m

[1m> Finished chain.[0m
```


```output
'The average box office revenue for all the Star Wars movies is approximately 754.1 million dollars.'
```


## ì²´ì¸ ìˆ˜ì •ì

Ontotext GraphDB QA ì²´ì¸ì€ QA ì²´ì¸ì˜ ì¶”ê°€ ê°œì„  ë° ì•±ì˜ ì „ë°˜ì ì¸ ì‚¬ìš©ì ê²½í—˜ í–¥ìƒì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ ìˆ˜ì •ì„ í—ˆìš©í•©ë‹ˆë‹¤.

### "SPARQL ìƒì„±" í”„ë¡¬í”„íŠ¸

í”„ë¡¬í”„íŠ¸ëŠ” ì‚¬ìš©ì ì§ˆë¬¸ ë° KG ìŠ¤í‚¤ë§ˆë¥¼ ê¸°ë°˜ìœ¼ë¡œ SPARQL ì¿¼ë¦¬ ìƒì„±ì„ ìœ„í•´ ì‚¬ìš©ë©ë‹ˆë‹¤.

- `sparql_generation_prompt`
  
  ê¸°ë³¸ê°’:
  ```python
    GRAPHDB_SPARQL_GENERATION_TEMPLATE = """
    Write a SPARQL SELECT query for querying a graph database.
    The ontology schema delimited by triple backticks in Turtle format is:
  ```

  {schema}
  ```
  Use only the classes and properties provided in the schema to construct the SPARQL query.
  Do not use any classes or properties that are not explicitly provided in the SPARQL query.
  Include all necessary prefixes.
  Do not include any explanations or apologies in your responses.
  Do not wrap the query in backticks.
  Do not include any text except the SPARQL query generated.
  The question delimited by triple backticks is:
  ```

  {prompt}
  ```
  """
  GRAPHDB_SPARQL_GENERATION_PROMPT = PromptTemplate(
      input_variables=["schema", "prompt"],
      template=GRAPHDB_SPARQL_GENERATION_TEMPLATE,
  )
  ```


### "SPARQL ìˆ˜ì •" í”„ë¡¬í”„íŠ¸

ë•Œë•Œë¡œ LLMì´ êµ¬ë¬¸ ì˜¤ë¥˜ê°€ ìˆê±°ë‚˜ ì ‘ë‘ì‚¬ê°€ ëˆ„ë½ëœ SPARQL ì¿¼ë¦¬ë¥¼ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì²´ì¸ì€ LLMì—ê²Œ ì´ë¥¼ ìˆ˜ì •í•˜ë„ë¡ íŠ¹ì • íšŸìˆ˜ë§Œí¼ í”„ë¡¬í”„íŠ¸ë¥¼ ì œê³µí•˜ì—¬ ìˆ˜ì •í•˜ë ¤ê³  í•©ë‹ˆë‹¤.

- `sparql_fix_prompt`
  
  ê¸°ë³¸ê°’:
  ```python
    GRAPHDB_SPARQL_FIX_TEMPLATE = """
    This following SPARQL query delimited by triple backticks
  ```

  {generated_sparql}
  ```
  is not valid.
  The error delimited by triple backticks is
  ```

  {error_message}
  ```
  Give me a correct version of the SPARQL query.
  Do not change the logic of the query.
  Do not include any explanations or apologies in your responses.
  Do not wrap the query in backticks.
  Do not include any text except the SPARQL query generated.
  The ontology schema delimited by triple backticks in Turtle format is:
  ```

  {schema}
  ```
  """
  
  GRAPHDB_SPARQL_FIX_PROMPT = PromptTemplate(
      input_variables=["error_message", "generated_sparql", "schema"],
      template=GRAPHDB_SPARQL_FIX_TEMPLATE,
  )
  ```

- `max_fix_retries`
  
  ê¸°ë³¸ê°’: `5`

### "ì‘ë‹µ" í”„ë¡¬í”„íŠ¸

í”„ë¡¬í”„íŠ¸ëŠ” ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ë°˜í™˜ëœ ê²°ê³¼ì™€ ì´ˆê¸° ì‚¬ìš©ì ì§ˆë¬¸ì„ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µí•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤. ê¸°ë³¸ì ìœ¼ë¡œ LLMì€ ë°˜í™˜ëœ ê²°ê³¼ì—ì„œë§Œ ì •ë³´ë¥¼ ì‚¬ìš©í•˜ë„ë¡ ì§€ì‹œë©ë‹ˆë‹¤. ê²°ê³¼ ì§‘í•©ì´ ë¹„ì–´ ìˆëŠ” ê²½ìš° LLMì€ ì§ˆë¬¸ì— ë‹µí•  ìˆ˜ ì—†ë‹¤ê³  ì•Œë ¤ì•¼ í•©ë‹ˆë‹¤.

- `qa_prompt`
  
  ê¸°ë³¸ê°’:
  ```python
    GRAPHDB_QA_TEMPLATE = """Task: Generate a natural language response from the results of a SPARQL query.
    You are an assistant that creates well-written and human understandable answers.
    The information part contains the information provided, which you can use to construct an answer.
    The information provided is authoritative, you must never doubt it or try to use your internal knowledge to correct it.
    Make your response sound like the information is coming from an AI assistant, but don't add any information.
    Don't use internal knowledge to answer the question, just say you don't know if no information is available.
    Information:
    {context}
    
    Question: {prompt}
    Helpful Answer:"""
    GRAPHDB_QA_PROMPT = PromptTemplate(
        input_variables=["context", "prompt"], template=GRAPHDB_QA_TEMPLATE
    )
  ```


GraphDBì™€ í•¨ê»˜ QAë¥¼ ë§ˆì¹˜ë©´ ë‹¤ìŒ ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•˜ì—¬ Docker í™˜ê²½ì„ ì¢…ë£Œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
`docker compose down -v --remove-orphans`
Docker ì»´í¬ì¦ˆ íŒŒì¼ì´ ìˆëŠ” ë””ë ‰í† ë¦¬ì—ì„œ.