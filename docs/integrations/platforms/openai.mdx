---
canonical: https://python.langchain.com/v0.2/docs/integrations/platforms/openai/
keywords:
- openai
---

# OpenAI

All functionality related to OpenAI

>[OpenAI](https://en.wikipedia.org/wiki/OpenAI) is American artificial intelligence (AI) research laboratory 
> consisting of the non-profit `OpenAI Incorporated`
> and its for-profit subsidiary corporation `OpenAI Limited Partnership`. 
> `OpenAI` conducts AI research with the declared intention of promoting and developing a friendly AI. 
> `OpenAI` systems run on an `Azure`-based supercomputing platform from `Microsoft`.

>The [OpenAI API](https://platform.openai.com/docs/models) is powered by a diverse set of models with different capabilities and price points.
> 
>[ChatGPT](https://chat.openai.com) is the Artificial Intelligence (AI) chatbot developed by `OpenAI`.

## Installation and Setup

Install the integration package with
```bash
pip install langchain-openai
```

Get an OpenAI api key and set it as an environment variable (`OPENAI_API_KEY`)

## Chat model

See a [usage example](/docs/integrations/chat/openai).

```python
<!--IMPORTS:[{"imported": "ChatOpenAI", "source": "langchain_openai", "docs": "https://api.python.langchain.com/en/latest/chat_models/langchain_openai.chat_models.base.ChatOpenAI.html", "title": "OpenAI"}]-->
from langchain_openai import ChatOpenAI
```

If you are using a model hosted on `Azure`, you should use different wrapper for that:
```python
<!--IMPORTS:[{"imported": "AzureChatOpenAI", "source": "langchain_openai", "docs": "https://api.python.langchain.com/en/latest/chat_models/langchain_openai.chat_models.azure.AzureChatOpenAI.html", "title": "OpenAI"}]-->
from langchain_openai import AzureChatOpenAI
```
For a more detailed walkthrough of the `Azure` wrapper, see [here](/docs/integrations/chat/azure_chat_openai).

## LLM

See a [usage example](/docs/integrations/llms/openai).

```python
<!--IMPORTS:[{"imported": "OpenAI", "source": "langchain_openai", "docs": "https://api.python.langchain.com/en/latest/llms/langchain_openai.llms.base.OpenAI.html", "title": "OpenAI"}]-->
from langchain_openai import OpenAI
```

If you are using a model hosted on `Azure`, you should use different wrapper for that:
```python
<!--IMPORTS:[{"imported": "AzureOpenAI", "source": "langchain_openai", "docs": "https://api.python.langchain.com/en/latest/llms/langchain_openai.llms.azure.AzureOpenAI.html", "title": "OpenAI"}]-->
from langchain_openai import AzureOpenAI
```
For a more detailed walkthrough of the `Azure` wrapper, see [here](/docs/integrations/llms/azure_openai).

## Embedding Model

See a [usage example](/docs/integrations/text_embedding/openai)

```python
<!--IMPORTS:[{"imported": "OpenAIEmbeddings", "source": "langchain_openai", "docs": "https://api.python.langchain.com/en/latest/embeddings/langchain_openai.embeddings.base.OpenAIEmbeddings.html", "title": "OpenAI"}]-->
from langchain_openai import OpenAIEmbeddings
```

## Document Loader

See a [usage example](/docs/integrations/document_loaders/chatgpt_loader).

```python
<!--IMPORTS:[{"imported": "ChatGPTLoader", "source": "langchain_community.document_loaders.chatgpt", "docs": "https://api.python.langchain.com/en/latest/document_loaders/langchain_community.document_loaders.chatgpt.ChatGPTLoader.html", "title": "OpenAI"}]-->
from langchain_community.document_loaders.chatgpt import ChatGPTLoader
```

## Retriever

See a [usage example](/docs/integrations/retrievers/chatgpt-plugin).

```python
<!--IMPORTS:[{"imported": "ChatGPTPluginRetriever", "source": "langchain.retrievers", "docs": "https://api.python.langchain.com/en/latest/retrievers/langchain_community.retrievers.chatgpt_plugin_retriever.ChatGPTPluginRetriever.html", "title": "OpenAI"}]-->
from langchain.retrievers import ChatGPTPluginRetriever
```

## Tools

### Dall-E Image Generator

>[OpenAI Dall-E](https://openai.com/dall-e-3) are text-to-image models developed by `OpenAI` 
> using deep learning methodologies to generate digital images from natural language descriptions, 
> called "prompts".


See a [usage example](/docs/integrations/tools/dalle_image_generator).

```python
<!--IMPORTS:[{"imported": "DallEAPIWrapper", "source": "langchain_community.utilities.dalle_image_generator", "docs": "https://api.python.langchain.com/en/latest/utilities/langchain_community.utilities.dalle_image_generator.DallEAPIWrapper.html", "title": "OpenAI"}]-->
from langchain_community.utilities.dalle_image_generator import DallEAPIWrapper
```

## Adapter

See a [usage example](/docs/integrations/adapters/openai).

```python
from langchain.adapters import openai as lc_openai
```

## Tokenizer

There are several places you can use the `tiktoken` tokenizer. By default, it is used to count tokens
for OpenAI LLMs.

You can also use it to count tokens when splitting documents with 
```python
<!--IMPORTS:[{"imported": "CharacterTextSplitter", "source": "langchain.text_splitter", "docs": "https://api.python.langchain.com/en/latest/character/langchain_text_splitters.character.CharacterTextSplitter.html", "title": "OpenAI"}]-->
from langchain.text_splitter import CharacterTextSplitter
CharacterTextSplitter.from_tiktoken_encoder(...)
```
For a more detailed walkthrough of this, see [this notebook](/docs/how_to/split_by_token/#tiktoken)

## Chain

See a [usage example](https://python.langchain.com/v0.1/docs/guides/productionization/safety/moderation).

```python
<!--IMPORTS:[{"imported": "OpenAIModerationChain", "source": "langchain.chains", "docs": "https://api.python.langchain.com/en/latest/chains/langchain.chains.moderation.OpenAIModerationChain.html", "title": "OpenAI"}]-->
from langchain.chains import OpenAIModerationChain
```