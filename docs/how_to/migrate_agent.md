---
custom_edit_url: https://github.com/langchain-ai/langchain/edit/master/docs/docs/how_to/migrate_agent.ipynb
description: ë ˆê±°ì‹œ LangChain ì—ì´ì „íŠ¸ë¥¼ LangGraph ì—ì´ì „íŠ¸ë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜í•˜ëŠ” ë°©ë²•ì„ ì•ˆë‚´í•˜ëŠ” ê°€ì´ë“œì…ë‹ˆë‹¤.
keywords:
- create_react_agent
- create_react_agent()
---

# ë ˆê±°ì‹œ LangChain ì—ì´ì „íŠ¸ì—ì„œ LangGraphë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜í•˜ëŠ” ë°©ë²•

:::info ì „ì œ ì¡°ê±´

ì´ ê°€ì´ë“œëŠ” ë‹¤ìŒ ê°œë…ì— ëŒ€í•œ ì´í•´ë¥¼ ì „ì œë¡œ í•©ë‹ˆë‹¤:
- [ì—ì´ì „íŠ¸](/docs/concepts/#agents)
- [LangGraph](https://langchain-ai.github.io/langgraph/)
- [ë„êµ¬ í˜¸ì¶œ](/docs/how_to/tool_calling/)

:::

ì—¬ê¸°ì„œëŠ” ë ˆê±°ì‹œ LangChain ì—ì´ì „íŠ¸ì—ì„œ ë” ìœ ì—°í•œ [LangGraph](https://langchain-ai.github.io/langgraph/) ì—ì´ì „íŠ¸ë¡œ ì´ë™í•˜ëŠ” ë°©ë²•ì— ì´ˆì ì„ ë§ì¶¥ë‹ˆë‹¤.
LangChain ì—ì´ì „íŠ¸(íŠ¹íˆ [AgentExecutor](https://api.python.langchain.com/en/latest/agents/langchain.agents.agent.AgentExecutor.html#langchain.agents.agent.AgentExecutor))ëŠ” ì—¬ëŸ¬ êµ¬ì„± ë§¤ê°œë³€ìˆ˜ë¥¼ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤.
ì´ ë…¸íŠ¸ë¶ì—ì„œëŠ” ì´ëŸ¬í•œ ë§¤ê°œë³€ìˆ˜ê°€ [create_react_agent](https://langchain-ai.github.io/langgraph/reference/prebuilt/#create_react_agent) í”„ë¦¬ë¹ŒíŠ¸ í—¬í¼ ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ LangGraph ë¦¬ì•¡íŠ¸ ì—ì´ì „íŠ¸ ì‹¤í–‰ê¸°ë¡œ ì–´ë–»ê²Œ ë§¤í•‘ë˜ëŠ”ì§€ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.

#### ì „ì œ ì¡°ê±´

ì´ ì‚¬ìš© ë°©ë²• ê°€ì´ë“œëŠ” OpenAIë¥¼ LLMìœ¼ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤. ì‹¤í–‰ì„ ìœ„í•œ ì¢…ì†ì„±ì„ ì„¤ì¹˜í•˜ì„¸ìš”.

```python
%%capture --no-stderr
%pip install -U langgraph langchain langchain-openai
```


ê·¸ëŸ° ë‹¤ìŒ OpenAI API í‚¤ë¥¼ ì„¤ì •í•˜ì„¸ìš”.

```python
import os

os.environ["OPENAI_API_KEY"] = "sk-..."
```


## ê¸°ë³¸ ì‚¬ìš©ë²•

ë„êµ¬ í˜¸ì¶œ ReAct ìŠ¤íƒ€ì¼ ì—ì´ì „íŠ¸ë¥¼ ê¸°ë³¸ì ìœ¼ë¡œ ìƒì„±í•˜ê³  ì‚¬ìš©í•˜ëŠ” ê¸°ëŠ¥ì€ ë™ì¼í•©ë‹ˆë‹¤. ë¨¼ì € ëª¨ë¸ê³¼ ë„êµ¬ë¥¼ ì •ì˜í•œ ë‹¤ìŒ ì´ë¥¼ ì‚¬ìš©í•˜ì—¬ ì—ì´ì „íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

```python
<!--IMPORTS:[{"imported": "tool", "source": "langchain_core.tools", "docs": "https://api.python.langchain.com/en/latest/tools/langchain_core.tools.convert.tool.html", "title": "How to migrate from legacy LangChain agents to LangGraph"}, {"imported": "ChatOpenAI", "source": "langchain_openai", "docs": "https://api.python.langchain.com/en/latest/chat_models/langchain_openai.chat_models.base.ChatOpenAI.html", "title": "How to migrate from legacy LangChain agents to LangGraph"}]-->
from langchain_core.tools import tool
from langchain_openai import ChatOpenAI

model = ChatOpenAI(model="gpt-4o")


@tool
def magic_function(input: int) -> int:
    """Applies a magic function to an input."""
    return input + 2


tools = [magic_function]


query = "what is the value of magic_function(3)?"
```


LangChainì˜ [AgentExecutor](https://api.python.langchain.com/en/latest/agents/langchain.agents.agent.AgentExecutor.html#langchain.agents.agent.AgentExecutor)ì—ì„œëŠ” ì—ì´ì „íŠ¸ì˜ ìŠ¤í¬ë˜ì¹˜íŒ¨ë“œë¥¼ ìœ„í•œ ìë¦¬ í‘œì‹œìê°€ ìˆëŠ” í”„ë¡¬í”„íŠ¸ë¥¼ ì •ì˜í•©ë‹ˆë‹¤. ì—ì´ì „íŠ¸ëŠ” ë‹¤ìŒê³¼ ê°™ì´ í˜¸ì¶œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```python
<!--IMPORTS:[{"imported": "AgentExecutor", "source": "langchain.agents", "docs": "https://api.python.langchain.com/en/latest/agents/langchain.agents.agent.AgentExecutor.html", "title": "How to migrate from legacy LangChain agents to LangGraph"}, {"imported": "create_tool_calling_agent", "source": "langchain.agents", "docs": "https://api.python.langchain.com/en/latest/agents/langchain.agents.tool_calling_agent.base.create_tool_calling_agent.html", "title": "How to migrate from legacy LangChain agents to LangGraph"}, {"imported": "ChatPromptTemplate", "source": "langchain_core.prompts", "docs": "https://api.python.langchain.com/en/latest/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html", "title": "How to migrate from legacy LangChain agents to LangGraph"}]-->
from langchain.agents import AgentExecutor, create_tool_calling_agent
from langchain_core.prompts import ChatPromptTemplate

prompt = ChatPromptTemplate.from_messages(
    [
        ("system", "You are a helpful assistant"),
        ("human", "{input}"),
        # Placeholders fill up a **list** of messages
        ("placeholder", "{agent_scratchpad}"),
    ]
)


agent = create_tool_calling_agent(model, tools, prompt)
agent_executor = AgentExecutor(agent=agent, tools=tools)

agent_executor.invoke({"input": query})
```


```output
{'input': 'what is the value of magic_function(3)?',
 'output': 'The value of `magic_function(3)` is 5.'}
```


LangGraphì˜ [ë¦¬ì•¡íŠ¸ ì—ì´ì „íŠ¸ ì‹¤í–‰ê¸°](https://langchain-ai.github.io/langgraph/reference/prebuilt/#create_react_agent)ëŠ” ë©”ì‹œì§€ ëª©ë¡ìœ¼ë¡œ ì •ì˜ëœ ìƒíƒœë¥¼ ê´€ë¦¬í•©ë‹ˆë‹¤. ì—ì´ì „íŠ¸ì˜ ì¶œë ¥ì— ë„êµ¬ í˜¸ì¶œì´ ì—†ì„ ë•Œê¹Œì§€ ëª©ë¡ì„ ê³„ì† ì²˜ë¦¬í•©ë‹ˆë‹¤. ì‹œì‘í•˜ë ¤ë©´ ë©”ì‹œì§€ ëª©ë¡ì„ ì…ë ¥í•©ë‹ˆë‹¤. ì¶œë ¥ì—ëŠ” ê·¸ë˜í”„ì˜ ì „ì²´ ìƒíƒœê°€ í¬í•¨ë©ë‹ˆë‹¤. ì´ ê²½ìš° ëŒ€í™” ê¸°ë¡ì…ë‹ˆë‹¤.

```python
from langgraph.prebuilt import create_react_agent

app = create_react_agent(model, tools)


messages = app.invoke({"messages": [("human", query)]})
{
    "input": query,
    "output": messages["messages"][-1].content,
}
```


```output
{'input': 'what is the value of magic_function(3)?',
 'output': 'The value of `magic_function(3)` is 5.'}
```


```python
message_history = messages["messages"]

new_query = "Pardon?"

messages = app.invoke({"messages": message_history + [("human", new_query)]})
{
    "input": new_query,
    "output": messages["messages"][-1].content,
}
```


```output
{'input': 'Pardon?',
 'output': 'The value you get when you apply `magic_function` to the input 3 is 5.'}
```


## í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿

ë ˆê±°ì‹œ LangChain ì—ì´ì „íŠ¸ì—ì„œëŠ” í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì„ ì „ë‹¬í•´ì•¼ í•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ì—ì´ì „íŠ¸ë¥¼ ì œì–´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

LangGraph [ë¦¬ì•¡íŠ¸ ì—ì´ì „íŠ¸ ì‹¤í–‰ê¸°](https://langchain-ai.github.io/langgraph/reference/prebuilt/#create_react_agent)ì—ì„œëŠ” ê¸°ë³¸ì ìœ¼ë¡œ í”„ë¡¬í”„íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤. ì—ì´ì „íŠ¸ì— ëŒ€í•´ ìœ ì‚¬í•œ ì œì–´ë¥¼ ëª‡ ê°€ì§€ ë°©ë²•ìœ¼ë¡œ ë‹¬ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

1. ì‹œìŠ¤í…œ ë©”ì‹œì§€ë¥¼ ì…ë ¥ìœ¼ë¡œ ì „ë‹¬
2. ì‹œìŠ¤í…œ ë©”ì‹œì§€ë¡œ ì—ì´ì „íŠ¸ë¥¼ ì´ˆê¸°í™”
3. ëª¨ë¸ì— ì „ë‹¬í•˜ê¸° ì „ì— ë©”ì‹œì§€ë¥¼ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜ë¡œ ì—ì´ì „íŠ¸ë¥¼ ì´ˆê¸°í™”

ì•„ë˜ì—ì„œ ì´ ëª¨ë“  ê²ƒì„ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤. ì—ì´ì „íŠ¸ê°€ ìŠ¤í˜ì¸ì–´ë¡œ ì‘ë‹µí•˜ë„ë¡ ì‚¬ìš©ì ì •ì˜ ì§€ì¹¨ì„ ì „ë‹¬í•˜ê² ìŠµë‹ˆë‹¤.

ë¨¼ì € `AgentExecutor`ë¥¼ ì‚¬ìš©í•˜ì—¬:

```python
prompt = ChatPromptTemplate.from_messages(
    [
        ("system", "You are a helpful assistant. Respond only in Spanish."),
        ("human", "{input}"),
        # Placeholders fill up a **list** of messages
        ("placeholder", "{agent_scratchpad}"),
    ]
)


agent = create_tool_calling_agent(model, tools, prompt)
agent_executor = AgentExecutor(agent=agent, tools=tools)

agent_executor.invoke({"input": query})
```


```output
{'input': 'what is the value of magic_function(3)?',
 'output': 'El valor de `magic_function(3)` es 5.'}
```


ì´ì œ [ë¦¬ì•¡íŠ¸ ì—ì´ì „íŠ¸ ì‹¤í–‰ê¸°](https://langchain-ai.github.io/langgraph/reference/prebuilt/#create_react_agent)ì— ì‚¬ìš©ì ì •ì˜ ì‹œìŠ¤í…œ ë©”ì‹œì§€ë¥¼ ì „ë‹¬í•´ ë³´ê² ìŠµë‹ˆë‹¤.

LangGraphì˜ í”„ë¦¬ë¹ŒíŠ¸ `create_react_agent`ëŠ” í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì„ ì§ì ‘ ë§¤ê°œë³€ìˆ˜ë¡œ ë°›ì§€ ì•Šì§€ë§Œ, ëŒ€ì‹  [`state_modifier`](https://langchain-ai.github.io/langgraph/reference/prebuilt/#create_react_agent) ë§¤ê°œë³€ìˆ˜ë¥¼ ë°›ìŠµë‹ˆë‹¤. ì´ëŠ” LLMì´ í˜¸ì¶œë˜ê¸° ì „ì— ê·¸ë˜í”„ ìƒíƒœë¥¼ ìˆ˜ì •í•˜ë©°, ë„¤ ê°€ì§€ ê°’ ì¤‘ í•˜ë‚˜ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤:

- ë©”ì‹œì§€ ëª©ë¡ì˜ ì‹œì‘ ë¶€ë¶„ì— ì¶”ê°€ë˜ëŠ” `SystemMessage`.
- `SystemMessage`ë¡œ ë³€í™˜ë˜ì–´ ë©”ì‹œì§€ ëª©ë¡ì˜ ì‹œì‘ ë¶€ë¶„ì— ì¶”ê°€ë˜ëŠ” `string`.
- ì „ì²´ ê·¸ë˜í”„ ìƒíƒœë¥¼ ì…ë ¥ìœ¼ë¡œ ë°›ì•„ì•¼ í•˜ëŠ” `Callable`. ì¶œë ¥ì€ ì–¸ì–´ ëª¨ë¸ì— ì „ë‹¬ë©ë‹ˆë‹¤.
- ì „ì²´ ê·¸ë˜í”„ ìƒíƒœë¥¼ ì…ë ¥ìœ¼ë¡œ ë°›ì•„ì•¼ í•˜ëŠ” [`Runnable`](/docs/concepts/#langchain-expression-language-lcel). ì¶œë ¥ì€ ì–¸ì–´ ëª¨ë¸ì— ì „ë‹¬ë©ë‹ˆë‹¤.

ì‘ë™ ë°©ì‹ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:

```python
<!--IMPORTS:[{"imported": "SystemMessage", "source": "langchain_core.messages", "docs": "https://api.python.langchain.com/en/latest/messages/langchain_core.messages.system.SystemMessage.html", "title": "How to migrate from legacy LangChain agents to LangGraph"}]-->
from langchain_core.messages import SystemMessage
from langgraph.prebuilt import create_react_agent

system_message = "You are a helpful assistant. Respond only in Spanish."
# This could also be a SystemMessage object
# system_message = SystemMessage(content="You are a helpful assistant. Respond only in Spanish.")

app = create_react_agent(model, tools, state_modifier=system_message)


messages = app.invoke({"messages": [("user", query)]})
```


ë˜í•œ ì„ì˜ì˜ í•¨ìˆ˜ë¥¼ ì „ë‹¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ í•¨ìˆ˜ëŠ” ë©”ì‹œì§€ ëª©ë¡ì„ ì…ë ¥ìœ¼ë¡œ ë°›ì•„ ë©”ì‹œì§€ ëª©ë¡ì„ ì¶œë ¥í•´ì•¼ í•©ë‹ˆë‹¤.
ì—¬ê¸°ì—ì„œ ë©”ì‹œì§€ë¥¼ ì„ì˜ë¡œ í¬ë§·í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ ê²½ìš°, ë©”ì‹œì§€ ëª©ë¡ì˜ ì‹œì‘ ë¶€ë¶„ì— SystemMessageë¥¼ ì¶”ê°€í•˜ê² ìŠµë‹ˆë‹¤.

```python
from langgraph.prebuilt import create_react_agent
from langgraph.prebuilt.chat_agent_executor import AgentState

prompt = ChatPromptTemplate.from_messages(
    [
        ("system", "You are a helpful assistant. Respond only in Spanish."),
        ("placeholder", "{messages}"),
    ]
)


def _modify_state_messages(state: AgentState):
    return prompt.invoke({"messages": state["messages"]}).to_messages() + [
        ("user", "Also say 'Pandamonium!' after the answer.")
    ]


app = create_react_agent(model, tools, state_modifier=_modify_state_messages)


messages = app.invoke({"messages": [("human", query)]})
print(
    {
        "input": query,
        "output": messages["messages"][-1].content,
    }
)
```

```output
{'input': 'what is the value of magic_function(3)?', 'output': 'El valor de magic_function(3) es 5. Â¡Pandamonium!'}
```


## ë©”ëª¨ë¦¬

### LangChainì—ì„œ

LangChainì˜ [AgentExecutor](https://api.python.langchain.com/en/latest/agents/langchain.agents.agent.AgentExecutor.html#langchain.agents.agent.AgentExecutor.iter)ì—ì„œëŠ” ì±„íŒ… [Memory](https://api.python.langchain.com/en/latest/agents/langchain.agents.agent.AgentExecutor.html#langchain.agents.agent.AgentExecutor.memory)ë¥¼ ì¶”ê°€í•˜ì—¬ ë‹¤ì¤‘ í„´ ëŒ€í™”ì— ì°¸ì—¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```python
<!--IMPORTS:[{"imported": "AgentExecutor", "source": "langchain.agents", "docs": "https://api.python.langchain.com/en/latest/agents/langchain.agents.agent.AgentExecutor.html", "title": "How to migrate from legacy LangChain agents to LangGraph"}, {"imported": "create_tool_calling_agent", "source": "langchain.agents", "docs": "https://api.python.langchain.com/en/latest/agents/langchain.agents.tool_calling_agent.base.create_tool_calling_agent.html", "title": "How to migrate from legacy LangChain agents to LangGraph"}, {"imported": "InMemoryChatMessageHistory", "source": "langchain_core.chat_history", "docs": "https://api.python.langchain.com/en/latest/chat_history/langchain_core.chat_history.InMemoryChatMessageHistory.html", "title": "How to migrate from legacy LangChain agents to LangGraph"}, {"imported": "ChatPromptTemplate", "source": "langchain_core.prompts", "docs": "https://api.python.langchain.com/en/latest/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html", "title": "How to migrate from legacy LangChain agents to LangGraph"}, {"imported": "RunnableWithMessageHistory", "source": "langchain_core.runnables.history", "docs": "https://api.python.langchain.com/en/latest/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html", "title": "How to migrate from legacy LangChain agents to LangGraph"}, {"imported": "tool", "source": "langchain_core.tools", "docs": "https://api.python.langchain.com/en/latest/tools/langchain_core.tools.convert.tool.html", "title": "How to migrate from legacy LangChain agents to LangGraph"}, {"imported": "ChatOpenAI", "source": "langchain_openai", "docs": "https://api.python.langchain.com/en/latest/chat_models/langchain_openai.chat_models.base.ChatOpenAI.html", "title": "How to migrate from legacy LangChain agents to LangGraph"}]-->
from langchain.agents import AgentExecutor, create_tool_calling_agent
from langchain_core.chat_history import InMemoryChatMessageHistory
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_core.tools import tool
from langchain_openai import ChatOpenAI

model = ChatOpenAI(model="gpt-4o")
memory = InMemoryChatMessageHistory(session_id="test-session")
prompt = ChatPromptTemplate.from_messages(
    [
        ("system", "You are a helpful assistant."),
        # First put the history
        ("placeholder", "{chat_history}"),
        # Then the new input
        ("human", "{input}"),
        # Finally the scratchpad
        ("placeholder", "{agent_scratchpad}"),
    ]
)


@tool
def magic_function(input: int) -> int:
    """Applies a magic function to an input."""
    return input + 2


tools = [magic_function]


agent = create_tool_calling_agent(model, tools, prompt)
agent_executor = AgentExecutor(agent=agent, tools=tools)

agent_with_chat_history = RunnableWithMessageHistory(
    agent_executor,
    # This is needed because in most real world scenarios, a session id is needed
    # It isn't really used here because we are using a simple in memory ChatMessageHistory
    lambda session_id: memory,
    input_messages_key="input",
    history_messages_key="chat_history",
)

config = {"configurable": {"session_id": "test-session"}}
print(
    agent_with_chat_history.invoke(
        {"input": "Hi, I'm polly! What's the output of magic_function of 3?"}, config
    )["output"]
)
print("---")
print(agent_with_chat_history.invoke({"input": "Remember my name?"}, config)["output"])
print("---")
print(
    agent_with_chat_history.invoke({"input": "what was that output again?"}, config)[
        "output"
    ]
)
```

```output
Hi Polly! The output of the magic function for the input 3 is 5.
---
Yes, your name is Polly!
---
The output of the magic function for the input 3 is 5.
```


### LangGraphì—ì„œ

ë©”ëª¨ë¦¬ëŠ” ë‹¨ìˆœíˆ [ì§€ì†ì„±](https://langchain-ai.github.io/langgraph/how-tos/persistence/) ë˜ëŠ” [ì²´í¬í¬ì¸íŒ…](https://langchain-ai.github.io/langgraph/reference/checkpoints/)ì…ë‹ˆë‹¤.

ì—ì´ì „íŠ¸ì— `checkpointer`ë¥¼ ì¶”ê°€í•˜ë©´ ë¬´ë£Œë¡œ ì±„íŒ… ë©”ëª¨ë¦¬ë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```python
from langgraph.checkpoint import MemorySaver  # an in-memory checkpointer
from langgraph.prebuilt import create_react_agent

system_message = "You are a helpful assistant."
# This could also be a SystemMessage object
# system_message = SystemMessage(content="You are a helpful assistant. Respond only in Spanish.")

memory = MemorySaver()
app = create_react_agent(
    model, tools, state_modifier=system_message, checkpointer=memory
)

config = {"configurable": {"thread_id": "test-thread"}}
print(
    app.invoke(
        {
            "messages": [
                ("user", "Hi, I'm polly! What's the output of magic_function of 3?")
            ]
        },
        config,
    )["messages"][-1].content
)
print("---")
print(
    app.invoke({"messages": [("user", "Remember my name?")]}, config)["messages"][
        -1
    ].content
)
print("---")
print(
    app.invoke({"messages": [("user", "what was that output again?")]}, config)[
        "messages"
    ][-1].content
)
```

```output
Hi Polly! The output of the magic_function for the input of 3 is 5.
---
Yes, your name is Polly!
---
The output of the magic_function for the input of 3 was 5.
```


## ë‹¨ê³„ ë°˜ë³µí•˜ê¸°

### LangChainì—ì„œ

LangChainì˜ [AgentExecutor](https://api.python.langchain.com/en/latest/agents/langchain.agents.agent.AgentExecutor.html#langchain.agents.agent.AgentExecutor.iter)ì—ì„œëŠ” [stream](https://api.python.langchain.com/en/latest/runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable.stream) (ë˜ëŠ” ë¹„ë™ê¸° `astream`) ë©”ì„œë“œ ë˜ëŠ” [iter](https://api.python.langchain.com/en/latest/agents/langchain.agents.agent.AgentExecutor.html#langchain.agents.agent.AgentExecutor.iter) ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ ë‹¨ê³„ë¥¼ ë°˜ë³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. LangGraphëŠ” [stream](https://api.python.langchain.com/en/latest/runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable.stream) ì‚¬ìš©í•˜ì—¬ ë‹¨ê³„ë³„ ë°˜ë³µì„ ì§€ì›í•©ë‹ˆë‹¤.

```python
<!--IMPORTS:[{"imported": "AgentExecutor", "source": "langchain.agents", "docs": "https://api.python.langchain.com/en/latest/agents/langchain.agents.agent.AgentExecutor.html", "title": "How to migrate from legacy LangChain agents to LangGraph"}, {"imported": "create_tool_calling_agent", "source": "langchain.agents", "docs": "https://api.python.langchain.com/en/latest/agents/langchain.agents.tool_calling_agent.base.create_tool_calling_agent.html", "title": "How to migrate from legacy LangChain agents to LangGraph"}, {"imported": "ChatPromptTemplate", "source": "langchain_core.prompts", "docs": "https://api.python.langchain.com/en/latest/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html", "title": "How to migrate from legacy LangChain agents to LangGraph"}, {"imported": "tool", "source": "langchain_core.tools", "docs": "https://api.python.langchain.com/en/latest/tools/langchain_core.tools.convert.tool.html", "title": "How to migrate from legacy LangChain agents to LangGraph"}, {"imported": "ChatOpenAI", "source": "langchain_openai", "docs": "https://api.python.langchain.com/en/latest/chat_models/langchain_openai.chat_models.base.ChatOpenAI.html", "title": "How to migrate from legacy LangChain agents to LangGraph"}]-->
from langchain.agents import AgentExecutor, create_tool_calling_agent
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.tools import tool
from langchain_openai import ChatOpenAI

model = ChatOpenAI(model="gpt-4o")


prompt = ChatPromptTemplate.from_messages(
    [
        ("system", "You are a helpful assistant."),
        ("human", "{input}"),
        # Placeholders fill up a **list** of messages
        ("placeholder", "{agent_scratchpad}"),
    ]
)


@tool
def magic_function(input: int) -> int:
    """Applies a magic function to an input."""
    return input + 2


tools = [magic_function]

agent = create_tool_calling_agent(model, tools, prompt=prompt)
agent_executor = AgentExecutor(agent=agent, tools=tools)

for step in agent_executor.stream({"input": query}):
    print(step)
```

```output
{'actions': [ToolAgentAction(tool='magic_function', tool_input={'input': 3}, log="\nInvoking: `magic_function` with `{'input': 3}`\n\n\n", message_log=[AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_1exy0rScfPmo4fy27FbQ5qJ2', 'function': {'arguments': '{"input":3}', 'name': 'magic_function'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_4e2b2da518'}, id='run-5664e138-7085-4da7-a49e-5656a87b8d78', tool_calls=[{'name': 'magic_function', 'args': {'input': 3}, 'id': 'call_1exy0rScfPmo4fy27FbQ5qJ2', 'type': 'tool_call'}], tool_call_chunks=[{'name': 'magic_function', 'args': '{"input":3}', 'id': 'call_1exy0rScfPmo4fy27FbQ5qJ2', 'index': 0, 'type': 'tool_call_chunk'}])], tool_call_id='call_1exy0rScfPmo4fy27FbQ5qJ2')], 'messages': [AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_1exy0rScfPmo4fy27FbQ5qJ2', 'function': {'arguments': '{"input":3}', 'name': 'magic_function'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_4e2b2da518'}, id='run-5664e138-7085-4da7-a49e-5656a87b8d78', tool_calls=[{'name': 'magic_function', 'args': {'input': 3}, 'id': 'call_1exy0rScfPmo4fy27FbQ5qJ2', 'type': 'tool_call'}], tool_call_chunks=[{'name': 'magic_function', 'args': '{"input":3}', 'id': 'call_1exy0rScfPmo4fy27FbQ5qJ2', 'index': 0, 'type': 'tool_call_chunk'}])]}
{'steps': [AgentStep(action=ToolAgentAction(tool='magic_function', tool_input={'input': 3}, log="\nInvoking: `magic_function` with `{'input': 3}`\n\n\n", message_log=[AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_1exy0rScfPmo4fy27FbQ5qJ2', 'function': {'arguments': '{"input":3}', 'name': 'magic_function'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_4e2b2da518'}, id='run-5664e138-7085-4da7-a49e-5656a87b8d78', tool_calls=[{'name': 'magic_function', 'args': {'input': 3}, 'id': 'call_1exy0rScfPmo4fy27FbQ5qJ2', 'type': 'tool_call'}], tool_call_chunks=[{'name': 'magic_function', 'args': '{"input":3}', 'id': 'call_1exy0rScfPmo4fy27FbQ5qJ2', 'index': 0, 'type': 'tool_call_chunk'}])], tool_call_id='call_1exy0rScfPmo4fy27FbQ5qJ2'), observation=5)], 'messages': [FunctionMessage(content='5', name='magic_function')]}
{'output': 'The value of `magic_function(3)` is 5.', 'messages': [AIMessage(content='The value of `magic_function(3)` is 5.')]}
```


### LangGraphì—ì„œ

LangGraphì—ì„œëŠ” [stream](https://langchain-ai.github.io/langgraph/reference/graphs/#langgraph.graph.graph.CompiledGraph.stream) ë˜ëŠ” ë¹„ë™ê¸° `astream` ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ ê¸°ë³¸ì ìœ¼ë¡œ ì²˜ë¦¬ë©ë‹ˆë‹¤.

```python
from langgraph.prebuilt import create_react_agent
from langgraph.prebuilt.chat_agent_executor import AgentState

prompt = ChatPromptTemplate.from_messages(
    [
        ("system", "You are a helpful assistant."),
        ("placeholder", "{messages}"),
    ]
)


def _modify_state_messages(state: AgentState):
    return prompt.invoke({"messages": state["messages"]}).to_messages()


app = create_react_agent(model, tools, state_modifier=_modify_state_messages)

for step in app.stream({"messages": [("human", query)]}, stream_mode="updates"):
    print(step)
```

```output
{'agent': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_my9rzFSKR4T1yYKwCsfbZB8A', 'function': {'arguments': '{"input":3}', 'name': 'magic_function'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 61, 'total_tokens': 75}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_bc2a86f5f5', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-dd705555-8fae-4fb1-a033-5d99a23e3c22-0', tool_calls=[{'name': 'magic_function', 'args': {'input': 3}, 'id': 'call_my9rzFSKR4T1yYKwCsfbZB8A', 'type': 'tool_call'}], usage_metadata={'input_tokens': 61, 'output_tokens': 14, 'total_tokens': 75})]}}
{'tools': {'messages': [ToolMessage(content='5', name='magic_function', tool_call_id='call_my9rzFSKR4T1yYKwCsfbZB8A')]}}
{'agent': {'messages': [AIMessage(content='The value of `magic_function(3)` is 5.', response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 84, 'total_tokens': 98}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_4e2b2da518', 'finish_reason': 'stop', 'logprobs': None}, id='run-698cad05-8cb2-4d08-8c2a-881e354f6cc7-0', usage_metadata={'input_tokens': 84, 'output_tokens': 14, 'total_tokens': 98})]}}
```


## `return_intermediate_steps`

### LangChainì—ì„œ

AgentExecutorì—ì„œ ì´ ë§¤ê°œë³€ìˆ˜ë¥¼ ì„¤ì •í•˜ë©´ ì‚¬ìš©ìê°€ intermediate_stepsì— ì ‘ê·¼í•  ìˆ˜ ìˆìœ¼ë©°, ì´ëŠ” ì—ì´ì „íŠ¸ ì‘ì—…(ì˜ˆ: ë„êµ¬ í˜¸ì¶œ)ê³¼ ê·¸ ê²°ê³¼ë¥¼ ìŒìœ¼ë¡œ ë¬¶ìŠµë‹ˆë‹¤.

```python
agent_executor = AgentExecutor(agent=agent, tools=tools, return_intermediate_steps=True)
result = agent_executor.invoke({"input": query})
print(result["intermediate_steps"])
```

```output
[(ToolAgentAction(tool='magic_function', tool_input={'input': 3}, log="\nInvoking: `magic_function` with `{'input': 3}`\n\n\n", message_log=[AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_uPZ2D1Bo5mdED3gwgaeWURrf', 'function': {'arguments': '{"input":3}', 'name': 'magic_function'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_4e2b2da518'}, id='run-a792db4a-278d-4090-82ae-904a30eada93', tool_calls=[{'name': 'magic_function', 'args': {'input': 3}, 'id': 'call_uPZ2D1Bo5mdED3gwgaeWURrf', 'type': 'tool_call'}], tool_call_chunks=[{'name': 'magic_function', 'args': '{"input":3}', 'id': 'call_uPZ2D1Bo5mdED3gwgaeWURrf', 'index': 0, 'type': 'tool_call_chunk'}])], tool_call_id='call_uPZ2D1Bo5mdED3gwgaeWURrf'), 5)]
```


### LangGraphì—ì„œ

ê¸°ë³¸ì ìœ¼ë¡œ LangGraphì˜ [ë¦¬ì•¡íŠ¸ ì—ì´ì „íŠ¸ ì‹¤í–‰ê¸°](https://langchain-ai.github.io/langgraph/reference/prebuilt/#create_react_agent)ëŠ” ëª¨ë“  ë©”ì‹œì§€ë¥¼ ì¤‘ì•™ ìƒíƒœì— ì¶”ê°€í•©ë‹ˆë‹¤. ë”°ë¼ì„œ ì „ì²´ ìƒíƒœë¥¼ ë³´ê¸°ë§Œ í•˜ë©´ ì¤‘ê°„ ë‹¨ê³„ë¥¼ ì‰½ê²Œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```python
from langgraph.prebuilt import create_react_agent

app = create_react_agent(model, tools=tools)

messages = app.invoke({"messages": [("human", query)]})

messages
```


```output
{'messages': [HumanMessage(content='what is the value of magic_function(3)?', id='cd7d0f49-a0e0-425a-b2b0-603a716058ed'),
  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_VfZ9287DuybOSrBsQH5X12xf', 'function': {'arguments': '{"input":3}', 'name': 'magic_function'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 55, 'total_tokens': 69}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_4e2b2da518', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-a1e965cd-bf61-44f9-aec1-8aaecb80955f-0', tool_calls=[{'name': 'magic_function', 'args': {'input': 3}, 'id': 'call_VfZ9287DuybOSrBsQH5X12xf', 'type': 'tool_call'}], usage_metadata={'input_tokens': 55, 'output_tokens': 14, 'total_tokens': 69}),
  ToolMessage(content='5', name='magic_function', id='20d5c2fe-a5d8-47fa-9e04-5282642e2039', tool_call_id='call_VfZ9287DuybOSrBsQH5X12xf'),
  AIMessage(content='The value of `magic_function(3)` is 5.', response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 78, 'total_tokens': 92}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_4e2b2da518', 'finish_reason': 'stop', 'logprobs': None}, id='run-abf9341c-ef41-4157-935d-a3be5dfa2f41-0', usage_metadata={'input_tokens': 78, 'output_tokens': 14, 'total_tokens': 92})]}
```


## `max_iterations`

### LangChainì—ì„œ

`AgentExecutor`ëŠ” ì‚¬ìš©ìê°€ ì§€ì •ëœ ë°˜ë³µ ìˆ˜ë¥¼ ì´ˆê³¼í•˜ëŠ” ì‹¤í–‰ì„ ì¤‘ë‹¨í•  ìˆ˜ ìˆë„ë¡ `max_iterations` ë§¤ê°œë³€ìˆ˜ë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤.

```python
@tool
def magic_function(input: str) -> str:
    """Applies a magic function to an input."""
    return "Sorry, there was an error. Please try again."


tools = [magic_function]
```


```python
prompt = ChatPromptTemplate.from_messages(
    [
        ("system", "You are a helpful assistant. Respond only in Spanish."),
        ("human", "{input}"),
        # Placeholders fill up a **list** of messages
        ("placeholder", "{agent_scratchpad}"),
    ]
)

agent = create_tool_calling_agent(model, tools, prompt)
agent_executor = AgentExecutor(
    agent=agent,
    tools=tools,
    verbose=True,
    max_iterations=3,
)

agent_executor.invoke({"input": query})
```

```output


[1m> Entering new AgentExecutor chain...[0m
[32;1m[1;3m
Invoking: `magic_function` with `{'input': '3'}`


[0m[36;1m[1;3mSorry, there was an error. Please try again.[0m[32;1m[1;3mParece que hubo un error al intentar calcular el valor de la funciÃ³n mÃ¡gica. Â¿Te gustarÃ­a que lo intente de nuevo?[0m

[1m> Finished chain.[0m
```


```output
{'input': 'what is the value of magic_function(3)?',
 'output': 'Parece que hubo un error al intentar calcular el valor de la funciÃ³n mÃ¡gica. Â¿Te gustarÃ­a que lo intente de nuevo?'}
```


### LangGraphì—ì„œ

LangGraphì—ì„œëŠ” `recursion_limit` êµ¬ì„± ë§¤ê°œë³€ìˆ˜ë¥¼ í†µí•´ ì´ë¥¼ ì œì–´í•©ë‹ˆë‹¤.

`AgentExecutor`ì—ì„œ "ë°˜ë³µ"ì€ ë„êµ¬ í˜¸ì¶œ ë° ì‹¤í–‰ì˜ ì „ì²´ í„´ì„ í¬í•¨í•©ë‹ˆë‹¤. LangGraphì—ì„œëŠ” ê° ë‹¨ê³„ê°€ ì¬ê·€ í•œë„ì— ê¸°ì—¬í•˜ë¯€ë¡œ, ë™ë“±í•œ ê²°ê³¼ë¥¼ ì–»ê¸° ìœ„í•´ ë‘ ë°°ë¡œ ê³±í•˜ê³  í•˜ë‚˜ë¥¼ ë”í•´ì•¼ í•©ë‹ˆë‹¤.

ì¬ê·€ í•œë„ì— ë„ë‹¬í•˜ë©´ LangGraphëŠ” íŠ¹ì • ì˜ˆì™¸ ìœ í˜•ì„ ë°œìƒì‹œí‚¤ë©°, ì´ë¥¼ ì¡ì•„ë‚´ê³  AgentExecutorì™€ ìœ ì‚¬í•˜ê²Œ ê´€ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```python
from langgraph.errors import GraphRecursionError
from langgraph.prebuilt import create_react_agent

RECURSION_LIMIT = 2 * 3 + 1

app = create_react_agent(model, tools=tools)

try:
    for chunk in app.stream(
        {"messages": [("human", query)]},
        {"recursion_limit": RECURSION_LIMIT},
        stream_mode="values",
    ):
        print(chunk["messages"][-1])
except GraphRecursionError:
    print({"input": query, "output": "Agent stopped due to max iterations."})
```

```output
content='what is the value of magic_function(3)?' id='74e2d5e8-2b59-4820-979c-8d11ecfc14c2'
content='' additional_kwargs={'tool_calls': [{'id': 'call_ihtrH6IG95pDXpKluIwAgi3J', 'function': {'arguments': '{"input":"3"}', 'name': 'magic_function'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 55, 'total_tokens': 69}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_4e2b2da518', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-5a35e465-8a08-43dd-ac8b-4a76dcace305-0' tool_calls=[{'name': 'magic_function', 'args': {'input': '3'}, 'id': 'call_ihtrH6IG95pDXpKluIwAgi3J', 'type': 'tool_call'}] usage_metadata={'input_tokens': 55, 'output_tokens': 14, 'total_tokens': 69}
content='Sorry, there was an error. Please try again.' name='magic_function' id='8c37c19b-3586-46b1-aab9-a045786801a2' tool_call_id='call_ihtrH6IG95pDXpKluIwAgi3J'
content='It seems there was an error in processing the request. Let me try again.' additional_kwargs={'tool_calls': [{'id': 'call_iF0vYWAd6rfely0cXSqdMOnF', 'function': {'arguments': '{"input":"3"}', 'name': 'magic_function'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 31, 'prompt_tokens': 88, 'total_tokens': 119}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_4e2b2da518', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-eb88ec77-d492-43a5-a5dd-4cefef9a6920-0' tool_calls=[{'name': 'magic_function', 'args': {'input': '3'}, 'id': 'call_iF0vYWAd6rfely0cXSqdMOnF', 'type': 'tool_call'}] usage_metadata={'input_tokens': 88, 'output_tokens': 31, 'total_tokens': 119}
content='Sorry, there was an error. Please try again.' name='magic_function' id='c9ff261f-a0f1-4c92-a9f2-cd749f62d911' tool_call_id='call_iF0vYWAd6rfely0cXSqdMOnF'
content='I am currently unable to process the request with the input "3" for the `magic_function`. If you have any other questions or need assistance with something else, please let me know!' response_metadata={'token_usage': {'completion_tokens': 39, 'prompt_tokens': 141, 'total_tokens': 180}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_4e2b2da518', 'finish_reason': 'stop', 'logprobs': None} id='run-d42508aa-f286-4b57-80fb-f8a76736d470-0' usage_metadata={'input_tokens': 141, 'output_tokens': 39, 'total_tokens': 180}
```


## `max_execution_time`

### LangChainì—ì„œ

`AgentExecutor`ëŠ” ì‚¬ìš©ìê°€ ì´ ì‹œê°„ ì œí•œì„ ì´ˆê³¼í•˜ëŠ” ì‹¤í–‰ì„ ì¤‘ë‹¨í•  ìˆ˜ ìˆë„ë¡ `max_execution_time` ë§¤ê°œë³€ìˆ˜ë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤.

```python
import time


@tool
def magic_function(input: str) -> str:
    """Applies a magic function to an input."""
    time.sleep(2.5)
    return "Sorry, there was an error. Please try again."


tools = [magic_function]

agent = create_tool_calling_agent(model, tools, prompt)
agent_executor = AgentExecutor(
    agent=agent,
    tools=tools,
    max_execution_time=2,
    verbose=True,
)

agent_executor.invoke({"input": query})
```


```output


[1m> Entering new AgentExecutor chain...[0m
[32;1m[1;3m
Invoking: `magic_function` with `{'input': '3'}`


[0m[36;1m[1;3mSorry, there was an error. Please try again.[0m[32;1m[1;3m[0m

[1m> Finished chain.[0m
```


```output
{'input': 'what is the value of magic_function(3)?',
 'output': 'Agent stopped due to max iterations.'}
```


### LangGraphì—ì„œ

LangGraphì˜ ë¦¬ì•¡íŠ¸ ì—ì´ì „íŠ¸ë¥¼ ì‚¬ìš©í•˜ë©´ ë‘ ê°€ì§€ ìˆ˜ì¤€ì—ì„œ íƒ€ì„ì•„ì›ƒì„ ì œì–´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ê° **ë‹¨ê³„**ì˜ ê²½ê³„ë¥¼ ì„¤ì •í•˜ê¸° ìœ„í•´ `step_timeout`ì„ ì„¤ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```python
from langgraph.prebuilt import create_react_agent

app = create_react_agent(model, tools=tools)
# Set the max timeout for each step here
app.step_timeout = 2

try:
    for chunk in app.stream({"messages": [("human", query)]}):
        print(chunk)
        print("------")
except TimeoutError:
    print({"input": query, "output": "Agent stopped due to max iterations."})
```

```output
{'agent': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_FKiTkTd0Ffd4rkYSzERprf1M', 'function': {'arguments': '{"input":"3"}', 'name': 'magic_function'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 55, 'total_tokens': 69}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_4e2b2da518', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-b842f7b6-ec10-40f8-8c0e-baa220b77e91-0', tool_calls=[{'name': 'magic_function', 'args': {'input': '3'}, 'id': 'call_FKiTkTd0Ffd4rkYSzERprf1M', 'type': 'tool_call'}], usage_metadata={'input_tokens': 55, 'output_tokens': 14, 'total_tokens': 69})]}}
------
{'input': 'what is the value of magic_function(3)?', 'output': 'Agent stopped due to max iterations.'}
```


ì „ì²´ ì‹¤í–‰ì— ëŒ€í•œ ë‹¨ì¼ ìµœëŒ€ íƒ€ì„ì•„ì›ƒì„ ì„¤ì •í•˜ëŠ” ë˜ ë‹¤ë¥¸ ë°©ë²•ì€ íŒŒì´ì¬ í‘œì¤€ ë¼ì´ë¸ŒëŸ¬ë¦¬ [asyncio](https://docs.python.org/3/library/asyncio.html) ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì§ì ‘ ì‚¬ìš©í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

```python
import asyncio

from langgraph.prebuilt import create_react_agent

app = create_react_agent(model, tools=tools)


async def stream(app, inputs):
    async for chunk in app.astream({"messages": [("human", query)]}):
        print(chunk)
        print("------")


try:
    task = asyncio.create_task(stream(app, {"messages": [("human", query)]}))
    await asyncio.wait_for(task, timeout=3)
except TimeoutError:
    print("Task Cancelled.")
```

```output
{'agent': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_WoOB8juagB08xrP38twYlYKR', 'function': {'arguments': '{"input":"3"}', 'name': 'magic_function'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 55, 'total_tokens': 69}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_4e2b2da518', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-73dee47e-30ab-42c9-bb0c-6f227cac96cd-0', tool_calls=[{'name': 'magic_function', 'args': {'input': '3'}, 'id': 'call_WoOB8juagB08xrP38twYlYKR', 'type': 'tool_call'}], usage_metadata={'input_tokens': 55, 'output_tokens': 14, 'total_tokens': 69})]}}
------
Task Cancelled.
```


## `early_stopping_method`

### LangChainì—ì„œ

LangChainì˜ [AgentExecutor](https://api.python.langchain.com/en/latest/agents/langchain.agents.agent.AgentExecutor.html#langchain.agents.agent.AgentExecutor.iter)ì—ì„œëŠ” ì‚¬ìš©ìê°€ "ì—ì´ì „íŠ¸ê°€ ë°˜ë³µ í•œë„ ë˜ëŠ” ì‹œê°„ í•œë„ë¡œ ì¸í•´ ì¤‘ì§€ë˜ì—ˆìŠµë‹ˆë‹¤."ë¼ëŠ” ë¬¸ìì—´ì„ ë°˜í™˜í•˜ê±°ë‚˜(`"force"`), LLMì— ìµœì¢…ì ìœ¼ë¡œ ì‘ë‹µí•˜ë„ë¡ ìš”ì²­í•  ìˆ˜ ìˆëŠ” [early_stopping_method](https://api.python.langchain.com/en/latest/agents/langchain.agents.agent.AgentExecutor.html#langchain.agents.agent.AgentExecutor.early_stopping_method)ë¥¼ êµ¬ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```python
<!--IMPORTS:[{"imported": "AgentExecutor", "source": "langchain.agents", "docs": "https://api.python.langchain.com/en/latest/agents/langchain.agents.agent.AgentExecutor.html", "title": "How to migrate from legacy LangChain agents to LangGraph"}, {"imported": "create_tool_calling_agent", "source": "langchain.agents", "docs": "https://api.python.langchain.com/en/latest/agents/langchain.agents.tool_calling_agent.base.create_tool_calling_agent.html", "title": "How to migrate from legacy LangChain agents to LangGraph"}, {"imported": "ChatPromptTemplate", "source": "langchain_core.prompts", "docs": "https://api.python.langchain.com/en/latest/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html", "title": "How to migrate from legacy LangChain agents to LangGraph"}, {"imported": "tool", "source": "langchain_core.tools", "docs": "https://api.python.langchain.com/en/latest/tools/langchain_core.tools.convert.tool.html", "title": "How to migrate from legacy LangChain agents to LangGraph"}, {"imported": "ChatOpenAI", "source": "langchain_openai", "docs": "https://api.python.langchain.com/en/latest/chat_models/langchain_openai.chat_models.base.ChatOpenAI.html", "title": "How to migrate from legacy LangChain agents to LangGraph"}]-->
from langchain.agents import AgentExecutor, create_tool_calling_agent
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.tools import tool
from langchain_openai import ChatOpenAI

model = ChatOpenAI(model="gpt-4o")


prompt = ChatPromptTemplate.from_messages(
    [
        ("system", "You are a helpful assistant."),
        ("human", "{input}"),
        # Placeholders fill up a **list** of messages
        ("placeholder", "{agent_scratchpad}"),
    ]
)


@tool
def magic_function(input: int) -> int:
    """Applies a magic function to an input."""
    return "Sorry there was an error, please try again."


tools = [magic_function]

agent = create_tool_calling_agent(model, tools, prompt=prompt)
agent_executor = AgentExecutor(
    agent=agent, tools=tools, early_stopping_method="force", max_iterations=1
)

result = agent_executor.invoke({"input": query})
print("Output with early_stopping_method='force':")
print(result["output"])
```

```output
Output with early_stopping_method='force':
Agent stopped due to max iterations.
```


### LangGraphì—ì„œ

LangGraphì—ì„œëŠ” ì „ì²´ ìƒíƒœì— ì ‘ê·¼í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì—ì´ì „íŠ¸ ì™¸ë¶€ì—ì„œ ì‘ë‹µ ë™ì‘ì„ ëª…ì‹œì ìœ¼ë¡œ ì²˜ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```python
from langgraph.errors import GraphRecursionError
from langgraph.prebuilt import create_react_agent

RECURSION_LIMIT = 2 * 1 + 1

app = create_react_agent(model, tools=tools)

try:
    for chunk in app.stream(
        {"messages": [("human", query)]},
        {"recursion_limit": RECURSION_LIMIT},
        stream_mode="values",
    ):
        print(chunk["messages"][-1])
except GraphRecursionError:
    print({"input": query, "output": "Agent stopped due to max iterations."})
```

```output
content='what is the value of magic_function(3)?' id='4fa7fbe5-758c-47a3-9268-717665d10680'
content='' additional_kwargs={'tool_calls': [{'id': 'call_ujE0IQBbIQnxcF9gsZXQfdhF', 'function': {'arguments': '{"input":3}', 'name': 'magic_function'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 55, 'total_tokens': 69}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_4e2b2da518', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-65d689aa-baee-4342-a5d2-048feefab418-0' tool_calls=[{'name': 'magic_function', 'args': {'input': 3}, 'id': 'call_ujE0IQBbIQnxcF9gsZXQfdhF', 'type': 'tool_call'}] usage_metadata={'input_tokens': 55, 'output_tokens': 14, 'total_tokens': 69}
content='Sorry there was an error, please try again.' name='magic_function' id='ef8ddf1d-9ad7-4ac0-b784-b673c4d94bbd' tool_call_id='call_ujE0IQBbIQnxcF9gsZXQfdhF'
content='It seems there was an issue with the previous attempt. Let me try that again.' additional_kwargs={'tool_calls': [{'id': 'call_GcsAfCFUHJ50BN2IOWnwTbQ7', 'function': {'arguments': '{"input":3}', 'name': 'magic_function'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 32, 'prompt_tokens': 87, 'total_tokens': 119}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_4e2b2da518', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-54527c4b-8ff0-4ee8-8abf-224886bd222e-0' tool_calls=[{'name': 'magic_function', 'args': {'input': 3}, 'id': 'call_GcsAfCFUHJ50BN2IOWnwTbQ7', 'type': 'tool_call'}] usage_metadata={'input_tokens': 87, 'output_tokens': 32, 'total_tokens': 119}
{'input': 'what is the value of magic_function(3)?', 'output': 'Agent stopped due to max iterations.'}
```


## `trim_intermediate_steps`

### LangChainì—ì„œ

LangChainì˜ [AgentExecutor](https://api.python.langchain.com/en/latest/agents/langchain.agents.agent.AgentExecutor.html#langchain.agents.agent.AgentExecutor)ì—ì„œëŠ” [trim_intermediate_steps](https://api.python.langchain.com/en/latest/agents/langchain.agents.agent.AgentExecutor.html#langchain.agents.agent.AgentExecutor.trim_intermediate_steps)ë¥¼ ì‚¬ìš©í•˜ì—¬ ì¥ê¸° ì‹¤í–‰ ì—ì´ì „íŠ¸ì˜ ì¤‘ê°„ ë‹¨ê³„ë¥¼ ì˜ë¼ë‚¼ ìˆ˜ ìˆìœ¼ë©°, ì´ëŠ” ì •ìˆ˜(ì—ì´ì „íŠ¸ê°€ ë§ˆì§€ë§‰ N ë‹¨ê³„ë¥¼ ìœ ì§€í•´ì•¼ í•¨ì„ ë‚˜íƒ€ëƒ„) ë˜ëŠ” ì‚¬ìš©ì ì •ì˜ í•¨ìˆ˜ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ì˜ˆë¥¼ ë“¤ì–´, ì—ì´ì „íŠ¸ê°€ ê°€ì¥ ìµœê·¼ì˜ ì¤‘ê°„ ë‹¨ê³„ë§Œ ë³´ë„ë¡ ê°’ì„ ì˜ë¼ë‚¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```python
<!--IMPORTS:[{"imported": "AgentExecutor", "source": "langchain.agents", "docs": "https://api.python.langchain.com/en/latest/agents/langchain.agents.agent.AgentExecutor.html", "title": "How to migrate from legacy LangChain agents to LangGraph"}, {"imported": "create_tool_calling_agent", "source": "langchain.agents", "docs": "https://api.python.langchain.com/en/latest/agents/langchain.agents.tool_calling_agent.base.create_tool_calling_agent.html", "title": "How to migrate from legacy LangChain agents to LangGraph"}, {"imported": "ChatPromptTemplate", "source": "langchain_core.prompts", "docs": "https://api.python.langchain.com/en/latest/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html", "title": "How to migrate from legacy LangChain agents to LangGraph"}, {"imported": "tool", "source": "langchain_core.tools", "docs": "https://api.python.langchain.com/en/latest/tools/langchain_core.tools.convert.tool.html", "title": "How to migrate from legacy LangChain agents to LangGraph"}, {"imported": "ChatOpenAI", "source": "langchain_openai", "docs": "https://api.python.langchain.com/en/latest/chat_models/langchain_openai.chat_models.base.ChatOpenAI.html", "title": "How to migrate from legacy LangChain agents to LangGraph"}]-->
from langchain.agents import AgentExecutor, create_tool_calling_agent
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.tools import tool
from langchain_openai import ChatOpenAI

model = ChatOpenAI(model="gpt-4o")


prompt = ChatPromptTemplate.from_messages(
    [
        ("system", "You are a helpful assistant."),
        ("human", "{input}"),
        # Placeholders fill up a **list** of messages
        ("placeholder", "{agent_scratchpad}"),
    ]
)


magic_step_num = 1


@tool
def magic_function(input: int) -> int:
    """Applies a magic function to an input."""
    global magic_step_num
    print(f"Call number: {magic_step_num}")
    magic_step_num += 1
    return input + magic_step_num


tools = [magic_function]

agent = create_tool_calling_agent(model, tools, prompt=prompt)


def trim_steps(steps: list):
    # Let's give the agent amnesia
    return []


agent_executor = AgentExecutor(
    agent=agent, tools=tools, trim_intermediate_steps=trim_steps
)


query = "Call the magic function 4 times in sequence with the value 3. You cannot call it multiple times at once."

for step in agent_executor.stream({"input": query}):
    pass
```

```output
Call number: 1
Call number: 2
Call number: 3
Call number: 4
Call number: 5
Call number: 6
Call number: 7
Call number: 8
Call number: 9
Call number: 10
Call number: 11
Call number: 12
Call number: 13
Call number: 14
``````output
Stopping agent prematurely due to triggering stop condition
``````output
Call number: 15
```


### LangGraphì—ì„œ

í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì„ ì „ë‹¬í•  ë•Œì™€ ë§ˆì°¬ê°€ì§€ë¡œ [`state_modifier`](https://langchain-ai.github.io/langgraph/reference/prebuilt/#create_react_agent)ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```python
from langgraph.errors import GraphRecursionError
from langgraph.prebuilt import create_react_agent
from langgraph.prebuilt.chat_agent_executor import AgentState

magic_step_num = 1


@tool
def magic_function(input: int) -> int:
    """Applies a magic function to an input."""
    global magic_step_num
    print(f"Call number: {magic_step_num}")
    magic_step_num += 1
    return input + magic_step_num


tools = [magic_function]


def _modify_state_messages(state: AgentState):
    # Give the agent amnesia, only keeping the original user query
    return [("system", "You are a helpful assistant"), state["messages"][0]]


app = create_react_agent(model, tools, state_modifier=_modify_state_messages)

try:
    for step in app.stream({"messages": [("human", query)]}, stream_mode="updates"):
        pass
except GraphRecursionError as e:
    print("Stopping agent prematurely due to triggering stop condition")
```

```output
Call number: 1
Call number: 2
Call number: 3
Call number: 4
Call number: 5
Call number: 6
Call number: 7
Call number: 8
Call number: 9
Call number: 10
Call number: 11
Call number: 12
Stopping agent prematurely due to triggering stop condition
```


## ë‹¤ìŒ ë‹¨ê³„

ì´ì œ LangChain ì—ì´ì „íŠ¸ ì‹¤í–‰ê¸°ë¥¼ LangGraphë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜í•˜ëŠ” ë°©ë²•ì„ ë°°ì› ìŠµë‹ˆë‹¤.

ë‹¤ìŒìœ¼ë¡œ ë‹¤ë¥¸ [LangGraph ì‚¬ìš© ë°©ë²• ê°€ì´ë“œ](https://langchain-ai.github.io/langgraph/how-tos/)ë¥¼ í™•ì¸í•˜ì„¸ìš”.