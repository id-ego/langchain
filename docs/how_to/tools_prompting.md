---
custom_edit_url: https://github.com/langchain-ai/langchain/edit/master/docs/docs/how_to/tools_prompting.ipynb
description: ì´ ê°€ì´ë“œëŠ” LLM ë° ì±„íŒ… ëª¨ë¸ì— ëŒ€í•œ ì• ë“œí˜¹ ë„êµ¬ í˜¸ì¶œ ê¸°ëŠ¥ ì¶”ê°€ ë°©ë²•ì„ ì„¤ëª…í•©ë‹ˆë‹¤. ë„êµ¬ í˜¸ì¶œì„ ìœ„í•œ ëŒ€ì²´ ë°©ë²•ì„ ì œê³µí•©ë‹ˆë‹¤.
sidebar_position: 3
---

# LLM ë° ì±„íŒ… ëª¨ë¸ì— ì• ë“œí˜¹ ë„êµ¬ í˜¸ì¶œ ê¸°ëŠ¥ ì¶”ê°€í•˜ëŠ” ë°©ë²•

:::caution

ì¼ë¶€ ëª¨ë¸ì€ ë„êµ¬ í˜¸ì¶œì„ ìœ„í•´ ë¯¸ì„¸ ì¡°ì •ë˜ì–´ ìˆìœ¼ë©° ë„êµ¬ í˜¸ì¶œì„ ìœ„í•œ ì „ìš© APIë¥¼ ì œê³µí•©ë‹ˆë‹¤. ì¼ë°˜ì ìœ¼ë¡œ ì´ëŸ¬í•œ ëª¨ë¸ì€ ë¯¸ì„¸ ì¡°ì •ë˜ì§€ ì•Šì€ ëª¨ë¸ë³´ë‹¤ ë„êµ¬ í˜¸ì¶œì— ë” ëŠ¥ìˆ™í•˜ë©°, ë„êµ¬ í˜¸ì¶œì´ í•„ìš”í•œ ì‚¬ìš© ì‚¬ë¡€ì— ê¶Œì¥ë©ë‹ˆë‹¤. ìì„¸í•œ ë‚´ìš©ì€ [ì±„íŒ… ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ë„êµ¬ í˜¸ì¶œí•˜ëŠ” ë°©ë²•](/docs/how_to/tool_calling) ê°€ì´ë“œë¥¼ ì°¸ì¡°í•˜ì‹­ì‹œì˜¤.

:::

:::info í•„ìˆ˜ ì¡°ê±´

ì´ ê°€ì´ë“œëŠ” ë‹¤ìŒ ê°œë…ì— ëŒ€í•œ ì´í•´ë¥¼ ì „ì œë¡œ í•©ë‹ˆë‹¤:

- [LangChain Tools](/docs/concepts/#tools)
- [í•¨ìˆ˜/ë„êµ¬ í˜¸ì¶œ](https://python.langchain.com/v0.2/docs/concepts/#functiontool-calling)
- [ì±„íŒ… ëª¨ë¸](/docs/concepts/#chat-models)
- [LLMs](/docs/concepts/#llms)

:::

ì´ ê°€ì´ë“œì—ì„œëŠ” ì±„íŒ… ëª¨ë¸ì— **ì• ë“œí˜¹** ë„êµ¬ í˜¸ì¶œ ì§€ì›ì„ ì¶”ê°€í•˜ëŠ” ë°©ë²•ì„ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤. ì´ëŠ” [ë„êµ¬ í˜¸ì¶œ](/docs/how_to/tool_calling)ì„ ê¸°ë³¸ì ìœ¼ë¡œ ì§€ì›í•˜ì§€ ì•ŠëŠ” ëª¨ë¸ì„ ì‚¬ìš©í•  ê²½ìš° ë„êµ¬ë¥¼ í˜¸ì¶œí•˜ëŠ” ëŒ€ì²´ ë°©ë²•ì…ë‹ˆë‹¤.

ëª¨ë¸ì´ ì ì ˆí•œ ë„êµ¬ë¥¼ í˜¸ì¶œí•˜ë„ë¡ ìœ ë„í•˜ëŠ” í”„ë¡¬í”„íŠ¸ë¥¼ ì‘ì„±í•˜ì—¬ ì´ë¥¼ ìˆ˜í–‰í•  ê²ƒì…ë‹ˆë‹¤. ë‹¤ìŒì€ ë…¼ë¦¬ì˜ ë‹¤ì´ì–´ê·¸ë¨ì…ë‹ˆë‹¤:

![chain](../../static/img/tool_chain.svg)

## ì„¤ì •

ë‹¤ìŒ íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤:

```python
%pip install --upgrade --quiet langchain langchain-community
```


LangSmithë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ ì•„ë˜ì˜ ì£¼ì„ì„ ì œê±°í•˜ì‹­ì‹œì˜¤:

```python
import getpass
import os
# os.environ["LANGCHAIN_TRACING_V2"] = "true"
# os.environ["LANGCHAIN_API_KEY"] = getpass.getpass()
```


ì´ ì‚¬ìš© ë°©ë²• ê°€ì´ë“œë¥¼ ìœ„í•´ ì£¼ì–´ì§„ ëª¨ë¸ ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ ëª¨ë¸ë“¤ ì¤‘ ëŒ€ë¶€ë¶„ì€ ì´ë¯¸ [ë„¤ì´í‹°ë¸Œ ë„êµ¬ í˜¸ì¶œì„ ì§€ì›](/docs/integrations/chat/)í•˜ë¯€ë¡œ, ì—¬ê¸°ì„œ ë³´ì—¬ì£¼ëŠ” í”„ë¡¬í”„íŠ¸ ì „ëµì„ ì‚¬ìš©í•˜ëŠ” ê²ƒì€ ì˜ë¯¸ê°€ ì—†ìœ¼ë©°, ëŒ€ì‹  [ì±„íŒ… ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ë„êµ¬ í˜¸ì¶œí•˜ëŠ” ë°©ë²•](/docs/how_to/tool_calling) ê°€ì´ë“œë¥¼ ë”°ë¼ì•¼ í•©ë‹ˆë‹¤.

import ChatModelTabs from "@theme/ChatModelTabs";

<ChatModelTabs openaiParams={`model="gpt-4"`} />

ì•„ì´ë””ì–´ë¥¼ ì„¤ëª…í•˜ê¸° ìœ„í•´, ë„êµ¬ í˜¸ì¶œì— ëŒ€í•œ ë„¤ì´í‹°ë¸Œ ì§€ì›ì´ **ì—†ëŠ”** `phi3`ë¥¼ Ollamaë¥¼ í†µí•´ ì‚¬ìš©í•  ê²ƒì…ë‹ˆë‹¤. `Ollama`ë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ [ì´ ì§€ì¹¨](/docs/integrations/chat/ollama/)ì„ ë”°ë¥´ì‹­ì‹œì˜¤.

```python
<!--IMPORTS:[{"imported": "Ollama", "source": "langchain_community.llms", "docs": "https://api.python.langchain.com/en/latest/llms/langchain_community.llms.ollama.Ollama.html", "title": "How to add ad-hoc tool calling capability to LLMs and Chat Models"}]-->
from langchain_community.llms import Ollama

model = Ollama(model="phi3")
```


## ë„êµ¬ ìƒì„±

ë¨¼ì €, `add` ë° `multiply` ë„êµ¬ë¥¼ ìƒì„±í•˜ê² ìŠµë‹ˆë‹¤. ì‚¬ìš©ì ì •ì˜ ë„êµ¬ ìƒì„±ì— ëŒ€í•œ ìì„¸í•œ ë‚´ìš©ì€ [ì´ ê°€ì´ë“œ](/docs/how_to/custom_tools)ë¥¼ ì°¸ì¡°í•˜ì‹­ì‹œì˜¤.

```python
<!--IMPORTS:[{"imported": "tool", "source": "langchain_core.tools", "docs": "https://api.python.langchain.com/en/latest/tools/langchain_core.tools.convert.tool.html", "title": "How to add ad-hoc tool calling capability to LLMs and Chat Models"}]-->
from langchain_core.tools import tool


@tool
def multiply(x: float, y: float) -> float:
    """Multiply two numbers together."""
    return x * y


@tool
def add(x: int, y: int) -> int:
    "Add two numbers."
    return x + y


tools = [multiply, add]

# Let's inspect the tools
for t in tools:
    print("--")
    print(t.name)
    print(t.description)
    print(t.args)
```

```output
--
multiply
Multiply two numbers together.
{'x': {'title': 'X', 'type': 'number'}, 'y': {'title': 'Y', 'type': 'number'}}
--
add
Add two numbers.
{'x': {'title': 'X', 'type': 'integer'}, 'y': {'title': 'Y', 'type': 'integer'}}
```


```python
multiply.invoke({"x": 4, "y": 5})
```


```output
20.0
```


## í”„ë¡¬í”„íŠ¸ ì‘ì„±

ëª¨ë¸ì´ ì•¡ì„¸ìŠ¤í•  ìˆ˜ ìˆëŠ” ë„êµ¬, í•´ë‹¹ ë„êµ¬ì˜ ì¸ìˆ˜ ë° ëª¨ë¸ì˜ ì›í•˜ëŠ” ì¶œë ¥ í˜•ì‹ì„ ì§€ì •í•˜ëŠ” í”„ë¡¬í”„íŠ¸ë¥¼ ì‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤. ì´ ê²½ìš°, ëª¨ë¸ì—ê²Œ `{"name": "...", "arguments": {...}}` í˜•ì‹ì˜ JSON ë¸”ë¡­ì„ ì¶œë ¥í•˜ë„ë¡ ì§€ì‹œí•  ê²ƒì…ë‹ˆë‹¤.

```python
<!--IMPORTS:[{"imported": "JsonOutputParser", "source": "langchain_core.output_parsers", "docs": "https://api.python.langchain.com/en/latest/output_parsers/langchain_core.output_parsers.json.JsonOutputParser.html", "title": "How to add ad-hoc tool calling capability to LLMs and Chat Models"}, {"imported": "ChatPromptTemplate", "source": "langchain_core.prompts", "docs": "https://api.python.langchain.com/en/latest/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html", "title": "How to add ad-hoc tool calling capability to LLMs and Chat Models"}, {"imported": "render_text_description", "source": "langchain_core.tools", "docs": "https://api.python.langchain.com/en/latest/tools/langchain_core.tools.render.render_text_description.html", "title": "How to add ad-hoc tool calling capability to LLMs and Chat Models"}]-->
from langchain_core.output_parsers import JsonOutputParser
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.tools import render_text_description

rendered_tools = render_text_description(tools)
print(rendered_tools)
```

```output
multiply(x: float, y: float) -> float - Multiply two numbers together.
add(x: int, y: int) -> int - Add two numbers.
```


```python
system_prompt = f"""\
You are an assistant that has access to the following set of tools. 
Here are the names and descriptions for each tool:

{rendered_tools}

Given the user input, return the name and input of the tool to use. 
Return your response as a JSON blob with 'name' and 'arguments' keys.

The `arguments` should be a dictionary, with keys corresponding 
to the argument names and the values corresponding to the requested values.
"""

prompt = ChatPromptTemplate.from_messages(
    [("system", system_prompt), ("user", "{input}")]
)
```


```python
chain = prompt | model
message = chain.invoke({"input": "what's 3 plus 1132"})

# Let's take a look at the output from the model
# if the model is an LLM (not a chat model), the output will be a string.
if isinstance(message, str):
    print(message)
else:  # Otherwise it's a chat model
    print(message.content)
```

```output
{
    "name": "add",
    "arguments": {
        "x": 3,
        "y": 1132
    }
}
```


## ì¶œë ¥ íŒŒì„œ ì¶”ê°€

ëª¨ë¸ì˜ ì¶œë ¥ì„ JSONìœ¼ë¡œ íŒŒì‹±í•˜ê¸° ìœ„í•´ `JsonOutputParser`ë¥¼ ì‚¬ìš©í•  ê²ƒì…ë‹ˆë‹¤.

```python
<!--IMPORTS:[{"imported": "JsonOutputParser", "source": "langchain_core.output_parsers", "docs": "https://api.python.langchain.com/en/latest/output_parsers/langchain_core.output_parsers.json.JsonOutputParser.html", "title": "How to add ad-hoc tool calling capability to LLMs and Chat Models"}]-->
from langchain_core.output_parsers import JsonOutputParser

chain = prompt | model | JsonOutputParser()
chain.invoke({"input": "what's thirteen times 4"})
```


```output
{'name': 'multiply', 'arguments': {'x': 13.0, 'y': 4.0}}
```


:::important

ğŸ‰ ë†€ë¼ì›Œìš”! ğŸ‰ ì´ì œ ëª¨ë¸ì—ê²Œ ë„êµ¬ë¥¼ í˜¸ì¶œí•˜ë„ë¡ **ìš”ì²­**í•˜ëŠ” ë°©ë²•ì„ ì§€ì‹œí–ˆìŠµë‹ˆë‹¤.

ì´ì œ ë„êµ¬ë¥¼ ì‹¤ì œë¡œ ì‹¤í–‰í•  ìˆ˜ ìˆëŠ” ë¡œì§ì„ ë§Œë“¤ì–´ ë³´ê² ìŠµë‹ˆë‹¤!
:::

## ë„êµ¬ í˜¸ì¶œ ğŸƒ

ëª¨ë¸ì´ ë„êµ¬ë¥¼ í˜¸ì¶œí•˜ë„ë¡ ìš”ì²­í•  ìˆ˜ ìˆê²Œ ë˜ì—ˆìœ¼ë¯€ë¡œ, ì‹¤ì œë¡œ ë„êµ¬ë¥¼ í˜¸ì¶œí•  ìˆ˜ ìˆëŠ” í•¨ìˆ˜ë¥¼ ì‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤.

ì´ í•¨ìˆ˜ëŠ” ì´ë¦„ì— ë”°ë¼ ì ì ˆí•œ ë„êµ¬ë¥¼ ì„ íƒí•˜ê³ , ëª¨ë¸ì´ ì„ íƒí•œ ì¸ìˆ˜ë¥¼ ì „ë‹¬í•©ë‹ˆë‹¤.

```python
<!--IMPORTS:[{"imported": "RunnableConfig", "source": "langchain_core.runnables", "docs": "https://api.python.langchain.com/en/latest/runnables/langchain_core.runnables.config.RunnableConfig.html", "title": "How to add ad-hoc tool calling capability to LLMs and Chat Models"}]-->
from typing import Any, Dict, Optional, TypedDict

from langchain_core.runnables import RunnableConfig


class ToolCallRequest(TypedDict):
    """A typed dict that shows the inputs into the invoke_tool function."""

    name: str
    arguments: Dict[str, Any]


def invoke_tool(
    tool_call_request: ToolCallRequest, config: Optional[RunnableConfig] = None
):
    """A function that we can use the perform a tool invocation.

    Args:
        tool_call_request: a dict that contains the keys name and arguments.
            The name must match the name of a tool that exists.
            The arguments are the arguments to that tool.
        config: This is configuration information that LangChain uses that contains
            things like callbacks, metadata, etc.See LCEL documentation about RunnableConfig.

    Returns:
        output from the requested tool
    """
    tool_name_to_tool = {tool.name: tool for tool in tools}
    name = tool_call_request["name"]
    requested_tool = tool_name_to_tool[name]
    return requested_tool.invoke(tool_call_request["arguments"], config=config)
```


ì´ì œ ì´ë¥¼ í…ŒìŠ¤íŠ¸í•´ ë³´ê² ìŠµë‹ˆë‹¤ ğŸ§ª!

```python
invoke_tool({"name": "multiply", "arguments": {"x": 3, "y": 5}})
```


```output
15.0
```


## í•¨ê»˜ ëª¨ìœ¼ê¸°

ë”í•˜ê¸° ë° ê³±í•˜ê¸° ê¸°ëŠ¥ì„ ê°–ì¶˜ ê³„ì‚°ê¸°ë¥¼ ìƒì„±í•˜ëŠ” ì²´ì¸ìœ¼ë¡œ í•¨ê»˜ ëª¨ì•„ ë³´ê² ìŠµë‹ˆë‹¤.

```python
chain = prompt | model | JsonOutputParser() | invoke_tool
chain.invoke({"input": "what's thirteen times 4.14137281"})
```


```output
53.83784653
```


## ë„êµ¬ ì…ë ¥ ë°˜í™˜

ë„êµ¬ ì¶œë ¥ë¿ë§Œ ì•„ë‹ˆë¼ ë„êµ¬ ì…ë ¥ë„ ë°˜í™˜í•˜ëŠ” ê²ƒì´ ìœ ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ìš°ë¦¬ëŠ” `RunnablePassthrough.assign`ì„ ì‚¬ìš©í•˜ì—¬ ë„êµ¬ ì¶œë ¥ì„ ì‰½ê²Œ ë°˜í™˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” RunnablePassrthrough êµ¬ì„± ìš”ì†Œì— ëŒ€í•œ ì…ë ¥(ì‚¬ì „ìœ¼ë¡œ ê°€ì •ë¨)ì„ ê°€ì ¸ì™€ì„œ í˜„ì¬ ì…ë ¥ì— ìˆëŠ” ëª¨ë“  ê²ƒì„ ì „ë‹¬í•˜ë©´ì„œ í‚¤ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤:

```python
<!--IMPORTS:[{"imported": "RunnablePassthrough", "source": "langchain_core.runnables", "docs": "https://api.python.langchain.com/en/latest/runnables/langchain_core.runnables.passthrough.RunnablePassthrough.html", "title": "How to add ad-hoc tool calling capability to LLMs and Chat Models"}]-->
from langchain_core.runnables import RunnablePassthrough

chain = (
    prompt | model | JsonOutputParser() | RunnablePassthrough.assign(output=invoke_tool)
)
chain.invoke({"input": "what's thirteen times 4.14137281"})
```


```output
{'name': 'multiply',
 'arguments': {'x': 13, 'y': 4.14137281},
 'output': 53.83784653}
```


## ë‹¤ìŒì€ ë¬´ì—‡ì¸ê°€ìš”?

ì´ ì‚¬ìš© ë°©ë²• ê°€ì´ë“œëŠ” ëª¨ë¸ì´ ëª¨ë“  í•„ìˆ˜ ë„êµ¬ ì •ë³´ë¥¼ ì˜¬ë°”ë¥´ê²Œ ì¶œë ¥í•  ë•Œì˜ "í–‰ë³µí•œ ê²½ë¡œ"ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.

ì‹¤ì œë¡œ ë” ë³µì¡í•œ ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²½ìš°, íŠ¹íˆ ë„êµ¬ í˜¸ì¶œì„ ìœ„í•´ ë¯¸ì„¸ ì¡°ì •ë˜ì§€ ì•Šì€ ëª¨ë¸ì´ë‚˜ ëœ ëŠ¥ë ¥ ìˆëŠ” ëª¨ë¸ì„ ì‚¬ìš©í•  ê²½ìš° ëª¨ë¸ì—ì„œ ì˜¤ë¥˜ê°€ ë°œìƒí•˜ê¸° ì‹œì‘í•  ê²ƒì…ë‹ˆë‹¤.

ëª¨ë¸ì˜ ì¶œë ¥ì„ ê°œì„ í•˜ê¸° ìœ„í•œ ì „ëµì„ ì¶”ê°€í•  ì¤€ë¹„ê°€ í•„ìš”í•©ë‹ˆë‹¤; ì˜ˆë¥¼ ë“¤ì–´,

1. ëª‡ ê°€ì§€ ìƒ· ì˜ˆì œë¥¼ ì œê³µí•˜ì‹­ì‹œì˜¤.
2. ì˜¤ë¥˜ ì²˜ë¦¬ë¥¼ ì¶”ê°€í•˜ì‹­ì‹œì˜¤ (ì˜ˆ: ì˜ˆì™¸ë¥¼ í¬ì°©í•˜ê³  ì´ë¥¼ LLMì— í”¼ë“œë°±í•˜ì—¬ ì´ì „ ì¶œë ¥ì„ ìˆ˜ì •í•˜ë„ë¡ ìš”ì²­).