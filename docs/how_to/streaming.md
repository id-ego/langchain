---
custom_edit_url: https://github.com/langchain-ai/langchain/edit/master/docs/docs/how_to/streaming.ipynb
description: ì´ ë¬¸ì„œëŠ” LLM ê¸°ë°˜ ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ë°˜ì‘ì„±ì„ ë†’ì´ê¸° ìœ„í•œ ìŠ¤íŠ¸ë¦¬ë° ì‹¤í–‰ ë°©ë²•ê³¼ LangChainì˜ ëŸ°ë„ˆë¸” ì¸í„°í˜ì´ìŠ¤ë¥¼ ì„¤ëª…í•©ë‹ˆë‹¤.
keywords:
- stream
---

# ì‹¤í–‰ ê°€ëŠ¥í•œ ìŠ¤íŠ¸ë¦¬ë° ë°©ë²•

:::info ì „ì œ ì¡°ê±´

ì´ ê°€ì´ë“œëŠ” ë‹¤ìŒ ê°œë…ì— ëŒ€í•œ ì´í•´ë¥¼ ì „ì œë¡œ í•©ë‹ˆë‹¤:
- [ì±„íŒ… ëª¨ë¸](/docs/concepts/#chat-models)
- [LangChain í‘œí˜„ ì–¸ì–´](/docs/concepts/#langchain-expression-language)
- [ì¶œë ¥ íŒŒì„œ](/docs/concepts/#output-parsers)

:::

ìŠ¤íŠ¸ë¦¬ë°ì€ LLM ê¸°ë°˜ ì• í”Œë¦¬ì¼€ì´ì…˜ì´ ìµœì¢… ì‚¬ìš©ìì—ê²Œ ë°˜ì‘í•˜ëŠ” ëŠë‚Œì„ ì£¼ëŠ” ë° ì¤‘ìš”í•©ë‹ˆë‹¤.

[ì±„íŒ… ëª¨ë¸](/docs/concepts/#chat-models), [ì¶œë ¥ íŒŒì„œ](/docs/concepts/#output-parsers), [í”„ë¡¬í”„íŠ¸](/docs/concepts/#prompt-templates), [ê²€ìƒ‰ê¸°](/docs/concepts/#retrievers), [ì—ì´ì „íŠ¸](/docs/concepts/#agents)ì™€ ê°™ì€ ì¤‘ìš”í•œ LangChain ê¸°ë³¸ ìš”ì†Œë“¤ì€ LangChain [Runnable ì¸í„°í˜ì´ìŠ¤](/docs/concepts#interface)ë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤.

ì´ ì¸í„°í˜ì´ìŠ¤ëŠ” ì½˜í…ì¸ ë¥¼ ìŠ¤íŠ¸ë¦¬ë°í•˜ëŠ” ë‘ ê°€ì§€ ì¼ë°˜ì ì¸ ì ‘ê·¼ ë°©ì‹ì„ ì œê³µí•©ë‹ˆë‹¤:

1. ë™ê¸° `stream` ë° ë¹„ë™ê¸° `astream`: ì²´ì¸ì—ì„œ **ìµœì¢… ì¶œë ¥**ì„ ìŠ¤íŠ¸ë¦¬ë°í•˜ëŠ” **ê¸°ë³¸ êµ¬í˜„**ì…ë‹ˆë‹¤.
2. ë¹„ë™ê¸° `astream_events` ë° ë¹„ë™ê¸° `astream_log`: ì´ë“¤ì€ ì²´ì¸ì—ì„œ **ì¤‘ê°„ ë‹¨ê³„**ì™€ **ìµœì¢… ì¶œë ¥**ì„ ëª¨ë‘ ìŠ¤íŠ¸ë¦¬ë°í•˜ëŠ” ë°©ë²•ì„ ì œê³µí•©ë‹ˆë‹¤.

ë‘ ê°€ì§€ ì ‘ê·¼ ë°©ì‹ì„ ì‚´í´ë³´ê³  ì´ë¥¼ ì‚¬ìš©í•˜ëŠ” ë°©ë²•ì„ ì´í•´í•´ ë³´ê² ìŠµë‹ˆë‹¤.

:::info
LangChainì˜ ìŠ¤íŠ¸ë¦¬ë° ê¸°ìˆ ì— ëŒ€í•œ ë” ë†’ì€ ìˆ˜ì¤€ì˜ ê°œìš”ëŠ” [ê°œë… ê°€ì´ë“œì˜ ì´ ì„¹ì…˜](/docs/concepts/#streaming)ì„ ì°¸ì¡°í•˜ì‹­ì‹œì˜¤.
:::

## ìŠ¤íŠ¸ë¦¼ ì‚¬ìš©í•˜ê¸°

ëª¨ë“  `Runnable` ê°ì²´ëŠ” `stream`ì´ë¼ëŠ” ë™ê¸° ë©”ì„œë“œì™€ `astream`ì´ë¼ëŠ” ë¹„ë™ê¸° ë³€í˜•ì„ êµ¬í˜„í•©ë‹ˆë‹¤.

ì´ ë©”ì„œë“œëŠ” ìµœì¢… ì¶œë ¥ì„ ì²­í¬ë¡œ ìŠ¤íŠ¸ë¦¬ë°í•˜ë„ë¡ ì„¤ê³„ë˜ì—ˆìœ¼ë©°, ê° ì²­í¬ê°€ ì‚¬ìš© ê°€ëŠ¥í•´ì§€ëŠ” ì¦‰ì‹œ ì´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.

ìŠ¤íŠ¸ë¦¬ë°ì€ í”„ë¡œê·¸ë¨ì˜ ëª¨ë“  ë‹¨ê³„ê°€ **ì…ë ¥ ìŠ¤íŠ¸ë¦¼**ì„ ì²˜ë¦¬í•˜ëŠ” ë°©ë²•ì„ ì•Œê³  ìˆì„ ë•Œë§Œ ê°€ëŠ¥í•©ë‹ˆë‹¤; ì¦‰, ì…ë ¥ ì²­í¬ë¥¼ í•˜ë‚˜ì”© ì²˜ë¦¬í•˜ê³  í•´ë‹¹ ì¶œë ¥ ì²­í¬ë¥¼ ë°˜í™˜í•´ì•¼ í•©ë‹ˆë‹¤.

ì´ ì²˜ë¦¬ì˜ ë³µì¡ì„±ì€ LLMì´ ìƒì„±í•œ í† í°ì„ ë°©ì¶œí•˜ëŠ” ê²ƒê³¼ ê°™ì€ ê°„ë‹¨í•œ ì‘ì—…ì—ì„œë¶€í„° ì „ì²´ JSONì´ ì™„ë£Œë˜ê¸° ì „ì— JSON ê²°ê³¼ì˜ ì¼ë¶€ë¥¼ ìŠ¤íŠ¸ë¦¬ë°í•˜ëŠ” ê²ƒê³¼ ê°™ì€ ë” ë„ì „ì ì¸ ì‘ì—…ê¹Œì§€ ë‹¤ì–‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ìŠ¤íŠ¸ë¦¬ë°ì„ íƒìƒ‰í•˜ê¸° ì‹œì‘í•˜ëŠ” ê°€ì¥ ì¢‹ì€ ì¥ì†ŒëŠ” LLM ì• í”Œë¦¬ì¼€ì´ì…˜ì—ì„œ ê°€ì¥ ì¤‘ìš”í•œ êµ¬ì„± ìš”ì†Œì¸ LLM ìì²´ì…ë‹ˆë‹¤!

### LLM ë° ì±„íŒ… ëª¨ë¸

ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ê³¼ ê·¸ ì±„íŒ… ë³€í˜•ì€ LLM ê¸°ë°˜ ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ì£¼ìš” ë³‘ëª© í˜„ìƒì…ë‹ˆë‹¤.

ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ì€ ì¿¼ë¦¬ì— ëŒ€í•œ ì™„ì „í•œ ì‘ë‹µì„ ìƒì„±í•˜ëŠ” ë° **ìˆ˜ ì´ˆ**ê°€ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” ì• í”Œë¦¬ì¼€ì´ì…˜ì´ ìµœì¢… ì‚¬ìš©ìì—ê²Œ ë°˜ì‘í•˜ëŠ” ëŠë‚Œì„ ì£¼ëŠ” **~200-300 ms** ì„ê³„ê°’ë³´ë‹¤ í›¨ì”¬ ëŠë¦½ë‹ˆë‹¤.

ì• í”Œë¦¬ì¼€ì´ì…˜ì´ ë” ë°˜ì‘ì ìœ¼ë¡œ ëŠê»´ì§€ë„ë¡ í•˜ëŠ” í•µì‹¬ ì „ëµì€ ì¤‘ê°„ ì§„í–‰ ìƒí™©ì„ ë³´ì—¬ì£¼ëŠ” ê²ƒì…ë‹ˆë‹¤; ì¦‰, ëª¨ë¸ì˜ ì¶œë ¥ì„ **í† í° ë‹¨ìœ„ë¡œ** ìŠ¤íŠ¸ë¦¬ë°í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

ì±„íŒ… ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ìŠ¤íŠ¸ë¦¬ë° ì˜ˆì œë¥¼ ë³´ì—¬ë“œë¦¬ê² ìŠµë‹ˆë‹¤. ì•„ë˜ ì˜µì…˜ ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒí•˜ì„¸ìš”:

import ChatModelTabs from "@theme/ChatModelTabs";

<ChatModelTabs
customVarName="model"
/>

ë™ê¸° `stream` APIë¶€í„° ì‹œì‘í•´ ë³´ê² ìŠµë‹ˆë‹¤:

```python
chunks = []
for chunk in model.stream("what color is the sky?"):
    chunks.append(chunk)
    print(chunk.content, end="|", flush=True)
```

```output
The| sky| appears| blue| during| the| day|.|
```

ëŒ€ì•ˆìœ¼ë¡œ ë¹„ë™ê¸° í™˜ê²½ì—ì„œ ì‘ì—…í•˜ëŠ” ê²½ìš° ë¹„ë™ê¸° `astream` APIë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì„ ê³ ë ¤í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```python
chunks = []
async for chunk in model.astream("what color is the sky?"):
    chunks.append(chunk)
    print(chunk.content, end="|", flush=True)
```

```output
The| sky| appears| blue| during| the| day|.|
```

ì²­í¬ ì¤‘ í•˜ë‚˜ë¥¼ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤

```python
chunks[0]
```


```output
AIMessageChunk(content='The', id='run-b36bea64-5511-4d7a-b6a3-a07b3db0c8e7')
```


ìš°ë¦¬ëŠ” `AIMessageChunk`ë¼ëŠ” ê²ƒì„ ë°›ì•˜ìŠµë‹ˆë‹¤. ì´ ì²­í¬ëŠ” `AIMessage`ì˜ ì¼ë¶€ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.

ë©”ì‹œì§€ ì²­í¬ëŠ” ì„¤ê³„ìƒ ì¶”ê°€ì ì…ë‹ˆë‹¤ -- ë‹¨ìˆœíˆ ë”í•˜ì—¬ ì§€ê¸ˆê¹Œì§€ì˜ ì‘ë‹µ ìƒíƒœë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤!

```python
chunks[0] + chunks[1] + chunks[2] + chunks[3] + chunks[4]
```


```output
AIMessageChunk(content='The sky appears blue during', id='run-b36bea64-5511-4d7a-b6a3-a07b3db0c8e7')
```


### ì²´ì¸

ì‚¬ì‹¤ìƒ ëª¨ë“  LLM ì• í”Œë¦¬ì¼€ì´ì…˜ì€ ì–¸ì–´ ëª¨ë¸ì— ëŒ€í•œ í˜¸ì¶œ ì´ìƒì˜ ë‹¨ê³„ë¥¼ í¬í•¨í•©ë‹ˆë‹¤.

í”„ë¡¬í”„íŠ¸, ëª¨ë¸ ë° íŒŒì„œë¥¼ ê²°í•©í•˜ì—¬ ìŠ¤íŠ¸ë¦¬ë°ì´ ì‘ë™í•˜ëŠ”ì§€ í™•ì¸í•˜ëŠ” ê°„ë‹¨í•œ ì²´ì¸ì„ `LangChain í‘œí˜„ ì–¸ì–´`(`LCEL`)ë¥¼ ì‚¬ìš©í•˜ì—¬ êµ¬ì¶•í•´ ë³´ê² ìŠµë‹ˆë‹¤.

ìš°ë¦¬ëŠ” [`StrOutputParser`](https://api.python.langchain.com/en/latest/output_parsers/langchain_core.output_parsers.string.StrOutputParser.html)ë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì˜ ì¶œë ¥ì„ íŒŒì‹±í•  ê²ƒì…ë‹ˆë‹¤. ì´ëŠ” `AIMessageChunk`ì—ì„œ `content` í•„ë“œë¥¼ ì¶”ì¶œí•˜ì—¬ ëª¨ë¸ì´ ë°˜í™˜í•œ `token`ì„ ì œê³µí•©ë‹ˆë‹¤.

:::tip
LCELì€ ë‹¤ì–‘í•œ LangChain ê¸°ë³¸ ìš”ì†Œë¥¼ ì—°ê²°í•˜ì—¬ "í”„ë¡œê·¸ë¨"ì„ ì§€ì •í•˜ëŠ” *ì„ ì–¸ì * ë°©ë²•ì…ë‹ˆë‹¤. LCELì„ ì‚¬ìš©í•˜ì—¬ ìƒì„±ëœ ì²´ì¸ì€ ìµœì¢… ì¶œì¶œì˜ ìŠ¤íŠ¸ë¦¬ë°ì„ í—ˆìš©í•˜ëŠ” `stream` ë° `astream`ì˜ ìë™ êµ¬í˜„ì˜ ì´ì ì„ ëˆ„ë¦½ë‹ˆë‹¤. ì‹¤ì œë¡œ LCELë¡œ ìƒì„±ëœ ì²´ì¸ì€ ì „ì²´ í‘œì¤€ Runnable ì¸í„°í˜ì´ìŠ¤ë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤.
:::

```python
<!--IMPORTS:[{"imported": "StrOutputParser", "source": "langchain_core.output_parsers", "docs": "https://api.python.langchain.com/en/latest/output_parsers/langchain_core.output_parsers.string.StrOutputParser.html", "title": "How to stream runnables"}, {"imported": "ChatPromptTemplate", "source": "langchain_core.prompts", "docs": "https://api.python.langchain.com/en/latest/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html", "title": "How to stream runnables"}]-->
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate

prompt = ChatPromptTemplate.from_template("tell me a joke about {topic}")
parser = StrOutputParser()
chain = prompt | model | parser

async for chunk in chain.astream({"topic": "parrot"}):
    print(chunk, end="|", flush=True)
```

```output
Here|'s| a| joke| about| a| par|rot|:|

A man| goes| to| a| pet| shop| to| buy| a| par|rot|.| The| shop| owner| shows| him| two| stunning| pa|rr|ots| with| beautiful| pl|um|age|.|

"|There|'s| a| talking| par|rot| an|d a| non|-|talking| par|rot|,"| the| owner| says|.| "|The| talking| par|rot| costs| $|100|,| an|d the| non|-|talking| par|rot| is| $|20|."|

The| man| says|,| "|I|'ll| take| the| non|-|talking| par|rot| at| $|20|."|

He| pays| an|d leaves| with| the| par|rot|.| As| he|'s| walking| down| the| street|,| the| par|rot| looks| up| at| him| an|d says|,| "|You| know|,| you| really| are| a| stupi|d man|!"|

The| man| is| stun|ne|d an|d looks| at| the| par|rot| in| dis|bel|ief|.| The| par|rot| continues|,| "|Yes|,| you| got| r|ippe|d off| big| time|!| I| can| talk| just| as| well| as| that| other| par|rot|,| an|d you| only| pai|d $|20| |for| me|!"|
```

ìœ„ì˜ ì²´ì¸ ëì—ì„œ `parser`ë¥¼ ì‚¬ìš©í•˜ê³  ìˆìŒì—ë„ ë¶ˆêµ¬í•˜ê³  ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥ì„ ë°›ê³  ìˆë‹¤ëŠ” ì ì— ìœ ì˜í•˜ì‹­ì‹œì˜¤. `parser`ëŠ” ê° ìŠ¤íŠ¸ë¦¬ë° ì²­í¬ë¥¼ ê°œë³„ì ìœ¼ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤. ë§ì€ [LCEL ê¸°ë³¸ ìš”ì†Œ](/docs/how_to#langchain-expression-language-lcel)ë„ ì´ëŸ¬í•œ ë³€í™˜ ìŠ¤íƒ€ì¼ì˜ í†µê³¼ ìŠ¤íŠ¸ë¦¬ë°ì„ ì§€ì›í•˜ë©°, ì´ëŠ” ì• í”Œë¦¬ì¼€ì´ì…˜ì„ êµ¬ì„±í•  ë•Œ ë§¤ìš° í¸ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ì‚¬ìš©ì ì •ì˜ í•¨ìˆ˜ëŠ” [ì œë„ˆë ˆì´í„°ë¥¼ ë°˜í™˜í•˜ë„ë¡ ì„¤ê³„ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤](/docs/how_to/functions#streaming), ì´ëŠ” ìŠ¤íŠ¸ë¦¼ì—ì„œ ì‘ë™í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ì¼ë¶€ ì‹¤í–‰ ê°€ëŠ¥ ìš”ì†Œ, ì˜ˆë¥¼ ë“¤ì–´ [í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿](/docs/how_to#prompt-templates) ë° [ì±„íŒ… ëª¨ë¸](/docs/how_to#chat-models)ì€ ê°œë³„ ì²­í¬ë¥¼ ì²˜ë¦¬í•  ìˆ˜ ì—†ìœ¼ë©° ëŒ€ì‹  ëª¨ë“  ì´ì „ ë‹¨ê³„ë¥¼ ì§‘ê³„í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ì‹¤í–‰ ê°€ëŠ¥ ìš”ì†ŒëŠ” ìŠ¤íŠ¸ë¦¬ë° í”„ë¡œì„¸ìŠ¤ë¥¼ ì¤‘ë‹¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

:::note
LangChain í‘œí˜„ ì–¸ì–´ëŠ” ì²´ì¸ì˜ êµ¬ì„±ê³¼ ì‚¬ìš© ëª¨ë“œ(ì˜ˆ: ë™ê¸°/ë¹„ë™ê¸°, ë°°ì¹˜/ìŠ¤íŠ¸ë¦¬ë° ë“±)ë¥¼ ë¶„ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ê²ƒì´ ë‹¹ì‹ ì´ êµ¬ì¶•í•˜ëŠ” ê²ƒê³¼ ê´€ë ¨ì´ ì—†ë‹¤ë©´, ê° êµ¬ì„± ìš”ì†Œì— ëŒ€í•´ `invoke`, `batch` ë˜ëŠ” `stream`ì„ í˜¸ì¶œí•˜ì—¬ í‘œì¤€ **ëª…ë ¹í˜•** í”„ë¡œê·¸ë˜ë° ì ‘ê·¼ ë°©ì‹ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìœ¼ë©°, ê²°ê³¼ë¥¼ ë³€ìˆ˜ì— í• ë‹¹í•œ ë‹¤ìŒ í•„ìš”ì— ë”°ë¼ í•˜ë¥˜ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
:::

### ì…ë ¥ ìŠ¤íŠ¸ë¦¼ ì‘ì—…í•˜ê¸°

ì¶œë ¥ì´ ìƒì„±ë˜ëŠ” ë™ì•ˆ JSONì„ ìŠ¤íŠ¸ë¦¬ë°í•˜ê³  ì‹¶ë‹¤ë©´ ì–´ë–»ê²Œ í•´ì•¼ í• ê¹Œìš”?

`json.loads`ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¶€ë¶„ JSONì„ íŒŒì‹±í•˜ë ¤ê³  í•˜ë©´, ë¶€ë¶„ JSONì´ ìœ íš¨í•œ JSONì´ ì•„ë‹ˆê¸° ë•Œë¬¸ì— íŒŒì‹±ì´ ì‹¤íŒ¨í•  ê²ƒì…ë‹ˆë‹¤.

ë‹¹ì‹ ì€ ì•„ë§ˆë„ ë¬´ì—‡ì„ í•´ì•¼ í• ì§€ ì™„ì „íˆ ë§‰ë§‰í•´ì§ˆ ê²ƒì´ë©° JSONì„ ìŠ¤íŠ¸ë¦¬ë°í•˜ëŠ” ê²ƒì´ ë¶ˆê°€ëŠ¥í•˜ë‹¤ê³  ì£¼ì¥í•  ê²ƒì…ë‹ˆë‹¤.

í•˜ì§€ë§Œ, ë°©ë²•ì´ ìˆìŠµë‹ˆë‹¤ -- íŒŒì„œëŠ” **ì…ë ¥ ìŠ¤íŠ¸ë¦¼**ì—ì„œ ì‘ë™í•´ì•¼ í•˜ë©°, ë¶€ë¶„ JSONì„ ìœ íš¨í•œ ìƒíƒœë¡œ "ìë™ ì™„ì„±"í•˜ë ¤ê³  ì‹œë„í•´ì•¼ í•©ë‹ˆë‹¤.

ì´ê²ƒì´ ì˜ë¯¸í•˜ëŠ” ë°”ë¥¼ ì´í•´í•˜ê¸° ìœ„í•´ ì´ëŸ¬í•œ íŒŒì„œë¥¼ ì‹¤ì œë¡œ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤.

```python
<!--IMPORTS:[{"imported": "JsonOutputParser", "source": "langchain_core.output_parsers", "docs": "https://api.python.langchain.com/en/latest/output_parsers/langchain_core.output_parsers.json.JsonOutputParser.html", "title": "How to stream runnables"}]-->
from langchain_core.output_parsers import JsonOutputParser

chain = (
    model | JsonOutputParser()
)  # Due to a bug in older versions of Langchain, JsonOutputParser did not stream results from some models
async for text in chain.astream(
    "output a list of the countries france, spain and japan and their populations in JSON format. "
    'Use a dict with an outer key of "countries" which contains a list of countries. '
    "Each country should have the key `name` and `population`"
):
    print(text, flush=True)
```

```output
{}
{'countries': []}
{'countries': [{}]}
{'countries': [{'name': ''}]}
{'countries': [{'name': 'France'}]}
{'countries': [{'name': 'France', 'population': 67}]}
{'countries': [{'name': 'France', 'population': 67413}]}
{'countries': [{'name': 'France', 'population': 67413000}]}
{'countries': [{'name': 'France', 'population': 67413000}, {}]}
{'countries': [{'name': 'France', 'population': 67413000}, {'name': ''}]}
{'countries': [{'name': 'France', 'population': 67413000}, {'name': 'Spain'}]}
{'countries': [{'name': 'France', 'population': 67413000}, {'name': 'Spain', 'population': 47}]}
{'countries': [{'name': 'France', 'population': 67413000}, {'name': 'Spain', 'population': 47351}]}
{'countries': [{'name': 'France', 'population': 67413000}, {'name': 'Spain', 'population': 47351567}]}
{'countries': [{'name': 'France', 'population': 67413000}, {'name': 'Spain', 'population': 47351567}, {}]}
{'countries': [{'name': 'France', 'population': 67413000}, {'name': 'Spain', 'population': 47351567}, {'name': ''}]}
{'countries': [{'name': 'France', 'population': 67413000}, {'name': 'Spain', 'population': 47351567}, {'name': 'Japan'}]}
{'countries': [{'name': 'France', 'population': 67413000}, {'name': 'Spain', 'population': 47351567}, {'name': 'Japan', 'population': 125}]}
{'countries': [{'name': 'France', 'population': 67413000}, {'name': 'Spain', 'population': 47351567}, {'name': 'Japan', 'population': 125584}]}
{'countries': [{'name': 'France', 'population': 67413000}, {'name': 'Spain', 'population': 47351567}, {'name': 'Japan', 'population': 125584000}]}
```

ì´ì œ ìŠ¤íŠ¸ë¦¬ë°ì„ **ì¤‘ë‹¨**í•´ ë³´ê² ìŠµë‹ˆë‹¤. ì´ì „ ì˜ˆì œë¥¼ ì‚¬ìš©í•˜ê³  ìµœì¢… JSONì—ì„œ êµ­ê°€ ì´ë¦„ì„ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜ë¥¼ ëì— ì¶”ê°€í•˜ê² ìŠµë‹ˆë‹¤.

:::warning
ì²´ì¸ì—ì„œ **ìµœì¢…í™”ëœ ì…ë ¥**ì—ì„œ ì‘ë™í•˜ëŠ” ëª¨ë“  ë‹¨ê³„ëŠ” `stream` ë˜ëŠ” `astream`ì„ í†µí•´ ìŠ¤íŠ¸ë¦¬ë° ê¸°ëŠ¥ì„ ì¤‘ë‹¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
:::

:::tip
ë‚˜ì¤‘ì— ì¤‘ê°„ ë‹¨ê³„ì—ì„œ ê²°ê³¼ë¥¼ ìŠ¤íŠ¸ë¦¬ë°í•˜ëŠ” `astream_events` APIì— ëŒ€í•´ ë…¼ì˜í•  ê²ƒì…ë‹ˆë‹¤. ì´ APIëŠ” ì²´ì¸ì— **ìµœì¢…í™”ëœ ì…ë ¥**ì—ì„œë§Œ ì‘ë™í•˜ëŠ” ë‹¨ê³„ê°€ í¬í•¨ë˜ì–´ ìˆë”ë¼ë„ ì¤‘ê°„ ë‹¨ê³„ì—ì„œ ê²°ê³¼ë¥¼ ìŠ¤íŠ¸ë¦¬ë°í•©ë‹ˆë‹¤.
:::

```python
<!--IMPORTS:[{"imported": "JsonOutputParser", "source": "langchain_core.output_parsers", "docs": "https://api.python.langchain.com/en/latest/output_parsers/langchain_core.output_parsers.json.JsonOutputParser.html", "title": "How to stream runnables"}]-->
from langchain_core.output_parsers import (
    JsonOutputParser,
)


# A function that operates on finalized inputs
# rather than on an input_stream
def _extract_country_names(inputs):
    """A function that does not operates on input streams and breaks streaming."""
    if not isinstance(inputs, dict):
        return ""

    if "countries" not in inputs:
        return ""

    countries = inputs["countries"]

    if not isinstance(countries, list):
        return ""

    country_names = [
        country.get("name") for country in countries if isinstance(country, dict)
    ]
    return country_names


chain = model | JsonOutputParser() | _extract_country_names

async for text in chain.astream(
    "output a list of the countries france, spain and japan and their populations in JSON format. "
    'Use a dict with an outer key of "countries" which contains a list of countries. '
    "Each country should have the key `name` and `population`"
):
    print(text, end="|", flush=True)
```

```output
['France', 'Spain', 'Japan']|
```

#### ì œë„ˆë ˆì´í„° í•¨ìˆ˜

ì…ë ¥ ìŠ¤íŠ¸ë¦¼ì—ì„œ ì‘ë™í•  ìˆ˜ ìˆëŠ” ì œë„ˆë ˆì´í„° í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ìŠ¤íŠ¸ë¦¬ë°ì„ ìˆ˜ì •í•´ ë³´ê² ìŠµë‹ˆë‹¤.

:::tip
ì œë„ˆë ˆì´í„° í•¨ìˆ˜(ì¦‰, `yield`ë¥¼ ì‚¬ìš©í•˜ëŠ” í•¨ìˆ˜)ëŠ” **ì…ë ¥ ìŠ¤íŠ¸ë¦¼**ì—ì„œ ì‘ë™í•˜ëŠ” ì½”ë“œë¥¼ ì‘ì„±í•  ìˆ˜ ìˆê²Œ í•´ì¤ë‹ˆë‹¤.
:::

```python
<!--IMPORTS:[{"imported": "JsonOutputParser", "source": "langchain_core.output_parsers", "docs": "https://api.python.langchain.com/en/latest/output_parsers/langchain_core.output_parsers.json.JsonOutputParser.html", "title": "How to stream runnables"}]-->
from langchain_core.output_parsers import JsonOutputParser


async def _extract_country_names_streaming(input_stream):
    """A function that operates on input streams."""
    country_names_so_far = set()

    async for input in input_stream:
        if not isinstance(input, dict):
            continue

        if "countries" not in input:
            continue

        countries = input["countries"]

        if not isinstance(countries, list):
            continue

        for country in countries:
            name = country.get("name")
            if not name:
                continue
            if name not in country_names_so_far:
                yield name
                country_names_so_far.add(name)


chain = model | JsonOutputParser() | _extract_country_names_streaming

async for text in chain.astream(
    "output a list of the countries france, spain and japan and their populations in JSON format. "
    'Use a dict with an outer key of "countries" which contains a list of countries. '
    "Each country should have the key `name` and `population`",
):
    print(text, end="|", flush=True)
```

```output
France|Spain|Japan|
```

:::note
ìœ„ì˜ ì½”ë“œëŠ” JSON ìë™ ì™„ì„±ì— ì˜ì¡´í•˜ê³  ìˆê¸° ë•Œë¬¸ì— êµ­ê°€ì˜ ë¶€ë¶„ ì´ë¦„(ì˜ˆ: `Sp`ì™€ `Spain`)ì´ í‘œì‹œë  ìˆ˜ ìˆìœ¼ë©°, ì´ëŠ” ì¶”ì¶œ ê²°ê³¼ë¡œ ì›í•˜ëŠ” ê²ƒì´ ì•„ë‹™ë‹ˆë‹¤!

ìš°ë¦¬ëŠ” ìŠ¤íŠ¸ë¦¬ë° ê°œë…ì— ì§‘ì¤‘í•˜ê³  ìˆìœ¼ë©°, ì²´ì¸ì˜ ê²°ê³¼ëŠ” ë°˜ë“œì‹œ í¬í•¨ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
:::

### ë¹„ìŠ¤íŠ¸ë¦¬ë° êµ¬ì„± ìš”ì†Œ

ê²€ìƒ‰ê¸°ì™€ ê°™ì€ ì¼ë¶€ ë‚´ì¥ êµ¬ì„± ìš”ì†ŒëŠ” `ìŠ¤íŠ¸ë¦¬ë°`ì„ ì œê³µí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì´ë“¤ì„ `stream`í•˜ë ¤ê³  í•˜ë©´ ì–´ë–»ê²Œ ë ê¹Œìš”? ğŸ¤¨

```python
<!--IMPORTS:[{"imported": "FAISS", "source": "langchain_community.vectorstores", "docs": "https://api.python.langchain.com/en/latest/vectorstores/langchain_community.vectorstores.faiss.FAISS.html", "title": "How to stream runnables"}, {"imported": "StrOutputParser", "source": "langchain_core.output_parsers", "docs": "https://api.python.langchain.com/en/latest/output_parsers/langchain_core.output_parsers.string.StrOutputParser.html", "title": "How to stream runnables"}, {"imported": "ChatPromptTemplate", "source": "langchain_core.prompts", "docs": "https://api.python.langchain.com/en/latest/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html", "title": "How to stream runnables"}, {"imported": "RunnablePassthrough", "source": "langchain_core.runnables", "docs": "https://api.python.langchain.com/en/latest/runnables/langchain_core.runnables.passthrough.RunnablePassthrough.html", "title": "How to stream runnables"}, {"imported": "OpenAIEmbeddings", "source": "langchain_openai", "docs": "https://api.python.langchain.com/en/latest/embeddings/langchain_openai.embeddings.base.OpenAIEmbeddings.html", "title": "How to stream runnables"}]-->
from langchain_community.vectorstores import FAISS
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain_openai import OpenAIEmbeddings

template = """Answer the question based only on the following context:
{context}

Question: {question}
"""
prompt = ChatPromptTemplate.from_template(template)

vectorstore = FAISS.from_texts(
    ["harrison worked at kensho", "harrison likes spicy food"],
    embedding=OpenAIEmbeddings(),
)
retriever = vectorstore.as_retriever()

chunks = [chunk for chunk in retriever.stream("where did harrison work?")]
chunks
```


```output
[[Document(page_content='harrison worked at kensho'),
  Document(page_content='harrison likes spicy food')]]
```


ìŠ¤íŠ¸ë¦¼ì€ í•´ë‹¹ êµ¬ì„± ìš”ì†Œì—ì„œ ìµœì¢… ê²°ê³¼ë¥¼ ë°˜í™˜í–ˆìŠµë‹ˆë‹¤.

ê´œì°®ìŠµë‹ˆë‹¤ ğŸ¥¹! ëª¨ë“  êµ¬ì„± ìš”ì†Œê°€ ìŠ¤íŠ¸ë¦¬ë°ì„ êµ¬í˜„í•´ì•¼ í•˜ëŠ” ê²ƒì€ ì•„ë‹™ë‹ˆë‹¤ -- ê²½ìš°ì— ë”°ë¼ ìŠ¤íŠ¸ë¦¬ë°ì€ ë¶ˆí•„ìš”í•˜ê±°ë‚˜ ì–´ë µê±°ë‚˜ ê·¸ì € ì˜ë¯¸ê°€ ì—†ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

:::tip
ë¹„ìŠ¤íŠ¸ë¦¬ë° êµ¬ì„± ìš”ì†Œë¥¼ ì‚¬ìš©í•˜ì—¬ êµ¬ì„±ëœ LCEL ì²´ì¸ì€ ì—¬ì „íˆ ë§ì€ ê²½ìš°ì— ìŠ¤íŠ¸ë¦¬ë°í•  ìˆ˜ ìˆìœ¼ë©°, ì²´ì¸ì—ì„œ ë§ˆì§€ë§‰ ë¹„ìŠ¤íŠ¸ë¦¬ë° ë‹¨ê³„ ì´í›„ì— ë¶€ë¶„ ì¶œë ¥ì„ ìŠ¤íŠ¸ë¦¬ë°í•˜ê¸° ì‹œì‘í•©ë‹ˆë‹¤.
:::

```python
retrieval_chain = (
    {
        "context": retriever.with_config(run_name="Docs"),
        "question": RunnablePassthrough(),
    }
    | prompt
    | model
    | StrOutputParser()
)
```


```python
for chunk in retrieval_chain.stream(
    "Where did harrison work? " "Write 3 made up sentences about this place."
):
    print(chunk, end="|", flush=True)
```

```output
Base|d on| the| given| context|,| Harrison| worke|d at| K|ens|ho|.|

Here| are| |3| |made| up| sentences| about| this| place|:|

1|.| K|ens|ho| was| a| cutting|-|edge| technology| company| known| for| its| innovative| solutions| in| artificial| intelligence| an|d data| analytics|.|

2|.| The| modern| office| space| at| K|ens|ho| feature|d open| floor| plans|,| collaborative| work|sp|aces|,| an|d a| vib|rant| atmosphere| that| fos|tere|d creativity| an|d team|work|.|

3|.| With| its| prime| location| in| the| heart| of| the| city|,| K|ens|ho| attracte|d top| talent| from| aroun|d the| worl|d,| creating| a| diverse| an|d dynamic| work| environment|.|
```

ì´ì œ `stream`ê³¼ `astream`ì´ ì–´ë–»ê²Œ ì‘ë™í•˜ëŠ”ì§€ ì‚´í´ë³´ì•˜ìœ¼ë‹ˆ, ìŠ¤íŠ¸ë¦¬ë° ì´ë²¤íŠ¸ì˜ ì„¸ê³„ë¡œ ë‚˜ì•„ê°€ ë³´ê² ìŠµë‹ˆë‹¤. ğŸï¸

## ìŠ¤íŠ¸ë¦¼ ì´ë²¤íŠ¸ ì‚¬ìš©í•˜ê¸°

ì´ë²¤íŠ¸ ìŠ¤íŠ¸ë¦¬ë°ì€ **ë² íƒ€** APIì…ë‹ˆë‹¤. ì´ APIëŠ” í”¼ë“œë°±ì— ë”°ë¼ ì•½ê°„ ë³€ê²½ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

:::note

ì´ ê°€ì´ë“œëŠ” `V2` APIë¥¼ ë³´ì—¬ì£¼ë©° langchain-core >= 0.2ê°€ í•„ìš”í•©ë‹ˆë‹¤. ì´ì „ ë²„ì „ì˜ LangChainê³¼ í˜¸í™˜ë˜ëŠ” `V1` APIëŠ” [ì—¬ê¸°](https://python.langchain.com/v0.1/docs/expression_language/streaming/#using-stream-events)ë¥¼ ì°¸ì¡°í•˜ì‹­ì‹œì˜¤.
:::

```python
import langchain_core

langchain_core.__version__
```


`astream_events` APIê°€ ì œëŒ€ë¡œ ì‘ë™í•˜ë ¤ë©´:

* ê°€ëŠ¥í•œ í•œ ì½”ë“œ ì „ë°˜ì— ê±¸ì³ `async`ë¥¼ ì‚¬ìš©í•˜ì‹­ì‹œì˜¤ (ì˜ˆ: ë¹„ë™ê¸° ë„êµ¬ ë“±)
* ì‚¬ìš©ì ì •ì˜ í•¨ìˆ˜/ì‹¤í–‰ ê°€ëŠ¥ ìš”ì†Œë¥¼ ì •ì˜í•  ê²½ìš° ì½œë°±ì„ ì „íŒŒí•˜ì‹­ì‹œì˜¤.
* LCEL ì—†ì´ ì‹¤í–‰ ê°€ëŠ¥ ìš”ì†Œë¥¼ ì‚¬ìš©í•  ë•ŒëŠ” LLMì—ì„œ `.ainvoke` ëŒ€ì‹  `.astream()`ì„ í˜¸ì¶œí•˜ì—¬ LLMì´ í† í°ì„ ìŠ¤íŠ¸ë¦¬ë°í•˜ë„ë¡ ê°•ì œí•˜ì‹­ì‹œì˜¤.
* ì˜ˆìƒëŒ€ë¡œ ì‘ë™í•˜ì§€ ì•ŠëŠ” ê²ƒì´ ìˆë‹¤ë©´ ì•Œë ¤ì£¼ì„¸ìš”! :)

### ì´ë²¤íŠ¸ ì°¸ì¡°

ì•„ë˜ëŠ” ë‹¤ì–‘í•œ Runnable ê°ì²´ì—ì„œ ë°œìƒí•  ìˆ˜ ìˆëŠ” ëª‡ ê°€ì§€ ì´ë²¤íŠ¸ë¥¼ ë³´ì—¬ì£¼ëŠ” ì°¸ì¡° í‘œì…ë‹ˆë‹¤.

:::note
ìŠ¤íŠ¸ë¦¬ë°ì´ ì œëŒ€ë¡œ êµ¬í˜„ë˜ë©´, ì‹¤í–‰ ê°€ëŠ¥ ìš”ì†Œì— ëŒ€í•œ ì…ë ¥ì€ ì…ë ¥ ìŠ¤íŠ¸ë¦¼ì´ ì™„ì „íˆ ì†Œëª¨ëœ í›„ì—ë§Œ ì•Œë ¤ì§‘ë‹ˆë‹¤. ì´ëŠ” `inputs`ê°€ ì¢…ì¢… `end` ì´ë²¤íŠ¸ì—ë§Œ í¬í•¨ë˜ê³  `start` ì´ë²¤íŠ¸ì—ëŠ” í¬í•¨ë˜ì§€ ì•ŠìŒì„ ì˜ë¯¸í•©ë‹ˆë‹¤.
:::

| ì´ë²¤íŠ¸                | ì´ë¦„             | ì²­í¬                           | ì…ë ¥                                         | ì¶œë ¥                                          |
|----------------------|------------------|---------------------------------|-----------------------------------------------|-------------------------------------------------|
| on_chat_model_start  | [ëª¨ë¸ ì´ë¦„]     |                                 | {"messages": [[SystemMessage, HumanMessage]]} |                                                 |
| on_chat_model_stream | [ëª¨ë¸ ì´ë¦„]     | AIMessageChunk(content="hello") |                                               |                                                 |
| on_chat_model_end    | [ëª¨ë¸ ì´ë¦„]     |                                 | {"messages": [[SystemMessage, HumanMessage]]} | AIMessageChunk(content="hello world")           |
| on_llm_start         | [ëª¨ë¸ ì´ë¦„]     |                                 | {'input': 'hello'}                            |                                                 |
| on_llm_stream        | [ëª¨ë¸ ì´ë¦„]     | 'Hello'                         |                                               |                                                 |
| on_llm_end           | [ëª¨ë¸ ì´ë¦„]     |                                 | 'Hello human!'                                |                                                 |
| on_chain_start       | format_docs      |                                 |                                               |                                                 |
| on_chain_stream      | format_docs      | "hello world!, goodbye world!"  |                                               |                                                 |
| on_chain_end         | format_docs      |                                 | [Document(...)]                               | "hello world!, goodbye world!"                  |
| on_tool_start        | some_tool        |                                 | {"x": 1, "y": "2"}                            |                                                 |
| on_tool_end          | some_tool        |                                 |                                               | {"x": 1, "y": "2"}                              |
| on_retriever_start   | [retriever name] |                                 | {"query": "hello"}                            |                                                 |
| on_retriever_end     | [retriever name] |                                 | {"query": "hello"}                            | [Document(...), ..]                             |
| on_prompt_start      | [template_name]  |                                 | {"question": "hello"}                         |                                                 |
| on_prompt_end        | [template_name]  |                                 | {"question": "hello"}                         | ChatPromptValue(messages: [SystemMessage, ...]) |

### ì±„íŒ… ëª¨ë¸

ì±„íŒ… ëª¨ë¸ì—ì„œ ìƒì„±ëœ ì´ë²¤íŠ¸ë¥¼ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤.

```python
events = []
async for event in model.astream_events("hello", version="v2"):
    events.append(event)
```

```output
/home/eugene/src/langchain/libs/core/langchain_core/_api/beta_decorator.py:87: LangChainBetaWarning: This API is in beta and may change in the future.
  warn_beta(
```

:::note

APIì˜ ê·¸ ì¬ë¯¸ìˆëŠ” version="v2" ë§¤ê°œë³€ìˆ˜ëŠ” ë¬´ì—‡ì¸ê°€ìš”?! ğŸ˜¾

ì´ê²ƒì€ **ë² íƒ€ API**ì´ë©°, ìš°ë¦¬ëŠ” ê±°ì˜ í™•ì‹¤íˆ ì´ë¥¼ ë³€ê²½í•  ê²ƒì…ë‹ˆë‹¤ (ì‚¬ì‹¤, ì´ë¯¸ ë³€ê²½í–ˆìŠµë‹ˆë‹¤!)

ì´ ë²„ì „ ë§¤ê°œë³€ìˆ˜ëŠ” ì½”ë“œì— ëŒ€í•œ ì´ëŸ¬í•œ íŒŒê´´ì ì¸ ë³€ê²½ì„ ìµœì†Œí™”í•  ìˆ˜ ìˆê²Œ í•´ì¤ë‹ˆë‹¤.

ê°„ë‹¨íˆ ë§í•´, ìš°ë¦¬ëŠ” ì§€ê¸ˆ ë‹¹ì‹ ì„ ê·€ì°®ê²Œ í•˜ê³  ìˆìœ¼ë¯€ë¡œ, ë‚˜ì¤‘ì— ê·€ì°®ê²Œ í•˜ì§€ ì•Šê¸° ìœ„í•´ì„œì…ë‹ˆë‹¤.

`v2`ëŠ” langchain-core>=0.2.0ì—ì„œë§Œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

:::

ì‹œì‘ ì´ë²¤íŠ¸ ëª‡ ê°œì™€ ì¢…ë£Œ ì´ë²¤íŠ¸ ëª‡ ê°œë¥¼ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤.

```python
events[:3]
```


```output
[{'event': 'on_chat_model_start',
  'data': {'input': 'hello'},
  'name': 'ChatAnthropic',
  'tags': [],
  'run_id': 'a81e4c0f-fc36-4d33-93bc-1ac25b9bb2c3',
  'metadata': {}},
 {'event': 'on_chat_model_stream',
  'data': {'chunk': AIMessageChunk(content='Hello', id='run-a81e4c0f-fc36-4d33-93bc-1ac25b9bb2c3')},
  'run_id': 'a81e4c0f-fc36-4d33-93bc-1ac25b9bb2c3',
  'name': 'ChatAnthropic',
  'tags': [],
  'metadata': {}},
 {'event': 'on_chat_model_stream',
  'data': {'chunk': AIMessageChunk(content='!', id='run-a81e4c0f-fc36-4d33-93bc-1ac25b9bb2c3')},
  'run_id': 'a81e4c0f-fc36-4d33-93bc-1ac25b9bb2c3',
  'name': 'ChatAnthropic',
  'tags': [],
  'metadata': {}}]
```


```python
events[-2:]
```


```output
[{'event': 'on_chat_model_stream',
  'data': {'chunk': AIMessageChunk(content='?', id='run-a81e4c0f-fc36-4d33-93bc-1ac25b9bb2c3')},
  'run_id': 'a81e4c0f-fc36-4d33-93bc-1ac25b9bb2c3',
  'name': 'ChatAnthropic',
  'tags': [],
  'metadata': {}},
 {'event': 'on_chat_model_end',
  'data': {'output': AIMessageChunk(content='Hello! How can I assist you today?', id='run-a81e4c0f-fc36-4d33-93bc-1ac25b9bb2c3')},
  'run_id': 'a81e4c0f-fc36-4d33-93bc-1ac25b9bb2c3',
  'name': 'ChatAnthropic',
  'tags': [],
  'metadata': {}}]
```


### ì²´ì¸

ìŠ¤íŠ¸ë¦¬ë° JSONì„ íŒŒì‹±í•œ ì˜ˆì œ ì²´ì¸ìœ¼ë¡œ ëŒì•„ê°€ ìŠ¤íŠ¸ë¦¬ë° ì´ë²¤íŠ¸ APIë¥¼ íƒìƒ‰í•´ ë³´ê² ìŠµë‹ˆë‹¤.

```python
chain = (
    model | JsonOutputParser()
)  # Due to a bug in older versions of Langchain, JsonOutputParser did not stream results from some models

events = [
    event
    async for event in chain.astream_events(
        "output a list of the countries france, spain and japan and their populations in JSON format. "
        'Use a dict with an outer key of "countries" which contains a list of countries. '
        "Each country should have the key `name` and `population`",
        version="v2",
    )
]
```


ì²˜ìŒ ëª‡ ê°œì˜ ì´ë²¤íŠ¸ë¥¼ ì‚´í´ë³´ë©´, **2**ê°œì˜ ì‹œì‘ ì´ë²¤íŠ¸ê°€ ì•„ë‹Œ **3**ê°œì˜ ì‹œì‘ ì´ë²¤íŠ¸ê°€ ìˆë‹¤ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ì„¸ ê°œì˜ ì‹œì‘ ì´ë²¤íŠ¸ëŠ” ë‹¤ìŒì— í•´ë‹¹í•©ë‹ˆë‹¤:

1. ì²´ì¸ (ëª¨ë¸ + íŒŒì„œ)
2. ëª¨ë¸
3. íŒŒì„œ

```python
events[:3]
```


```output
[{'event': 'on_chain_start',
  'data': {'input': 'output a list of the countries france, spain and japan and their populations in JSON format. Use a dict with an outer key of "countries" which contains a list of countries. Each country should have the key `name` and `population`'},
  'name': 'RunnableSequence',
  'tags': [],
  'run_id': '4765006b-16e2-4b1d-a523-edd9fd64cb92',
  'metadata': {}},
 {'event': 'on_chat_model_start',
  'data': {'input': {'messages': [[HumanMessage(content='output a list of the countries france, spain and japan and their populations in JSON format. Use a dict with an outer key of "countries" which contains a list of countries. Each country should have the key `name` and `population`')]]}},
  'name': 'ChatAnthropic',
  'tags': ['seq:step:1'],
  'run_id': '0320c234-7b52-4a14-ae4e-5f100949e589',
  'metadata': {}},
 {'event': 'on_chat_model_stream',
  'data': {'chunk': AIMessageChunk(content='{', id='run-0320c234-7b52-4a14-ae4e-5f100949e589')},
  'run_id': '0320c234-7b52-4a14-ae4e-5f100949e589',
  'name': 'ChatAnthropic',
  'tags': ['seq:step:1'],
  'metadata': {}}]
```


ë§ˆì§€ë§‰ 3ê°œì˜ ì´ë²¤íŠ¸ë¥¼ ì‚´í´ë³´ë©´ ë¬´ì—‡ì„ ë³´ê²Œ ë ê¹Œìš”? ì¤‘ê°„ì€ ì–´ë–¨ê¹Œìš”?

ì´ APIë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ê³¼ íŒŒì„œì˜ ìŠ¤íŠ¸ë¦¼ ì´ë²¤íŠ¸ ì¶œë ¥ì„ ê°€ì ¸ì˜¤ê² ìŠµë‹ˆë‹¤. ìš°ë¦¬ëŠ” ì‹œì‘ ì´ë²¤íŠ¸, ì¢…ë£Œ ì´ë²¤íŠ¸ ë° ì²´ì¸ì—ì„œì˜ ì´ë²¤íŠ¸ëŠ” ë¬´ì‹œí•˜ê³  ìˆìŠµë‹ˆë‹¤.

```python
num_events = 0

async for event in chain.astream_events(
    "output a list of the countries france, spain and japan and their populations in JSON format. "
    'Use a dict with an outer key of "countries" which contains a list of countries. '
    "Each country should have the key `name` and `population`",
    version="v2",
):
    kind = event["event"]
    if kind == "on_chat_model_stream":
        print(
            f"Chat model chunk: {repr(event['data']['chunk'].content)}",
            flush=True,
        )
    if kind == "on_parser_stream":
        print(f"Parser chunk: {event['data']['chunk']}", flush=True)
    num_events += 1
    if num_events > 30:
        # Truncate the output
        print("...")
        break
```

```output
Chat model chunk: '{'
Parser chunk: {}
Chat model chunk: '\n  '
Chat model chunk: '"'
Chat model chunk: 'countries'
Chat model chunk: '":'
Chat model chunk: ' ['
Parser chunk: {'countries': []}
Chat model chunk: '\n    '
Chat model chunk: '{'
Parser chunk: {'countries': [{}]}
Chat model chunk: '\n      '
Chat model chunk: '"'
Chat model chunk: 'name'
Chat model chunk: '":'
Chat model chunk: ' "'
Parser chunk: {'countries': [{'name': ''}]}
Chat model chunk: 'France'
Parser chunk: {'countries': [{'name': 'France'}]}
Chat model chunk: '",'
Chat model chunk: '\n      '
Chat model chunk: '"'
Chat model chunk: 'population'
...
```

ëª¨ë¸ê³¼ íŒŒì„œ ëª¨ë‘ ìŠ¤íŠ¸ë¦¬ë°ì„ ì§€ì›í•˜ë¯€ë¡œ, ë‘ êµ¬ì„± ìš”ì†Œì—ì„œ ì‹¤ì‹œê°„ìœ¼ë¡œ ìŠ¤íŠ¸ë¦¬ë° ì´ë²¤íŠ¸ë¥¼ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤! ë©‹ì§€ì§€ ì•Šë‚˜ìš”? ğŸ¦œ

### ì´ë²¤íŠ¸ í•„í„°ë§

ì´ APIëŠ” ë§ì€ ì´ë²¤íŠ¸ë¥¼ ìƒì„±í•˜ë¯€ë¡œ, ì´ë²¤íŠ¸ë¥¼ í•„í„°ë§í•  ìˆ˜ ìˆëŠ” ê¸°ëŠ¥ì´ ìœ ìš©í•©ë‹ˆë‹¤.

êµ¬ì„± ìš”ì†Œ `name`, êµ¬ì„± ìš”ì†Œ `tags` ë˜ëŠ” êµ¬ì„± ìš”ì†Œ `type`ìœ¼ë¡œ í•„í„°ë§í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

#### ì´ë¦„ìœ¼ë¡œ í•„í„°ë§

```python
chain = model.with_config({"run_name": "model"}) | JsonOutputParser().with_config(
    {"run_name": "my_parser"}
)

max_events = 0
async for event in chain.astream_events(
    "output a list of the countries france, spain and japan and their populations in JSON format. "
    'Use a dict with an outer key of "countries" which contains a list of countries. '
    "Each country should have the key `name` and `population`",
    version="v2",
    include_names=["my_parser"],
):
    print(event)
    max_events += 1
    if max_events > 10:
        # Truncate output
        print("...")
        break
```

```output
{'event': 'on_parser_start', 'data': {'input': 'output a list of the countries france, spain and japan and their populations in JSON format. Use a dict with an outer key of "countries" which contains a list of countries. Each country should have the key `name` and `population`'}, 'name': 'my_parser', 'tags': ['seq:step:2'], 'run_id': 'e058d750-f2c2-40f6-aa61-10f84cd671a9', 'metadata': {}}
{'event': 'on_parser_stream', 'data': {'chunk': {}}, 'run_id': 'e058d750-f2c2-40f6-aa61-10f84cd671a9', 'name': 'my_parser', 'tags': ['seq:step:2'], 'metadata': {}}
{'event': 'on_parser_stream', 'data': {'chunk': {'countries': []}}, 'run_id': 'e058d750-f2c2-40f6-aa61-10f84cd671a9', 'name': 'my_parser', 'tags': ['seq:step:2'], 'metadata': {}}
{'event': 'on_parser_stream', 'data': {'chunk': {'countries': [{}]}}, 'run_id': 'e058d750-f2c2-40f6-aa61-10f84cd671a9', 'name': 'my_parser', 'tags': ['seq:step:2'], 'metadata': {}}
{'event': 'on_parser_stream', 'data': {'chunk': {'countries': [{'name': ''}]}}, 'run_id': 'e058d750-f2c2-40f6-aa61-10f84cd671a9', 'name': 'my_parser', 'tags': ['seq:step:2'], 'metadata': {}}
{'event': 'on_parser_stream', 'data': {'chunk': {'countries': [{'name': 'France'}]}}, 'run_id': 'e058d750-f2c2-40f6-aa61-10f84cd671a9', 'name': 'my_parser', 'tags': ['seq:step:2'], 'metadata': {}}
{'event': 'on_parser_stream', 'data': {'chunk': {'countries': [{'name': 'France', 'population': 67}]}}, 'run_id': 'e058d750-f2c2-40f6-aa61-10f84cd671a9', 'name': 'my_parser', 'tags': ['seq:step:2'], 'metadata': {}}
{'event': 'on_parser_stream', 'data': {'chunk': {'countries': [{'name': 'France', 'population': 67413}]}}, 'run_id': 'e058d750-f2c2-40f6-aa61-10f84cd671a9', 'name': 'my_parser', 'tags': ['seq:step:2'], 'metadata': {}}
{'event': 'on_parser_stream', 'data': {'chunk': {'countries': [{'name': 'France', 'population': 67413000}]}}, 'run_id': 'e058d750-f2c2-40f6-aa61-10f84cd671a9', 'name': 'my_parser', 'tags': ['seq:step:2'], 'metadata': {}}
{'event': 'on_parser_stream', 'data': {'chunk': {'countries': [{'name': 'France', 'population': 67413000}, {}]}}, 'run_id': 'e058d750-f2c2-40f6-aa61-10f84cd671a9', 'name': 'my_parser', 'tags': ['seq:step:2'], 'metadata': {}}
{'event': 'on_parser_stream', 'data': {'chunk': {'countries': [{'name': 'France', 'population': 67413000}, {'name': ''}]}}, 'run_id': 'e058d750-f2c2-40f6-aa61-10f84cd671a9', 'name': 'my_parser', 'tags': ['seq:step:2'], 'metadata': {}}
...
```

#### ìœ í˜•ìœ¼ë¡œ í•„í„°ë§

```python
chain = model.with_config({"run_name": "model"}) | JsonOutputParser().with_config(
    {"run_name": "my_parser"}
)

max_events = 0
async for event in chain.astream_events(
    'output a list of the countries france, spain and japan and their populations in JSON format. Use a dict with an outer key of "countries" which contains a list of countries. Each country should have the key `name` and `population`',
    version="v2",
    include_types=["chat_model"],
):
    print(event)
    max_events += 1
    if max_events > 10:
        # Truncate output
        print("...")
        break
```

```output
{'event': 'on_chat_model_start', 'data': {'input': 'output a list of the countries france, spain and japan and their populations in JSON format. Use a dict with an outer key of "countries" which contains a list of countries. Each country should have the key `name` and `population`'}, 'name': 'model', 'tags': ['seq:step:1'], 'run_id': 'db246792-2a91-4eb3-a14b-29658947065d', 'metadata': {}}
{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='{', id='run-db246792-2a91-4eb3-a14b-29658947065d')}, 'run_id': 'db246792-2a91-4eb3-a14b-29658947065d', 'name': 'model', 'tags': ['seq:step:1'], 'metadata': {}}
{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='\n  ', id='run-db246792-2a91-4eb3-a14b-29658947065d')}, 'run_id': 'db246792-2a91-4eb3-a14b-29658947065d', 'name': 'model', 'tags': ['seq:step:1'], 'metadata': {}}
{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='"', id='run-db246792-2a91-4eb3-a14b-29658947065d')}, 'run_id': 'db246792-2a91-4eb3-a14b-29658947065d', 'name': 'model', 'tags': ['seq:step:1'], 'metadata': {}}
{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='countries', id='run-db246792-2a91-4eb3-a14b-29658947065d')}, 'run_id': 'db246792-2a91-4eb3-a14b-29658947065d', 'name': 'model', 'tags': ['seq:step:1'], 'metadata': {}}
{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='":', id='run-db246792-2a91-4eb3-a14b-29658947065d')}, 'run_id': 'db246792-2a91-4eb3-a14b-29658947065d', 'name': 'model', 'tags': ['seq:step:1'], 'metadata': {}}
{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' [', id='run-db246792-2a91-4eb3-a14b-29658947065d')}, 'run_id': 'db246792-2a91-4eb3-a14b-29658947065d', 'name': 'model', 'tags': ['seq:step:1'], 'metadata': {}}
{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='\n    ', id='run-db246792-2a91-4eb3-a14b-29658947065d')}, 'run_id': 'db246792-2a91-4eb3-a14b-29658947065d', 'name': 'model', 'tags': ['seq:step:1'], 'metadata': {}}
{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='{', id='run-db246792-2a91-4eb3-a14b-29658947065d')}, 'run_id': 'db246792-2a91-4eb3-a14b-29658947065d', 'name': 'model', 'tags': ['seq:step:1'], 'metadata': {}}
{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='\n      ', id='run-db246792-2a91-4eb3-a14b-29658947065d')}, 'run_id': 'db246792-2a91-4eb3-a14b-29658947065d', 'name': 'model', 'tags': ['seq:step:1'], 'metadata': {}}
{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='"', id='run-db246792-2a91-4eb3-a14b-29658947065d')}, 'run_id': 'db246792-2a91-4eb3-a14b-29658947065d', 'name': 'model', 'tags': ['seq:step:1'], 'metadata': {}}
...
```

#### íƒœê·¸ë¡œ í•„í„°ë§

:::caution

íƒœê·¸ëŠ” ì£¼ì–´ì§„ ì‹¤í–‰ ê°€ëŠ¥ ìš”ì†Œì˜ ìì‹ êµ¬ì„± ìš”ì†Œì— ì˜í•´ ìƒì†ë©ë‹ˆë‹¤.

í•„í„°ë§ì— íƒœê·¸ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²½ìš°, ì´ê²ƒì´ ë‹¹ì‹ ì´ ì›í•˜ëŠ” ê²ƒì¸ì§€ í™•ì¸í•˜ì‹­ì‹œì˜¤.
:::

```python
chain = (model | JsonOutputParser()).with_config({"tags": ["my_chain"]})

max_events = 0
async for event in chain.astream_events(
    'output a list of the countries france, spain and japan and their populations in JSON format. Use a dict with an outer key of "countries" which contains a list of countries. Each country should have the key `name` and `population`',
    version="v2",
    include_tags=["my_chain"],
):
    print(event)
    max_events += 1
    if max_events > 10:
        # Truncate output
        print("...")
        break
```

```output
{'event': 'on_chain_start', 'data': {'input': 'output a list of the countries france, spain and japan and their populations in JSON format. Use a dict with an outer key of "countries" which contains a list of countries. Each country should have the key `name` and `population`'}, 'name': 'RunnableSequence', 'tags': ['my_chain'], 'run_id': 'fd68dd64-7a4d-4bdb-a0c2-ee592db0d024', 'metadata': {}}
{'event': 'on_chat_model_start', 'data': {'input': {'messages': [[HumanMessage(content='output a list of the countries france, spain and japan and their populations in JSON format. Use a dict with an outer key of "countries" which contains a list of countries. Each country should have the key `name` and `population`')]]}}, 'name': 'ChatAnthropic', 'tags': ['seq:step:1', 'my_chain'], 'run_id': 'efd3c8af-4be5-4f6c-9327-e3f9865dd1cd', 'metadata': {}}
{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='{', id='run-efd3c8af-4be5-4f6c-9327-e3f9865dd1cd')}, 'run_id': 'efd3c8af-4be5-4f6c-9327-e3f9865dd1cd', 'name': 'ChatAnthropic', 'tags': ['seq:step:1', 'my_chain'], 'metadata': {}}
{'event': 'on_parser_start', 'data': {}, 'name': 'JsonOutputParser', 'tags': ['seq:step:2', 'my_chain'], 'run_id': 'afde30b9-beac-4b36-b4c7-dbbe423ddcdb', 'metadata': {}}
{'event': 'on_parser_stream', 'data': {'chunk': {}}, 'run_id': 'afde30b9-beac-4b36-b4c7-dbbe423ddcdb', 'name': 'JsonOutputParser', 'tags': ['seq:step:2', 'my_chain'], 'metadata': {}}
{'event': 'on_chain_stream', 'data': {'chunk': {}}, 'run_id': 'fd68dd64-7a4d-4bdb-a0c2-ee592db0d024', 'name': 'RunnableSequence', 'tags': ['my_chain'], 'metadata': {}}
{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='\n  ', id='run-efd3c8af-4be5-4f6c-9327-e3f9865dd1cd')}, 'run_id': 'efd3c8af-4be5-4f6c-9327-e3f9865dd1cd', 'name': 'ChatAnthropic', 'tags': ['seq:step:1', 'my_chain'], 'metadata': {}}
{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='"', id='run-efd3c8af-4be5-4f6c-9327-e3f9865dd1cd')}, 'run_id': 'efd3c8af-4be5-4f6c-9327-e3f9865dd1cd', 'name': 'ChatAnthropic', 'tags': ['seq:step:1', 'my_chain'], 'metadata': {}}
{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='countries', id='run-efd3c8af-4be5-4f6c-9327-e3f9865dd1cd')}, 'run_id': 'efd3c8af-4be5-4f6c-9327-e3f9865dd1cd', 'name': 'ChatAnthropic', 'tags': ['seq:step:1', 'my_chain'], 'metadata': {}}
{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='":', id='run-efd3c8af-4be5-4f6c-9327-e3f9865dd1cd')}, 'run_id': 'efd3c8af-4be5-4f6c-9327-e3f9865dd1cd', 'name': 'ChatAnthropic', 'tags': ['seq:step:1', 'my_chain'], 'metadata': {}}
{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' [', id='run-efd3c8af-4be5-4f6c-9327-e3f9865dd1cd')}, 'run_id': 'efd3c8af-4be5-4f6c-9327-e3f9865dd1cd', 'name': 'ChatAnthropic', 'tags': ['seq:step:1', 'my_chain'], 'metadata': {}}
...
```

### ë¹„ìŠ¤íŠ¸ë¦¬ë° ì»´í¬ë„ŒíŠ¸

ì¼ë¶€ ì»´í¬ë„ŒíŠ¸ê°€ **ì…ë ¥ ìŠ¤íŠ¸ë¦¼**ì—ì„œ ì‘ë™í•˜ì§€ ì•Šê¸° ë•Œë¬¸ì— ìŠ¤íŠ¸ë¦¬ë°ì´ ì˜ ë˜ì§€ ì•ŠëŠ”ë‹¤ëŠ” ê²ƒì„ ê¸°ì–µí•˜ë‚˜ìš”?

ì´ëŸ¬í•œ ì»´í¬ë„ŒíŠ¸ëŠ” `astream`ì„ ì‚¬ìš©í•  ë•Œ ìµœì¢… ì¶œë ¥ì˜ ìŠ¤íŠ¸ë¦¬ë°ì„ ì¤‘ë‹¨í•  ìˆ˜ ìˆì§€ë§Œ, `astream_events`ëŠ” ì—¬ì „íˆ ìŠ¤íŠ¸ë¦¬ë°ì„ ì§€ì›í•˜ëŠ” ì¤‘ê°„ ë‹¨ê³„ì—ì„œ ìŠ¤íŠ¸ë¦¬ë° ì´ë²¤íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤!

```python
# Function that does not support streaming.
# It operates on the finalizes inputs rather than
# operating on the input stream.
def _extract_country_names(inputs):
    """A function that does not operates on input streams and breaks streaming."""
    if not isinstance(inputs, dict):
        return ""

    if "countries" not in inputs:
        return ""

    countries = inputs["countries"]

    if not isinstance(countries, list):
        return ""

    country_names = [
        country.get("name") for country in countries if isinstance(country, dict)
    ]
    return country_names


chain = (
    model | JsonOutputParser() | _extract_country_names
)  # This parser only works with OpenAI right now
```


ì˜ˆìƒëŒ€ë¡œ, `_extract_country_names`ê°€ ìŠ¤íŠ¸ë¦¼ì—ì„œ ì‘ë™í•˜ì§€ ì•Šê¸° ë•Œë¬¸ì— `astream` APIëŠ” ì œëŒ€ë¡œ ì‘ë™í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.

```python
async for chunk in chain.astream(
    "output a list of the countries france, spain and japan and their populations in JSON format. "
    'Use a dict with an outer key of "countries" which contains a list of countries. '
    "Each country should have the key `name` and `population`",
):
    print(chunk, flush=True)
```

```output
['France', 'Spain', 'Japan']
```

ì´ì œ, `astream_events`ë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ê³¼ íŒŒì„œì—ì„œ ì—¬ì „íˆ ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥ì„ ë³´ê³  ìˆëŠ”ì§€ í™•ì¸í•´ ë´…ì‹œë‹¤.

```python
num_events = 0

async for event in chain.astream_events(
    "output a list of the countries france, spain and japan and their populations in JSON format. "
    'Use a dict with an outer key of "countries" which contains a list of countries. '
    "Each country should have the key `name` and `population`",
    version="v2",
):
    kind = event["event"]
    if kind == "on_chat_model_stream":
        print(
            f"Chat model chunk: {repr(event['data']['chunk'].content)}",
            flush=True,
        )
    if kind == "on_parser_stream":
        print(f"Parser chunk: {event['data']['chunk']}", flush=True)
    num_events += 1
    if num_events > 30:
        # Truncate the output
        print("...")
        break
```

```output
Chat model chunk: '{'
Parser chunk: {}
Chat model chunk: '\n  '
Chat model chunk: '"'
Chat model chunk: 'countries'
Chat model chunk: '":'
Chat model chunk: ' ['
Parser chunk: {'countries': []}
Chat model chunk: '\n    '
Chat model chunk: '{'
Parser chunk: {'countries': [{}]}
Chat model chunk: '\n      '
Chat model chunk: '"'
Chat model chunk: 'name'
Chat model chunk: '":'
Chat model chunk: ' "'
Parser chunk: {'countries': [{'name': ''}]}
Chat model chunk: 'France'
Parser chunk: {'countries': [{'name': 'France'}]}
Chat model chunk: '",'
Chat model chunk: '\n      '
Chat model chunk: '"'
Chat model chunk: 'population'
Chat model chunk: '":'
Chat model chunk: ' '
Chat model chunk: '67'
Parser chunk: {'countries': [{'name': 'France', 'population': 67}]}
...
```

### ì½œë°± ì „íŒŒ

:::caution
ë„êµ¬ ë‚´ì—ì„œ ì‹¤í–‰ ê°€ëŠ¥í•œ í•­ëª©ì„ í˜¸ì¶œí•˜ëŠ” ê²½ìš°, ì½œë°±ì„ ì‹¤í–‰ ê°€ëŠ¥í•œ í•­ëª©ìœ¼ë¡œ ì „íŒŒí•´ì•¼ í•©ë‹ˆë‹¤. ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ ìŠ¤íŠ¸ë¦¼ ì´ë²¤íŠ¸ê°€ ìƒì„±ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
:::

:::note
`RunnableLambdas` ë˜ëŠ” `@chain` ë°ì½”ë ˆì´í„°ë¥¼ ì‚¬ìš©í•  ë•Œ, ì½œë°±ì€ ìë™ìœ¼ë¡œ ë’·ë©´ì—ì„œ ì „íŒŒë©ë‹ˆë‹¤.
:::

```python
<!--IMPORTS:[{"imported": "RunnableLambda", "source": "langchain_core.runnables", "docs": "https://api.python.langchain.com/en/latest/runnables/langchain_core.runnables.base.RunnableLambda.html", "title": "How to stream runnables"}, {"imported": "tool", "source": "langchain_core.tools", "docs": "https://api.python.langchain.com/en/latest/tools/langchain_core.tools.convert.tool.html", "title": "How to stream runnables"}]-->
from langchain_core.runnables import RunnableLambda
from langchain_core.tools import tool


def reverse_word(word: str):
    return word[::-1]


reverse_word = RunnableLambda(reverse_word)


@tool
def bad_tool(word: str):
    """Custom tool that doesn't propagate callbacks."""
    return reverse_word.invoke(word)


async for event in bad_tool.astream_events("hello", version="v2"):
    print(event)
```

```output
{'event': 'on_tool_start', 'data': {'input': 'hello'}, 'name': 'bad_tool', 'tags': [], 'run_id': 'ea900472-a8f7-425d-b627-facdef936ee8', 'metadata': {}}
{'event': 'on_chain_start', 'data': {'input': 'hello'}, 'name': 'reverse_word', 'tags': [], 'run_id': '77b01284-0515-48f4-8d7c-eb27c1882f86', 'metadata': {}}
{'event': 'on_chain_end', 'data': {'output': 'olleh', 'input': 'hello'}, 'run_id': '77b01284-0515-48f4-8d7c-eb27c1882f86', 'name': 'reverse_word', 'tags': [], 'metadata': {}}
{'event': 'on_tool_end', 'data': {'output': 'olleh'}, 'run_id': 'ea900472-a8f7-425d-b627-facdef936ee8', 'name': 'bad_tool', 'tags': [], 'metadata': {}}
```

ì½œë°±ì„ ì˜¬ë°”ë¥´ê²Œ ì „íŒŒí•˜ëŠ” ì¬êµ¬í˜„ì´ ìˆìŠµë‹ˆë‹¤. ì´ì œ `reverse_word` ì‹¤í–‰ ê°€ëŠ¥í•œ í•­ëª©ì—ì„œ ì´ë²¤íŠ¸ë¥¼ ë°›ê³  ìˆë‹¤ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```python
@tool
def correct_tool(word: str, callbacks):
    """A tool that correctly propagates callbacks."""
    return reverse_word.invoke(word, {"callbacks": callbacks})


async for event in correct_tool.astream_events("hello", version="v2"):
    print(event)
```

```output
{'event': 'on_tool_start', 'data': {'input': 'hello'}, 'name': 'correct_tool', 'tags': [], 'run_id': 'd5ea83b9-9278-49cc-9f1d-aa302d671040', 'metadata': {}}
{'event': 'on_chain_start', 'data': {'input': 'hello'}, 'name': 'reverse_word', 'tags': [], 'run_id': '44dafbf4-2f87-412b-ae0e-9f71713810df', 'metadata': {}}
{'event': 'on_chain_end', 'data': {'output': 'olleh', 'input': 'hello'}, 'run_id': '44dafbf4-2f87-412b-ae0e-9f71713810df', 'name': 'reverse_word', 'tags': [], 'metadata': {}}
{'event': 'on_tool_end', 'data': {'output': 'olleh'}, 'run_id': 'd5ea83b9-9278-49cc-9f1d-aa302d671040', 'name': 'correct_tool', 'tags': [], 'metadata': {}}
```

`Runnable Lambdas` ë˜ëŠ” `@chains` ë‚´ì—ì„œ ì‹¤í–‰ ê°€ëŠ¥í•œ í•­ëª©ì„ í˜¸ì¶œí•˜ëŠ” ê²½ìš°, ì½œë°±ì€ ìë™ìœ¼ë¡œ ê·€í•˜ë¥¼ ëŒ€ì‹ í•˜ì—¬ ì „ë‹¬ë©ë‹ˆë‹¤.

```python
<!--IMPORTS:[{"imported": "RunnableLambda", "source": "langchain_core.runnables", "docs": "https://api.python.langchain.com/en/latest/runnables/langchain_core.runnables.base.RunnableLambda.html", "title": "How to stream runnables"}]-->
from langchain_core.runnables import RunnableLambda


async def reverse_and_double(word: str):
    return await reverse_word.ainvoke(word) * 2


reverse_and_double = RunnableLambda(reverse_and_double)

await reverse_and_double.ainvoke("1234")

async for event in reverse_and_double.astream_events("1234", version="v2"):
    print(event)
```

```output
{'event': 'on_chain_start', 'data': {'input': '1234'}, 'name': 'reverse_and_double', 'tags': [], 'run_id': '03b0e6a1-3e60-42fc-8373-1e7829198d80', 'metadata': {}}
{'event': 'on_chain_start', 'data': {'input': '1234'}, 'name': 'reverse_word', 'tags': [], 'run_id': '5cf26fc8-840b-4642-98ed-623dda28707a', 'metadata': {}}
{'event': 'on_chain_end', 'data': {'output': '4321', 'input': '1234'}, 'run_id': '5cf26fc8-840b-4642-98ed-623dda28707a', 'name': 'reverse_word', 'tags': [], 'metadata': {}}
{'event': 'on_chain_stream', 'data': {'chunk': '43214321'}, 'run_id': '03b0e6a1-3e60-42fc-8373-1e7829198d80', 'name': 'reverse_and_double', 'tags': [], 'metadata': {}}
{'event': 'on_chain_end', 'data': {'output': '43214321'}, 'run_id': '03b0e6a1-3e60-42fc-8373-1e7829198d80', 'name': 'reverse_and_double', 'tags': [], 'metadata': {}}
```

ê·¸ë¦¬ê³  `@chain` ë°ì½”ë ˆì´í„°ì™€ í•¨ê»˜:

```python
<!--IMPORTS:[{"imported": "chain", "source": "langchain_core.runnables", "docs": "https://api.python.langchain.com/en/latest/runnables/langchain_core.runnables.base.chain.html", "title": "How to stream runnables"}]-->
from langchain_core.runnables import chain


@chain
async def reverse_and_double(word: str):
    return await reverse_word.ainvoke(word) * 2


await reverse_and_double.ainvoke("1234")

async for event in reverse_and_double.astream_events("1234", version="v2"):
    print(event)
```

```output
{'event': 'on_chain_start', 'data': {'input': '1234'}, 'name': 'reverse_and_double', 'tags': [], 'run_id': '1bfcaedc-f4aa-4d8e-beee-9bba6ef17008', 'metadata': {}}
{'event': 'on_chain_start', 'data': {'input': '1234'}, 'name': 'reverse_word', 'tags': [], 'run_id': '64fc99f0-5d7d-442b-b4f5-4537129f67d1', 'metadata': {}}
{'event': 'on_chain_end', 'data': {'output': '4321', 'input': '1234'}, 'run_id': '64fc99f0-5d7d-442b-b4f5-4537129f67d1', 'name': 'reverse_word', 'tags': [], 'metadata': {}}
{'event': 'on_chain_stream', 'data': {'chunk': '43214321'}, 'run_id': '1bfcaedc-f4aa-4d8e-beee-9bba6ef17008', 'name': 'reverse_and_double', 'tags': [], 'metadata': {}}
{'event': 'on_chain_end', 'data': {'output': '43214321'}, 'run_id': '1bfcaedc-f4aa-4d8e-beee-9bba6ef17008', 'name': 'reverse_and_double', 'tags': [], 'metadata': {}}
```

## ë‹¤ìŒ ë‹¨ê³„

ì´ì œ LangChainì„ ì‚¬ìš©í•˜ì—¬ ìµœì¢… ì¶œë ¥ê³¼ ë‚´ë¶€ ë‹¨ê³„ë¥¼ ìŠ¤íŠ¸ë¦¬ë°í•˜ëŠ” ëª‡ ê°€ì§€ ë°©ë²•ì„ ë°°ì› ìŠµë‹ˆë‹¤.

ë” ì•Œì•„ë³´ë ¤ë©´ ì´ ì„¹ì…˜ì˜ ë‹¤ë¥¸ ì‚¬ìš© ë°©ë²• ê°€ì´ë“œë¥¼ í™•ì¸í•˜ê±°ë‚˜ [Langchain í‘œí˜„ ì–¸ì–´ì— ëŒ€í•œ ê°œë… ê°€ì´ë“œ](/docs/concepts/#langchain-expression-language/)ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”.