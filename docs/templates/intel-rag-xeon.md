---
description: ì´ ë¬¸ì„œëŠ” IntelÂ® XeonÂ® Scalable í”„ë¡œì„¸ì„œì—ì„œ Chromaì™€ í…ìŠ¤íŠ¸ ìƒì„± ì¶”ë¡ ì„ ì‚¬ìš©í•œ RAG ì˜ˆì œë¥¼ ì œê³µí•©ë‹ˆë‹¤.
---

# RAG ì˜ˆì œ ì¸í…” ì œì˜¨
ì´ í…œí”Œë¦¿ì€ ì¸í…”Â® ì œì˜¨Â® í™•ì¥ ê°€ëŠ¥ í”„ë¡œì„¸ì„œì—ì„œ Chroma ë° í…ìŠ¤íŠ¸ ìƒì„± ì¶”ë¡ ì„ ì‚¬ìš©í•˜ì—¬ RAGë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.  
ì¸í…”Â® ì œì˜¨Â® í™•ì¥ ê°€ëŠ¥ í”„ë¡œì„¸ì„œëŠ” ë” ë†’ì€ ì„±ëŠ¥ì„ ìœ„í•œ ë‚´ì¥ ê°€ì†ê¸°ë¥¼ íŠ¹ì§•ìœ¼ë¡œ í•˜ë©°, ë›°ì–´ë‚œ AI ì„±ëŠ¥ê³¼ í•¨ê»˜ ê°€ì¥ ìˆ˜ìš”ê°€ ë§ì€ ì‘ì—… ìš”êµ¬ ì‚¬í•­ì„ ìœ„í•œ ê³ ê¸‰ ë³´ì•ˆ ê¸°ìˆ ì„ ì œê³µí•©ë‹ˆë‹¤. ëª¨ë“  í´ë¼ìš°ë“œ ì„ íƒê³¼ ì• í”Œë¦¬ì¼€ì´ì…˜ ì´ì‹ì„±ì„ ì œê³µí•˜ë¯€ë¡œ [ì¸í…”Â® ì œì˜¨Â® í™•ì¥ ê°€ëŠ¥ í”„ë¡œì„¸ì„œ](https://www.intel.com/content/www/us/en/products/details/processors/xeon/scalable.html)ë¥¼ í™•ì¸í•´ ì£¼ì„¸ìš”.

## í™˜ê²½ ì„¤ì •
ì¸í…”Â® ì œì˜¨Â® í™•ì¥ ê°€ëŠ¥ í”„ë¡œì„¸ì„œì—ì„œ [ğŸ¤— text-generation-inference](https://github.com/huggingface/text-generation-inference)ë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ ë‹¤ìŒ ë‹¨ê³„ë¥¼ ë”°ë¥´ì„¸ìš”:

### ì¸í…” ì œì˜¨ ì„œë²„ì—ì„œ ë¡œì»¬ ì„œë²„ ì¸ìŠ¤í„´ìŠ¤ ì‹œì‘:
```bash
model=Intel/neural-chat-7b-v3-3
volume=$PWD/data # share a volume with the Docker container to avoid downloading weights every run

docker run --shm-size 1g -p 8080:80 -v $volume:/data ghcr.io/huggingface/text-generation-inference:1.4 --model-id $model
```


`LLAMA-2`ì™€ ê°™ì€ ì œí•œëœ ëª¨ë¸ì˜ ê²½ìš°, ìœ„ì˜ ë„ì»¤ ì‹¤í–‰ ëª…ë ¹ì— -e HUGGING_FACE_HUB_TOKEN=\<token\>ì„ ìœ íš¨í•œ Hugging Face Hub ì½ê¸° í† í°ê³¼ í•¨ê»˜ ì „ë‹¬í•´ì•¼ í•©ë‹ˆë‹¤.

ì ‘ê·¼ í† í°ì„ ì–»ìœ¼ë ¤ë©´ ì´ ë§í¬ [huggingface token](https://huggingface.co/docs/hub/security-tokens)ë¥¼ ë”°ë¼ê°€ê³ , `HUGGINGFACEHUB_API_TOKEN` í™˜ê²½ ë³€ìˆ˜ë¥¼ í† í°ìœ¼ë¡œ ë‚´ë³´ë‚´ì„¸ìš”.

```bash
export HUGGINGFACEHUB_API_TOKEN=<token> 
```


ì—”ë“œí¬ì¸íŠ¸ê°€ ì‘ë™í•˜ëŠ”ì§€ í™•ì¸í•˜ê¸° ìœ„í•´ ìš”ì²­ì„ ë³´ë‚´ì„¸ìš”:

```bash
curl localhost:8080/generate -X POST -d '{"inputs":"Which NFL team won the Super Bowl in the 2010 season?","parameters":{"max_new_tokens":128, "do_sample": true}}'   -H 'Content-Type: application/json'
```


ìì„¸í•œ ë‚´ìš©ì€ [text-generation-inference](https://github.com/huggingface/text-generation-inference)ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”.

## ë°ì´í„°ë¡œ ì±„ìš°ê¸°

DBë¥¼ ì˜ˆì œ ë°ì´í„°ë¡œ ì±„ìš°ê³  ì‹¶ë‹¤ë©´ ì•„ë˜ ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:
```shell
poetry install
poetry run python ingest.py
```


ìŠ¤í¬ë¦½íŠ¸ëŠ” Nike `nke-10k-2023.pdf`ì˜ Edgar 10k ì œì¶œ ë°ì´í„°ì—ì„œ ì„¹ì…˜ì„ ì²˜ë¦¬í•˜ê³  Chroma ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥í•©ë‹ˆë‹¤.

## ì‚¬ìš©ë²•

ì´ íŒ¨í‚¤ì§€ë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ ë¨¼ì € LangChain CLIë¥¼ ì„¤ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤:

```shell
pip install -U langchain-cli
```


ìƒˆ LangChain í”„ë¡œì íŠ¸ë¥¼ ìƒì„±í•˜ê³  ì´ê²ƒì„ ìœ ì¼í•œ íŒ¨í‚¤ì§€ë¡œ ì„¤ì¹˜í•˜ë ¤ë©´ ë‹¤ìŒê³¼ ê°™ì´ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```shell
langchain app new my-app --package intel-rag-xeon
```


ê¸°ì¡´ í”„ë¡œì íŠ¸ì— ì¶”ê°€í•˜ë ¤ë©´ ë‹¤ìŒ ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•˜ë©´ ë©ë‹ˆë‹¤:

```shell
langchain app add intel-rag-xeon
```


ê·¸ë¦¬ê³  ë‹¤ìŒ ì½”ë“œë¥¼ `server.py` íŒŒì¼ì— ì¶”ê°€í•˜ì„¸ìš”:
```python
from intel_rag_xeon import chain as xeon_rag_chain

add_routes(app, xeon_rag_chain, path="/intel-rag-xeon")
```


(ì„ íƒ ì‚¬í•­) ì´ì œ LangSmithë¥¼ êµ¬ì„±í•´ ë³´ê² ìŠµë‹ˆë‹¤. LangSmithëŠ” LangChain ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ì¶”ì , ëª¨ë‹ˆí„°ë§ ë° ë””ë²„ê¹…í•˜ëŠ” ë° ë„ì›€ì„ ì¤„ ê²ƒì…ë‹ˆë‹¤. LangSmithì— ê°€ì…í•˜ë ¤ë©´ [ì—¬ê¸°](https://smith.langchain.com/)ë¥¼ í´ë¦­í•˜ì„¸ìš”. ì ‘ê·¼ ê¶Œí•œì´ ì—†ë‹¤ë©´ ì´ ì„¹ì…˜ì„ ê±´ë„ˆë›¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```shell
export LANGCHAIN_TRACING_V2=true
export LANGCHAIN_API_KEY=<your-api-key>
export LANGCHAIN_PROJECT=<your-project>  # if not specified, defaults to "default"
```


ì´ ë””ë ‰í† ë¦¬ ë‚´ì— ìˆë‹¤ë©´ ë‹¤ìŒê³¼ ê°™ì´ LangServe ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì§ì ‘ ì‹œì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```shell
langchain serve
```


ì´ë ‡ê²Œ í•˜ë©´ FastAPI ì•±ì´ ì‹œì‘ë˜ë©° ì„œë²„ê°€ ë¡œì»¬ì—ì„œ ì‹¤í–‰ë©ë‹ˆë‹¤.
[http://localhost:8000](http://localhost:8000)

ëª¨ë“  í…œí”Œë¦¿ì€ [http://127.0.0.1:8000/docs](http://127.0.0.1:8000/docs)ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  
í”Œë ˆì´ê·¸ë¼ìš´ë“œëŠ” [http://127.0.0.1:8000/intel-rag-xeon/playground](http://127.0.0.1:8000/intel-rag-xeon/playground)ì—ì„œ ì ‘ê·¼í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ì½”ë“œì—ì„œ í…œí”Œë¦¿ì— ì ‘ê·¼í•˜ë ¤ë©´:

```python
from langserve.client import RemoteRunnable

runnable = RemoteRunnable("http://localhost:8000/intel-rag-xeon")
```