---
description: LangChain은 자연어 처리 분야의 최신 연구를 구현하며, 관련된 arXiv 논문들을 소개하는 페이지입니다.
---

# arXiv

LangChain은 자연어 처리 분야의 최신 연구를 구현합니다.  
이 페이지에는 LangChain 문서, API 참조, 템플릿 및 요리책에서 참조된 `arXiv` 논문이 포함되어 있습니다.

반대 방향에서 과학자들은 연구에 `LangChain`을 사용하고 연구 논문에서 이를 참조합니다.  
여기에서 다음을 참조하는 논문을 찾을 수 있습니다:  
- [LangChain](https://arxiv.org/search/?query=langchain&searchtype=all&source=header)  
- [LangGraph](https://arxiv.org/search/?query=langgraph&searchtype=all&source=header)  
- [LangSmith](https://arxiv.org/search/?query=langsmith&searchtype=all&source=header)  
## 요약

| arXiv id / 제목 | 저자 | 발행일 🔻 | LangChain 문서 |
|------------------|---------|-------------------|------------------------|
| `2402.03620v1` [Self-Discover: 대형 언어 모델의 자기 구성 추론 구조](http://arxiv.org/abs/2402.03620v1) | Pei Zhou, Jay Pujara, Xiang Ren,  et al. | 2024-02-06 | `Cookbook:` [self-discover](https://github.com/langchain-ai/langchain/blob/master/cookbook/self-discover.ipynb) |
| `2401.18059v1` [RAPTOR: 트리 조직 검색을 위한 재귀적 추상 처리](http://arxiv.org/abs/2401.18059v1) | Parth Sarthi, Salman Abdullah, Aditi Tuli,  et al. | 2024-01-31 | `Cookbook:` [RAPTOR](https://github.com/langchain-ai/langchain/blob/master/cookbook/RAPTOR.ipynb) |
| `2401.15884v2` [교정 검색 증강 생성](http://arxiv.org/abs/2401.15884v2) | Shi-Qi Yan, Jia-Chen Gu, Yun Zhu,  et al. | 2024-01-29 | `Cookbook:` [langgraph_crag](https://github.com/langchain-ai/langchain/blob/master/cookbook/langgraph_crag.ipynb) |
| `2401.04088v1` [전문가의 믹스트랄](http://arxiv.org/abs/2401.04088v1) | Albert Q. Jiang, Alexandre Sablayrolles, Antoine Roux,  et al. | 2024-01-08 | `Cookbook:` [together_ai](https://github.com/langchain-ai/langchain/blob/master/cookbook/together_ai.ipynb) |
| `2312.06648v2` [밀집 X 검색: 어떤 검색 세분화를 사용해야 할까요?](http://arxiv.org/abs/2312.06648v2) | Tong Chen, Hongwei Wang, Sihao Chen,  et al. | 2023-12-11 | `Template:` [propositional-retrieval](https://python.langchain.com/docs/templates/propositional-retrieval) |
| `2311.09210v1` [Chain-of-Note: 검색 증강 언어 모델의 강건성 향상](http://arxiv.org/abs/2311.09210v1) | Wenhao Yu, Hongming Zhang, Xiaoman Pan,  et al. | 2023-11-15 | `Template:` [chain-of-note-wiki](https://python.langchain.com/docs/templates/chain-of-note-wiki) |
| `2310.11511v1` [Self-RAG: 자기 반성을 통한 검색, 생성 및 비판 학습](http://arxiv.org/abs/2310.11511v1) | Akari Asai, Zeqiu Wu, Yizhong Wang,  et al. | 2023-10-17 | `Cookbook:` [langgraph_self_rag](https://github.com/langchain-ai/langchain/blob/master/cookbook/langgraph_self_rag.ipynb) |
| `2310.06117v2` [한 걸음 물러서기: 대형 언어 모델에서 추상화를 통한 추론 유도](http://arxiv.org/abs/2310.06117v2) | Huaixiu Steven Zheng, Swaroop Mishra, Xinyun Chen,  et al. | 2023-10-09 | `Template:` [stepback-qa-prompting](https://python.langchain.com/docs/templates/stepback-qa-prompting), `Cookbook:` [stepback-qa](https://github.com/langchain-ai/langchain/blob/master/cookbook/stepback-qa.ipynb) |
| `2307.09288v2` [Llama 2: 오픈 파운데이션 및 미세 조정된 채팅 모델](http://arxiv.org/abs/2307.09288v2) | Hugo Touvron, Louis Martin, Kevin Stone,  et al. | 2023-07-18 | `Cookbook:` [Semi_Structured_RAG](https://github.com/langchain-ai/langchain/blob/master/cookbook/Semi_Structured_RAG.ipynb) |
| `2305.14283v3` [검색 증강 대형 언어 모델을 위한 쿼리 재작성](http://arxiv.org/abs/2305.14283v3) | Xinbei Ma, Yeyun Gong, Pengcheng He,  et al. | 2023-05-23 | `Template:` [rewrite-retrieve-read](https://python.langchain.com/docs/templates/rewrite-retrieve-read), `Cookbook:` [rewrite](https://github.com/langchain-ai/langchain/blob/master/cookbook/rewrite.ipynb) |
| `2305.08291v1` [대형 언어 모델 가이드 트리 오브 생각](http://arxiv.org/abs/2305.08291v1) | Jieyi Long | 2023-05-15 | `API:` [langchain_experimental.tot](https://api.python.langchain.com/en/latest/experimental_api_reference.html#module-langchain_experimental.tot), `Cookbook:` [tree_of_thought](https://github.com/langchain-ai/langchain/blob/master/cookbook/tree_of_thought.ipynb) |
| `2305.04091v3` [계획 및 해결 프롬프트: 대형 언어 모델에 의한 제로샷 체인 오브 생각 추론 개선](http://arxiv.org/abs/2305.04091v3) | Lei Wang, Wanyu Xu, Yihuai Lan,  et al. | 2023-05-06 | `Cookbook:` [plan_and_execute_agent](https://github.com/langchain-ai/langchain/blob/master/cookbook/plan_and_execute_agent.ipynb) |
| `2305.02156v1` [대형 언어 모델을 통한 제로샷 리스트 기반 문서 재순위](http://arxiv.org/abs/2305.02156v1) | Xueguang Ma, Xinyu Zhang, Ronak Pradeep,  et al. | 2023-05-03 | `API:` [langchain...LLMListwiseRerank](https://api.python.langchain.com/en/latest/retrievers/langchain.retrievers.document_compressors.listwise_rerank.LLMListwiseRerank.html#langchain.retrievers.document_compressors.listwise_rerank.LLMListwiseRerank) |
| `2304.08485v2` [비주얼 지침 조정](http://arxiv.org/abs/2304.08485v2) | Haotian Liu, Chunyuan Li, Qingyang Wu,  et al. | 2023-04-17 | `Cookbook:` [Semi_structured_and_multi_modal_RAG](https://github.com/langchain-ai/langchain/blob/master/cookbook/Semi_structured_and_multi_modal_RAG.ipynb), [Semi_structured_multi_modal_RAG_LLaMA2](https://github.com/langchain-ai/langchain/blob/master/cookbook/Semi_structured_multi_modal_RAG_LLaMA2.ipynb) |
| `2304.03442v2` [생성 에이전트: 대형 언어 모델 사회의 "마음" 탐색을 위한 상호작용 시뮬라크르](http://arxiv.org/abs/2304.03442v2) | Joon Sung Park, Joseph C. O'Brien, Carrie J. Cai,  et al. | 2023-04-07 | `Cookbook:` [multiagent_bidding](https://github.com/langchain-ai/langchain/blob/master/cookbook/multiagent_bidding.ipynb), [generative_agents_interactive_simulacra_of_human_behavior](https://github.com/langchain-ai/langchain/blob/master/cookbook/generative_agents_interactive_simulacra_of_human_behavior.ipynb) |
| `2303.17760v2` [CAMEL: 대형 언어 모델 사회의 "마음" 탐색을 위한 의사소통 에이전트](http://arxiv.org/abs/2303.17760v2) | Guohao Li, Hasan Abed Al Kader Hammoud, Hani Itani,  et al. | 2023-03-31 | `Cookbook:` [camel_role_playing](https://github.com/langchain-ai/langchain/blob/master/cookbook/camel_role_playing.ipynb) |
| `2303.17580v4` [HuggingGPT: ChatGPT 및 Hugging Face의 친구들과 AI 작업 해결](http://arxiv.org/abs/2303.17580v4) | Yongliang Shen, Kaitao Song, Xu Tan,  et al. | 2023-03-30 | `API:` [langchain_experimental.autonomous_agents](https://api.python.langchain.com/en/latest/experimental_api_reference.html#module-langchain_experimental.autonomous_agents), `Cookbook:` [hugginggpt](https://github.com/langchain-ai/langchain/blob/master/cookbook/hugginggpt.ipynb) |
| `2301.10226v4` [대형 언어 모델을 위한 워터마크](http://arxiv.org/abs/2301.10226v4) | John Kirchenbauer, Jonas Geiping, Yuxin Wen,  et al. | 2023-01-24 | `API:` [langchain_community...OCIModelDeploymentTGI](https://api.python.langchain.com/en/latest/llms/langchain_community.llms.oci_data_science_model_deployment_endpoint.OCIModelDeploymentTGI.html#langchain_community.llms.oci_data_science_model_deployment_endpoint.OCIModelDeploymentTGI), [langchain_huggingface...HuggingFaceEndpoint](https://api.python.langchain.com/en/latest/llms/langchain_huggingface.llms.huggingface_endpoint.HuggingFaceEndpoint.html#langchain_huggingface.llms.huggingface_endpoint.HuggingFaceEndpoint), [langchain_community...HuggingFaceEndpoint](https://api.python.langchain.com/en/latest/llms/langchain_community.llms.huggingface_endpoint.HuggingFaceEndpoint.html#langchain_community.llms.huggingface_endpoint.HuggingFaceEndpoint), [langchain_community...HuggingFaceTextGenInference](https://api.python.langchain.com/en/latest/llms/langchain_community.llms.huggingface_text_gen_inference.HuggingFaceTextGenInference.html#langchain_community.llms.huggingface_text_gen_inference.HuggingFaceTextGenInference) |
| `2212.10496v1` [관련성 레이블 없이 정확한 제로샷 밀집 검색](http://arxiv.org/abs/2212.10496v1) | Luyu Gao, Xueguang Ma, Jimmy Lin,  et al. | 2022-12-20 | `API:` [langchain...HypotheticalDocumentEmbedder](https://api.python.langchain.com/en/latest/chains/langchain.chains.hyde.base.HypotheticalDocumentEmbedder.html#langchain.chains.hyde.base.HypotheticalDocumentEmbedder), `Template:` [hyde](https://python.langchain.com/docs/templates/hyde), `Cookbook:` [hypothetical_document_embeddings](https://github.com/langchain-ai/langchain/blob/master/cookbook/hypothetical_document_embeddings.ipynb) |
| `2212.07425v3` [자연어 논증에서 논리적 오류의 강력하고 설명 가능한 식별](http://arxiv.org/abs/2212.07425v3) | Zhivar Sourati, Vishnu Priya Prasanna Venkatesh, Darshan Deshpande,  et al. | 2022-12-12 | `API:` [langchain_experimental.fallacy_removal](https://api.python.langchain.com/en/latest/experimental_api_reference.html#module-langchain_experimental.fallacy_removal) |
| `2211.13892v2` [효과적인 인컨텍스트 학습을 위한 보완 설명](http://arxiv.org/abs/2211.13892v2) | Xi Ye, Srinivasan Iyer, Asli Celikyilmaz,  et al. | 2022-11-25 | `API:` [langchain_core...MaxMarginalRelevanceExampleSelector](https://api.python.langchain.com/en/latest/example_selectors/langchain_core.example_selectors.semantic_similarity.MaxMarginalRelevanceExampleSelector.html#langchain_core.example_selectors.semantic_similarity.MaxMarginalRelevanceExampleSelector) |
| `2211.10435v2` [PAL: 프로그램 지원 언어 모델](http://arxiv.org/abs/2211.10435v2) | Luyu Gao, Aman Madaan, Shuyan Zhou,  et al. | 2022-11-18 | `API:` [langchain_experimental.pal_chain](https://api.python.langchain.com/en/latest/experimental_api_reference.html#module-langchain_experimental.pal_chain), [langchain_experimental...PALChain](https://api.python.langchain.com/en/latest/pal_chain/langchain_experimental.pal_chain.base.PALChain.html#langchain_experimental.pal_chain.base.PALChain), `Cookbook:` [program_aided_language_model](https://github.com/langchain-ai/langchain/blob/master/cookbook/program_aided_language_model.ipynb) |
| `2210.03629v3` [ReAct: 언어 모델에서 추론과 행동의 시너지](http://arxiv.org/abs/2210.03629v3) | Shunyu Yao, Jeffrey Zhao, Dian Yu,  et al. | 2022-10-06 | `Docs:` [docs/integrations/providers/cohere](https://python.langchain.com/docs/integrations/providers/cohere), [docs/integrations/tools/ionic_shopping](https://python.langchain.com/docs/integrations/tools/ionic_shopping), `API:` [langchain...TrajectoryEvalChain](https://api.python.langchain.com/en/latest/evaluation/langchain.evaluation.agents.trajectory_eval_chain.TrajectoryEvalChain.html#langchain.evaluation.agents.trajectory_eval_chain.TrajectoryEvalChain), [langchain...create_react_agent](https://api.python.langchain.com/en/latest/agents/langchain.agents.react.agent.create_react_agent.html#langchain.agents.react.agent.create_react_agent)
| `2209.10785v2` [Deep Lake: 딥 러닝을 위한 레이크하우스](http://arxiv.org/abs/2209.10785v2) | Sasun Hambardzumyan, Abhinav Tuli, Levon Ghukasyan,  et al. | 2022-09-22 | `Docs:` [docs/integrations/providers/activeloop_deeplake](https://python.langchain.com/docs/integrations/providers/activeloop_deeplake)
| `2205.13147v4` [마트료시카 표현 학습](http://arxiv.org/abs/2205.13147v4) | Aditya Kusupati, Gantavya Bhatt, Aniket Rege,  et al. | 2022-05-26 | `Docs:` [docs/integrations/providers/snowflake](https://python.langchain.com/docs/integrations/providers/snowflake)
| `2205.12654v1` [저자원 언어를 위한 증류된 문장 표현을 사용한 비텍스트 마이닝](http://arxiv.org/abs/2205.12654v1) | Kevin Heffernan, Onur Çelebi, Holger Schwenk | 2022-05-25 | `API:` [langchain_community...LaserEmbeddings](https://api.python.langchain.com/en/latest/embeddings/langchain_community.embeddings.laser.LaserEmbeddings.html#langchain_community.embeddings.laser.LaserEmbeddings)
| `2204.00498v1` [대형 언어 모델의 텍스트-투-SQL 기능 평가](http://arxiv.org/abs/2204.00498v1) | Nitarshan Rajkumar, Raymond Li, Dzmitry Bahdanau | 2022-03-15 | `API:` [langchain_community...SQLDatabase](https://api.python.langchain.com/en/latest/utilities/langchain_community.utilities.sql_database.SQLDatabase.html#langchain_community.utilities.sql_database.SQLDatabase), [langchain_community...SparkSQL](https://api.python.langchain.com/en/latest/utilities/langchain_community.utilities.spark_sql.SparkSQL.html#langchain_community.utilities.spark_sql.SparkSQL)
| `2202.00666v5` [로컬 전형 샘플링](http://arxiv.org/abs/2202.00666v5) | Clara Meister, Tiago Pimentel, Gian Wiher,  et al. | 2022-02-01 | `API:` [langchain_huggingface...HuggingFaceEndpoint](https://api.python.langchain.com/en/latest/llms/langchain_huggingface.llms.huggingface_endpoint.HuggingFaceEndpoint.html#langchain_huggingface.llms.huggingface_endpoint.HuggingFaceEndpoint), [langchain_community...HuggingFaceEndpoint](https://api.python.langchain.com/en/latest/llms/langchain_community.llms.huggingface_endpoint.HuggingFaceEndpoint.html#langchain_community.llms.huggingface_endpoint.HuggingFaceEndpoint), [langchain_community...HuggingFaceTextGenInference](https://api.python.langchain.com/en/latest/llms/langchain_community.llms.huggingface_text_gen_inference.HuggingFaceTextGenInference.html#langchain_community.llms.huggingface_text_gen_inference.HuggingFaceTextGenInference)
| `2103.00020v1` [자연어 감독으로부터 전이 가능한 시각 모델 학습](http://arxiv.org/abs/2103.00020v1) | Alec Radford, Jong Wook Kim, Chris Hallacy,  et al. | 2021-02-26 | `API:` [langchain_experimental.open_clip](https://api.python.langchain.com/en/latest/experimental_api_reference.html#module-langchain_experimental.open_clip)
| `1909.05858v2` [CTRL: 제어 가능한 생성을 위한 조건부 변환기 언어 모델](http://arxiv.org/abs/1909.05858v2) | Nitish Shirish Keskar, Bryan McCann, Lav R. Varshney,  et al. | 2019-09-11 | `API:` [langchain_huggingface...HuggingFaceEndpoint](https://api.python.langchain.com/en/latest/llms/langchain_huggingface.llms.huggingface_endpoint.HuggingFaceEndpoint.html#langchain_huggingface.llms.huggingface_endpoint.HuggingFaceEndpoint), [langchain_community...HuggingFaceEndpoint](https://api.python.langchain.com/en/latest/llms/langchain_community.llms.huggingface_endpoint.HuggingFaceEndpoint.html#langchain_community.llms.huggingface_endpoint.HuggingFaceEndpoint), [langchain_community...HuggingFaceTextGenInference](https://api.python.langchain.com/en/latest/llms/langchain_community.llms.huggingface_text_gen_inference.HuggingFaceTextGenInference.html#langchain_community.llms.huggingface_text_gen_inference.HuggingFaceTextGenInference)
## Self-Discover: 대형 언어 모델의 자기 발견 추론 구조

- **arXiv id:** [2402.03620v1](http://arxiv.org/abs/2402.03620v1)  **Published Date:** 2024-02-06
- **Title:** Self-Discover: 대형 언어 모델의 자기 발견 추론 구조
- **Authors:** Pei Zhou, Jay Pujara, Xiang Ren,  et al.
- **LangChain:**
  
  - **Cookbook:** [self-discover](https://github.com/langchain-ai/langchain/blob/master/cookbook/self-discover.ipynb)

**Abstract:** 우리는 LLM이 복잡한 추론 문제를 해결하기 위해 작업 고유의 추론 구조를 자기 발견할 수 있는 일반적인 프레임워크인 SELF-DISCOVER를 소개합니다. 이 프레임워크의 핵심은 LLM이 비판적 사고 및 단계별 사고와 같은 여러 원자적 추론 모듈을 선택하고 이를 명시적인 추론 구조로 구성하여 디코딩 중에 LLM이 따를 수 있도록 하는 자기 발견 프로세스입니다. SELF-DISCOVER는 Chain of Thought (CoT)와 비교하여 BigBench-Hard, grounded agent reasoning, MATH와 같은 도전적인 추론 벤치마크에서 GPT-4와 PaLM 2의 성능을 최대 32% 향상시킵니다. 또한, SELF-DISCOVER는 CoT-Self-Consistency와 같은 추론 집약적 방법보다 20% 이상 우수한 성능을 보이며, 10-40배 적은 추론 컴퓨팅을 요구합니다. 마지막으로, 우리는 자기 발견된 추론 구조가 PaLM 2-L에서 GPT-4, GPT-4에서 Llama2에 이르기까지 모델 패밀리 전반에 걸쳐 보편적으로 적용 가능하며, 인간의 추론 패턴과 공통점을 공유함을 보여줍니다.

## RAPTOR: 트리 조직 검색을 위한 재귀적 추상 처리

- **arXiv id:** [2401.18059v1](http://arxiv.org/abs/2401.18059v1)  **Published Date:** 2024-01-31
- **Title:** RAPTOR: 트리 조직 검색을 위한 재귀적 추상 처리
- **Authors:** Parth Sarthi, Salman Abdullah, Aditi Tuli,  et al.
- **LangChain:**
  
  - **Cookbook:** [RAPTOR](https://github.com/langchain-ai/langchain/blob/master/cookbook/RAPTOR.ipynb)

**Abstract:** 검색 증강 언어 모델은 세계 상태의 변화에 더 잘 적응하고 긴 꼬리 지식을 통합할 수 있습니다. 그러나 대부분의 기존 방법은 검색 코퍼스에서 짧고 연속적인 청크만 검색하여 전체 문서 맥락에 대한 전체적인 이해를 제한합니다. 우리는 텍스트 청크를 재귀적으로 임베딩, 클러스터링 및 요약하는 새로운 접근 방식을 소개하며, 아래에서 위로 다양한 요약 수준을 가진 트리를 구성합니다. 추론 시, 우리의 RAPTOR 모델은 이 트리에서 검색하여 서로 다른 추상화 수준에서 긴 문서 간의 정보를 통합합니다. 통제된 실험 결과, 재귀 요약을 통한 검색이 여러 작업에서 전통적인 검색 증강 LM보다 상당한 개선을 제공함을 보여줍니다. 복잡한 다단계 추론이 포함된 질문-응답 작업에서 우리는 최첨단 결과를 보여줍니다. 예를 들어, RAPTOR 검색과 GPT-4 사용을 결합함으로써 QuALITY 벤치마크에서 절대 정확도를 20% 향상시킬 수 있습니다.

## 수정 검색 증강 생성

- **arXiv id:** [2401.15884v2](http://arxiv.org/abs/2401.15884v2)  **Published Date:** 2024-01-29
- **Title:** 수정 검색 증강 생성
- **Authors:** Shi-Qi Yan, Jia-Chen Gu, Yun Zhu,  et al.
- **LangChain:**
  
  - **Cookbook:** [langgraph_crag](https://github.com/langchain-ai/langchain/blob/master/cookbook/langgraph_crag.ipynb)

**Abstract:** 대형 언어 모델(LLM)은 생성된 텍스트의 정확성을 단순히 캡슐화된 매개변수 지식만으로 보장할 수 없기 때문에 불가피하게 환각을 나타냅니다. 검색 증강 생성(RAG)은 LLM에 대한 실용적인 보완책이지만, 검색된 문서의 관련성에 크게 의존하여 검색이 잘못될 경우 모델의 동작에 대한 우려를 불러일으킵니다. 이를 위해 우리는 생성의 강건성을 개선하기 위해 수정 검색 증강 생성(CRAG)을 제안합니다. 구체적으로, 쿼리에 대한 검색된 문서의 전반적인 품질을 평가하기 위해 경량 검색 평가기를 설계하여, 다양한 지식 검색 작업을 촉발할 수 있는 신뢰도 정도를 반환합니다. 정적이고 제한된 코퍼스에서 검색된 문서는 최적이 아닌 문서만 반환할 수 있으므로, 대규모 웹 검색이 검색 결과를 보강하는 확장으로 활용됩니다. 또한, 검색된 문서에서 핵심 정보에 선택적으로 집중하고 관련 없는 정보를 필터링하기 위해 분해-재구성 알고리즘이 설계되었습니다. CRAG는 플러그 앤 플레이 방식으로 다양한 RAG 기반 접근 방식과 원활하게 결합될 수 있습니다. 짧은 형식 및 긴 형식 생성 작업을 포함하는 네 개의 데이터 세트에 대한 실험 결과, CRAG는 RAG 기반 접근 방식의 성능을 상당히 향상시킬 수 있음을 보여줍니다.

## Mixtral of Experts

- **arXiv id:** [2401.04088v1](http://arxiv.org/abs/2401.04088v1)  **Published Date:** 2024-01-08
- **Title:** Mixtral of Experts
- **Authors:** Albert Q. Jiang, Alexandre Sablayrolles, Antoine Roux,  et al.
- **LangChain:**
  
  - **Cookbook:** [together_ai](https://github.com/langchain-ai/langchain/blob/master/cookbook/together_ai.ipynb)

**Abstract:** 우리는 Sparse Mixture of Experts (SMoE) 언어 모델인 Mixtral 8x7B를 소개합니다. Mixtral은 Mistral 7B와 동일한 아키텍처를 가지며, 각 레이어는 8개의 피드포워드 블록(즉, 전문가)으로 구성됩니다. 각 토큰에 대해 각 레이어에서 라우터 네트워크가 현재 상태를 처리할 두 개의 전문가를 선택하고 그 출력을 결합합니다. 각 토큰은 두 개의 전문가만 보지만, 선택된 전문가는 각 시간 단계에서 다를 수 있습니다. 결과적으로 각 토큰은 47B 매개변수에 접근할 수 있지만, 추론 중에는 13B 활성 매개변수만 사용합니다. Mixtral은 32k 토큰의 컨텍스트 크기로 훈련되었으며, 평가된 모든 벤치마크에서 Llama 2 70B 및 GPT-3.5를 초과하거나 일치합니다. 특히, Mixtral은 수학, 코드 생성 및 다국어 벤치마크에서 Llama 2 70B를 크게 초과합니다. 우리는 또한 지침을 따르도록 미세 조정된 모델인 Mixtral 8x7B - Instruct를 제공하며, 이 모델은 인간 벤치마크에서 GPT-3.5 Turbo, Claude-2.1, Gemini Pro 및 Llama 2 70B - 채팅 모델을 초과합니다. 기본 모델과 지침 모델 모두 Apache 2.0 라이선스 하에 출시됩니다.

## Dense X Retrieval: 어떤 검색 세분화를 사용해야 할까요?

- **arXiv id:** [2312.06648v2](http://arxiv.org/abs/2312.06648v2)  **Published Date:** 2023-12-11
- **Title:** Dense X Retrieval: 어떤 검색 세분화를 사용해야 할까요?
- **Authors:** Tong Chen, Hongwei Wang, Sihao Chen,  et al.
- **LangChain:**
  
  - **Template:** [propositional-retrieval](https://python.langchain.com/docs/templates/propositional-retrieval)

**Abstract:** 밀집 검색은 개방형 도메인 NLP 작업에서 관련 맥락이나 세계 지식을 얻기 위한 주요 방법이 되었습니다. 추론 시 학습된 밀집 검색기를 검색 코퍼스에서 사용할 때, 종종 간과되는 설계 선택은 코퍼스가 색인화되는 검색 단위(예: 문서, 구절 또는 문장)입니다. 우리는 검색 단위 선택이 검색 및 하위 작업의 성능에 상당한 영향을 미친다는 것을 발견했습니다. 전형적인 접근 방식인 구절이나 문장을 사용하는 것과는 달리, 우리는 밀집 검색을 위한 새로운 검색 단위인 명제를 소개합니다. 명제는 텍스트 내의 원자 표현으로 정의되며, 각각은 독특한 사실을 캡슐화하고 간결하고 자급자족하는 자연어 형식으로 제시됩니다. 우리는 다양한 검색 세분화에 대한 실증적 비교를 수행했습니다. 우리의 결과는 명제 기반 검색이 전통적인 구절 또는 문장 기반 방법보다 밀집 검색에서 상당히 우수함을 보여줍니다. 더욱이, 명제로 검색하면 검색된 텍스트가 질문 관련 정보로 더 응축되어 하위 QA 작업의 성능도 향상됩니다. 이는 긴 입력 토큰의 필요성을 줄이고 불필요한 정보의 포함을 최소화합니다.

## Chain-of-Note: 검색 증강 언어 모델의 강건성 향상

- **arXiv id:** [2311.09210v1](http://arxiv.org/abs/2311.09210v1)  **Published Date:** 2023-11-15
- **Title:** Chain-of-Note: 검색 증강 언어 모델의 강건성 향상
- **Authors:** Wenhao Yu, Hongming Zhang, Xiaoman Pan,  et al.
- **LangChain:**
  
  - **Template:** [chain-of-note-wiki](https://python.langchain.com/docs/templates/chain-of-note-wiki)

**Abstract:** 검색 증강 언어 모델(RALM)은 대형 언어 모델의 기능에서 상당한 발전을 나타내며, 외부 지식 소스를 활용하여 사실적 환각을 줄이는 데 특히 효과적입니다. 그러나 검색된 정보의 신뢰성이 항상 보장되는 것은 아닙니다. 관련 없는 데이터의 검색은 잘못된 응답을 초래할 수 있으며, 모델이 쿼리를 해결하는 데 충분한 정보를 가지고 있음에도 불구하고 본래의 지식을 간과하게 만들 수 있습니다. 더욱이, 표준 RALM은 정확한 답변을 제공하기 위해 본질적 및 검색된 지식이 충분한지 평가하는 데 종종 어려움을 겪습니다. 지식이 부족한 상황에서는 이러한 시스템이 이상적으로 "알 수 없음"으로 응답해야 합니다. 이러한 문제에 대응하기 위해, 우리는 노이즈가 많고 관련 없는 문서에 직면할 때 RALM의 강건성을 개선하고 알 수 없는 시나리오를 처리하기 위한 새로운 접근 방식인 Chain-of-Noting (CoN)을 소개합니다. CoN의 핵심 아이디어는 검색된 문서에 대한 순차적 읽기 노트를 생성하여 주어진 질문에 대한 관련성을 철저히 평가하고 이 정보를 통합하여 최종 답변을 형성하는 것입니다. 우리는 ChatGPT를 사용하여 CoN의 훈련 데이터를 생성하였으며, 이후 LLaMa-2 7B 모델에서 훈련되었습니다. 네 개의 개방형 QA 벤치마크에 대한 실험 결과, CoN을 장착한 RALM은 표준 RALM보다 상당히 우수한 성능을 보였습니다. 특히, CoN은 완전히 노이즈가 많은 검색된 문서에 대해 EM 점수에서 평균 +7.9의 개선을 달성하고, 사전 훈련 지식 범위를 벗어난 실시간 질문에 대한 거부율에서 +10.5의 개선을 보였습니다.

## Self-RAG: 자기 반성을 통한 검색, 생성 및 비판 학습

- **arXiv id:** [2310.11511v1](http://arxiv.org/abs/2310.11511v1)  **Published Date:** 2023-10-17
- **Title:** Self-RAG: 자기 반성을 통한 검색, 생성 및 비판 학습
- **Authors:** Akari Asai, Zeqiu Wu, Yizhong Wang,  et al.
- **LangChain:**
  
  - **Cookbook:** [langgraph_self_rag](https://github.com/langchain-ai/langchain/blob/master/cookbook/langgraph_self_rag.ipynb)

**Abstract:** 비록 대형 언어 모델(LLM)의 뛰어난 능력에도 불구하고, LLM은 매개변수 지식에만 의존하기 때문에 사실적 부정확성을 포함한 응답을 생성하는 경우가 많습니다. 검색 증강 생성(RAG)은 관련 지식의 검색으로 LLM을 보강하는 즉흥적인 접근 방식으로 이러한 문제를 감소시킵니다. 그러나 검색이 필요하거나 구절이 관련이 있는지 여부에 관계없이 고정된 수의 검색된 구절을 무차별적으로 검색하고 통합하는 것은 LLM의 다양성을 감소시키거나 도움이 되지 않는 응답 생성을 초래할 수 있습니다. 우리는 검색 및 자기 반성을 통해 LLM의 품질과 사실성을 향상시키는 Self-Reflective Retrieval-Augmented Generation (Self-RAG)이라는 새로운 프레임워크를 소개합니다. 우리의 프레임워크는 요구에 따라 구절을 적응적으로 검색하고, 검색된 구절과 자신의 생성을 생성 및 반성하는 단일 임의의 LLM을 훈련합니다. 반성 토큰이라고 하는 특수 토큰을 사용하여 반성 토큰을 생성함으로써 LLM은 추론 단계에서 제어 가능하게 되어 다양한 작업 요구 사항에 맞게 행동을 조정할 수 있습니다. 실험 결과, Self-RAG (7B 및 13B 매개변수)는 다양한 작업에서 최첨단 LLM 및 검색 증강 모델보다 상당히 우수한 성능을 보입니다. 특히, Self-RAG는 Open-domain QA, 추론 및 사실 검증 작업에서 ChatGPT 및 검색 증강 Llama2-chat보다 우수하며, 이러한 모델에 비해 긴 형식 생성의 사실성과 인용 정확성을 개선하는 데 상당한 이점을 보여줍니다.
## 한 걸음 물러서기: 대형 언어 모델에서 추상을 통한 추론 유도

- **arXiv id:** [2310.06117v2](http://arxiv.org/abs/2310.06117v2)  **발행일:** 2023-10-09
- **제목:** 한 걸음 물러서기: 대형 언어 모델에서 추상을 통한 추론 유도
- **저자:** Huaixiu Steven Zheng, Swaroop Mishra, Xinyun Chen,  et al.
- **LangChain:**
  
  - **템플릿:** [stepback-qa-prompting](https://python.langchain.com/docs/templates/stepback-qa-prompting)
  - **요리책:** [stepback-qa](https://github.com/langchain-ai/langchain/blob/master/cookbook/stepback-qa.ipynb)

**초록:** 우리는 Step-Back Prompting을 제안합니다. 이는 LLM이 특정 세부 정보를 포함하는 사례에서 고수준 개념과 기본 원리를 도출하기 위해 추상을 수행할 수 있게 해주는 간단한 프롬프트 기법입니다. 개념과 원리를 사용하여 추론을 안내함으로써, LLM은 해결책을 향한 올바른 추론 경로를 따르는 능력을 크게 향상시킵니다. 우리는 PaLM-2L, GPT-4 및 Llama2-70B 모델로 Step-Back Prompting 실험을 수행하였고, STEM, 지식 QA 및 다중 단계 추론을 포함한 다양한 도전적인 추론 집약적 작업에서 상당한 성능 향상을 관찰하였습니다. 예를 들어, Step-Back Prompting은 MMLU(물리학 및 화학)에서 PaLM-2L의 성능을 각각 7% 및 11% 향상시키고, TimeQA는 27%, MuSiQue는 7% 향상시킵니다.

## Llama 2: 오픈 파운데이션 및 미세 조정된 채팅 모델

- **arXiv id:** [2307.09288v2](http://arxiv.org/abs/2307.09288v2)  **발행일:** 2023-07-18
- **제목:** Llama 2: 오픈 파운데이션 및 미세 조정된 채팅 모델
- **저자:** Hugo Touvron, Louis Martin, Kevin Stone,  et al.
- **LangChain:**
  
  - **요리책:** [Semi_Structured_RAG](https://github.com/langchain-ai/langchain/blob/master/cookbook/Semi_Structured_RAG.ipynb)

**초록:** 본 연구에서는 70억에서 700억 매개변수에 이르는 사전 훈련된 대형 언어 모델(LLM) 컬렉션인 Llama 2를 개발하고 공개합니다. 우리의 미세 조정된 LLM인 Llama 2-Chat은 대화 사용 사례에 최적화되어 있습니다. 우리의 모델은 우리가 테스트한 대부분의 벤치마크에서 오픈 소스 채팅 모델보다 우수한 성능을 보이며, 유용성과 안전성에 대한 인간 평가를 기반으로 폐쇄형 모델의 적절한 대체가 될 수 있습니다. 우리는 Llama 2-Chat의 미세 조정 및 안전성 개선 접근 방식에 대한 자세한 설명을 제공하여 커뮤니티가 우리의 작업을 기반으로 구축하고 LLM의 책임 있는 개발에 기여할 수 있도록 합니다.

## 검색 증강 대형 언어 모델을 위한 쿼리 재작성

- **arXiv id:** [2305.14283v3](http://arxiv.org/abs/2305.14283v3)  **발행일:** 2023-05-23
- **제목:** 검색 증강 대형 언어 모델을 위한 쿼리 재작성
- **저자:** Xinbei Ma, Yeyun Gong, Pengcheng He,  et al.
- **LangChain:**
  
  - **템플릿:** [rewrite-retrieve-read](https://python.langchain.com/docs/templates/rewrite-retrieve-read)
  - **요리책:** [rewrite](https://github.com/langchain-ai/langchain/blob/master/cookbook/rewrite.ipynb)

**초록:** 대형 언어 모델(LLM)은 검색 후 읽기 파이프라인에서 강력한 블랙 박스 리더 역할을 하며, 지식 집약적 작업에서 놀라운 진전을 이루었습니다. 본 연구에서는 쿼리 재작성 관점에서 검색 증강 LLM을 위한 새로운 프레임워크인 Rewrite-Retrieve-Read를 소개합니다. 이전의 검색 후 읽기 방식과는 달리, 우리의 접근 방식은 검색 쿼리 자체의 적응에 주목합니다. 입력 텍스트와 검색에 필요한 지식 사이에는 불가피한 간극이 있기 때문입니다. 우리는 먼저 LLM에 쿼리를 생성하도록 프롬프트한 다음, 웹 검색 엔진을 사용하여 컨텍스트를 검색합니다. 또한, 쿼리를 고정 모듈에 더 잘 맞추기 위해, 우리의 파이프라인을 위한 훈련 가능한 계획을 제안합니다. 작은 언어 모델을 훈련 가능한 재작성기로 채택하여 블랙 박스 LLM 리더에 맞추었습니다. 재작성기는 강화 학습을 통해 LLM 리더의 피드백을 사용하여 훈련됩니다. 평가 작업은 다운스트림 작업, 오픈 도메인 QA 및 다중 선택 QA에서 수행됩니다. 실험 결과는 일관된 성능 향상을 보여주며, 우리의 프레임워크가 효과적이고 확장 가능함을 나타내며, 검색 증강 LLM을 위한 새로운 프레임워크를 제공합니다.

## 대형 언어 모델 가이드 트리 오브 생각

- **arXiv id:** [2305.08291v1](http://arxiv.org/abs/2305.08291v1)  **발행일:** 2023-05-15
- **제목:** 대형 언어 모델 가이드 트리 오브 생각
- **저자:** Jieyi Long
- **LangChain:**
  
  - **API 참조:** [langchain_experimental.tot](https://api.python.langchain.com/en/latest/experimental_api_reference.html#module-langchain_experimental.tot)
  - **요리책:** [tree_of_thought](https://github.com/langchain-ai/langchain/blob/master/cookbook/tree_of_thought.ipynb)

**초록:** 본 논문에서는 자동 회귀 대형 언어 모델(LLM)의 문제 해결 능력을 향상시키기 위한 새로운 접근 방식인 Tree-of-Thought(ToT) 프레임워크를 소개합니다. ToT 기법은 복잡한 추론 작업을 해결하기 위한 인간의 사고 방식을 통해 영감을 받았습니다. 이 과정에서 인간의 사고는 나무와 같은 사고 과정을 통해 해결 공간을 탐색하며, 필요할 때 되돌아갈 수 있습니다. ToT를 소프트웨어 시스템으로 구현하기 위해, 우리는 프롬프터 에이전트, 검사기 모듈, 메모리 모듈 및 ToT 컨트롤러를 포함한 추가 모듈로 LLM을 보강합니다. 주어진 문제를 해결하기 위해 이러한 모듈은 LLM과 다중 라운드 대화를 진행합니다. 메모리 모듈은 대화 및 문제 해결 과정의 상태 기록을 기록하여 시스템이 사고 과정의 이전 단계로 되돌아가고 그곳에서 다른 방향을 탐색할 수 있도록 합니다. 제안된 기법의 효과를 검증하기 위해, 우리는 스도쿠 퍼즐을 위한 ToT 기반 해결기를 구현했습니다. 실험 결과는 ToT 프레임워크가 스도쿠 퍼즐 해결의 성공률을 크게 증가시킬 수 있음을 보여줍니다. 우리의 ToT 기반 스도쿠 해결기 구현은 GitHub에서 확인할 수 있습니다: \url{https://github.com/jieyilong/tree-of-thought-puzzle-solver}.

## 계획 및 해결 프롬프트: 대형 언어 모델에 의한 제로샷 사고 연쇄 추론 개선

- **arXiv id:** [2305.04091v3](http://arxiv.org/abs/2305.04091v3)  **발행일:** 2023-05-06
- **제목:** 계획 및 해결 프롬프트: 대형 언어 모델에 의한 제로샷 사고 연쇄 추론 개선
- **저자:** Lei Wang, Wanyu Xu, Yihuai Lan,  et al.
- **LangChain:**
  
  - **요리책:** [plan_and_execute_agent](https://github.com/langchain-ai/langchain/blob/master/cookbook/plan_and_execute_agent.ipynb)

**초록:** 대형 언어 모델(LLM)은 최근 다양한 NLP 작업에서 인상적인 성능을 보여주었습니다. 다단계 추론 작업을 해결하기 위해, 몇 가지 수작업으로 제작된 단계별 추론 시연을 포함하는 몇 샷 사고 연쇄(CoT) 프롬프트는 LLM이 명시적으로 추론 단계를 생성하고 추론 작업 정확도를 향상시킬 수 있게 합니다. 수작업 노력을 없애기 위해, 제로샷-CoT는 "단계별로 생각해 보자"라는 입력 프롬프트와 함께 목표 문제 진술을 LLM에 연결합니다. 제로샷-CoT의 성공에도 불구하고, 여전히 세 가지 단점이 있습니다: 계산 오류, 누락 단계 오류 및 의미 이해 오류. 누락 단계 오류를 해결하기 위해, 우리는 계획 및 해결(PS) 프롬프트를 제안합니다. 이는 전체 작업을 더 작은 하위 작업으로 나누기 위한 계획을 세우고, 그 계획에 따라 하위 작업을 수행하는 두 가지 구성 요소로 이루어져 있습니다. 계산 오류를 해결하고 생성된 추론 단계의 품질을 향상시키기 위해, 우리는 PS 프롬프트를 더 자세한 지침으로 확장하고 PS+ 프롬프트를 도출합니다. 우리는 제안한 프롬프트 전략을 세 가지 추론 문제에 걸쳐 10개 데이터 세트에서 평가합니다. 실험 결과는 GPT-3에서 제안한 제로샷 프롬프트가 모든 데이터 세트에서 제로샷-CoT를 크게 초과하며, 제로샷-프로그램 오브 사고 프롬프트와 비슷하거나 초과하고, 수학 추론 문제에 대해서는 8샷 CoT 프롬프트와 유사한 성능을 보인다는 것을 보여줍니다. 코드는 https://github.com/AGI-Edgerunners/Plan-and-Solve-Prompting에서 확인할 수 있습니다.

## 제로샷 리스트 기반 문서 재정렬을 위한 대형 언어 모델

- **arXiv id:** [2305.02156v1](http://arxiv.org/abs/2305.02156v1)  **발행일:** 2023-05-03
- **제목:** 제로샷 리스트 기반 문서 재정렬을 위한 대형 언어 모델
- **저자:** Xueguang Ma, Xinyu Zhang, Ronak Pradeep,  et al.
- **LangChain:**
  
  - **API 참조:** [langchain...LLMListwiseRerank](https://api.python.langchain.com/en/latest/retrievers/langchain.retrievers.document_compressors.listwise_rerank.LLMListwiseRerank.html#langchain.retrievers.document_compressors.listwise_rerank.LLMListwiseRerank)

**초록:** 바이 인코더 또는 크로스 인코더 아키텍처에 기반한 감독된 순위 매기기 방법은 다단계 텍스트 순위 매기기 작업에서 성공을 거두었지만, 훈련 데이터로서 많은 양의 관련성 판단이 필요합니다. 본 연구에서는 작업 특정 훈련 데이터 없이 강력한 재정렬 효과를 달성하는 대형 언어 모델(LLM)을 이용한 리스트 기반 재정렬기(LRL)를 제안합니다. 문서가 독립적으로 점수가 매겨지고 점수에 따라 순위가 매겨지는 기존의 포인트 기반 순위 매기기 방법과는 달리, LRL은 후보 문서가 주어졌을 때 문서 식별자의 재정렬된 리스트를 직접 생성합니다. 세 가지 TREC 웹 검색 데이터 세트에서의 실험 결과는 LRL이 첫 번째 단계 검색 결과를 재정렬할 때 제로샷 포인트 기반 방법보다 우수할 뿐만 아니라, 포인트 기반 방법의 상위 순위를 개선하기 위한 최종 단계 재정렬기로도 작용할 수 있음을 보여줍니다. 또한, 우리는 최근 다국어 검색 데이터 세트인 MIRACL의 하위 집합에 우리의 접근 방식을 적용하였으며, 그 결과는 다양한 언어에서 일반화할 수 있는 잠재력을 보여줍니다.

## 시각적 지침 조정

- **arXiv id:** [2304.08485v2](http://arxiv.org/abs/2304.08485v2)  **발행일:** 2023-04-17
- **제목:** 시각적 지침 조정
- **저자:** Haotian Liu, Chunyuan Li, Qingyang Wu,  et al.
- **LangChain:**
  
  - **요리책:** [Semi_structured_and_multi_modal_RAG](https://github.com/langchain-ai/langchain/blob/master/cookbook/Semi_structured_and_multi_modal_RAG.ipynb), [Semi_structured_multi_modal_RAG_LLaMA2](https://github.com/langchain-ai/langchain/blob/master/cookbook/Semi_structured_multi_modal_RAG_LLaMA2.ipynb)

**초록:** 기계 생성된 지침 따르기 데이터를 사용한 대형 언어 모델(LLM)의 지침 조정은 새로운 작업에 대한 제로샷 능력을 향상시켰지만, 이 아이디어는 다중 모드 분야에서 덜 탐구되었습니다. 본 논문에서는 언어 전용 GPT-4를 사용하여 다중 모드 언어-이미지 지침 따르기 데이터를 생성하는 첫 번째 시도를 제시합니다. 이러한 생성된 데이터에 대한 지침 조정을 통해, 우리는 LLaVA: 대형 언어 및 비전 어시스턴트를 소개합니다. 이는 비전 인코더와 LLM을 연결하여 일반 목적의 시각적 및 언어 이해를 위한 종단 간 훈련된 대형 다중 모드 모델입니다. 초기 실험 결과는 LLaVA가 인상적인 다중 모드 채팅 능력을 보여주며, 때때로 보지 못한 이미지/지침에 대해 다중 모드 GPT-4의 행동을 나타내고, 합성 다중 모드 지침 따르기 데이터 세트에서 GPT-4와 비교하여 85.1%의 상대 점수를 기록합니다. Science QA에서 미세 조정할 때, LLaVA와 GPT-4의 시너지는 92.53%의 새로운 최첨단 정확도를 달성합니다. 우리는 GPT-4가 생성한 시각적 지침 조정 데이터를 공개합니다.
## 생성 에이전트: 인간 행동의 상호작용 시뮬라크라

- **arXiv id:** [2304.03442v2](http://arxiv.org/abs/2304.03442v2)  **발행일:** 2023-04-07
- **제목:** 생성 에이전트: 인간 행동의 상호작용 시뮬라크라
- **저자:** Joon Sung Park, Joseph C. O'Brien, Carrie J. Cai, et al.
- **LangChain:**
  
  - **요리책:** [multiagent_bidding](https://github.com/langchain-ai/langchain/blob/master/cookbook/multiagent_bidding.ipynb), [generative_agents_interactive_simulacra_of_human_behavior](https://github.com/langchain-ai/langchain/blob/master/cookbook/generative_agents_interactive_simulacra_of_human_behavior.ipynb)

**초록:** 믿을 수 있는 인간 행동의 대리자는 몰입형 환경에서 대인 커뮤니케이션을 위한 리허설 공간, 프로토타입 도구에 이르기까지 다양한 상호작용 애플리케이션을 가능하게 할 수 있습니다. 본 논문에서는 믿을 수 있는 인간 행동을 시뮬레이션하는 계산 소프트웨어 에이전트인 생성 에이전트를 소개합니다. 생성 에이전트는 일어나서 아침을 요리하고, 일하러 나갑니다; 예술가는 그림을 그리고, 작가는 글을 씁니다; 그들은 의견을 형성하고, 서로를 알아차리며, 대화를 시작합니다; 그들은 기억하고 지난 날을 반성하며 다음 날을 계획합니다. 생성 에이전트를 가능하게 하기 위해, 우리는 자연어를 사용하여 에이전트의 경험을 완전하게 기록하고, 시간이 지남에 따라 이러한 기억을 더 높은 수준의 반성으로 합성하며, 행동을 계획하기 위해 동적으로 검색하는 아키텍처를 설명합니다. 우리는 The Sims에서 영감을 받은 상호작용 샌드박스 환경을 채우기 위해 생성 에이전트를 구현하며, 최종 사용자는 자연어를 사용하여 25명의 에이전트로 구성된 작은 마을과 상호작용할 수 있습니다. 평가에서 이러한 생성 에이전트는 믿을 수 있는 개별 및 emergent 사회적 행동을 생성합니다: 예를 들어, 한 에이전트가 발렌타인 데이 파티를 열고 싶다는 단일 사용자 지정 개념으로 시작하여, 에이전트는 다음 이틀 동안 자율적으로 파티 초대를 전파하고, 새로운 친구를 사귀고, 서로에게 파티에 대한 데이트를 요청하며, 올바른 시간에 함께 파티에 참석하기 위해 조정합니다. 우리는 관찰, 계획 및 반성이라는 에이전트 아키텍처의 구성 요소가 에이전트 행동의 신뢰성에 각각 중요한 기여를 한다는 것을 ablation을 통해 입증합니다. 대형 언어 모델과 계산적, 상호작용 에이전트를 융합함으로써, 이 작업은 인간 행동의 믿을 수 있는 시뮬레이션을 가능하게 하는 아키텍처 및 상호작용 패턴을 소개합니다.

## CAMEL: 대형 언어 모델 사회의 "마음" 탐색을 위한 의사소통 에이전트

- **arXiv id:** [2303.17760v2](http://arxiv.org/abs/2303.17760v2)  **발행일:** 2023-03-31
- **제목:** CAMEL: 대형 언어 모델 사회의 "마음" 탐색을 위한 의사소통 에이전트
- **저자:** Guohao Li, Hasan Abed Al Kader Hammoud, Hani Itani, et al.
- **LangChain:**
  
  - **요리책:** [camel_role_playing](https://github.com/langchain-ai/langchain/blob/master/cookbook/camel_role_playing.ipynb)

**초록:** 채팅 기반 언어 모델의 빠른 발전은 복잡한 작업 해결에서 놀라운 진전을 가져왔습니다. 그러나 그들의 성공은 대화를 안내하기 위한 인간의 입력에 크게 의존하며, 이는 도전적이고 시간이 많이 소요될 수 있습니다. 본 논문에서는 의사소통 에이전트 간의 자율 협력을 촉진하기 위한 확장 가능한 기술을 구축할 가능성을 탐구하고, 그들의 "인지" 과정에 대한 통찰력을 제공합니다. 자율 협력 달성의 도전과제를 해결하기 위해, 우리는 역할 놀이라는 새로운 의사소통 에이전트 프레임워크를 제안합니다. 우리의 접근 방식은 일관성을 유지하면서 작업 완료를 위해 채팅 에이전트를 안내하기 위해 inception prompting을 사용하는 것입니다. 우리는 역할 놀이가 에이전트 사회의 행동과 능력을 연구하기 위해 대화 데이터를 생성하는 데 어떻게 사용될 수 있는지를 보여주며, 대화형 언어 모델을 조사하는 데 유용한 자원을 제공합니다. 특히, 우리는 다중 에이전트 설정에서 지침 따르기 협력에 대한 포괄적인 연구를 수행합니다. 우리의 기여에는 새로운 의사소통 에이전트 프레임워크를 소개하고, 다중 에이전트 시스템의 협력 행동과 능력을 연구하기 위한 확장 가능한 접근 방식을 제공하며, 의사소통 에이전트 및 그 이상에 대한 연구를 지원하기 위해 우리의 라이브러리를 오픈 소스화하는 것이 포함됩니다: https://github.com/camel-ai/camel.

## HuggingGPT: ChatGPT와 Hugging Face의 친구들로 AI 작업 해결하기

- **arXiv id:** [2303.17580v4](http://arxiv.org/abs/2303.17580v4)  **발행일:** 2023-03-30
- **제목:** HuggingGPT: ChatGPT와 Hugging Face의 친구들로 AI 작업 해결하기
- **저자:** Yongliang Shen, Kaitao Song, Xu Tan, et al.
- **LangChain:**
  
  - **API 참조:** [langchain_experimental.autonomous_agents](https://api.python.langchain.com/en/latest/experimental_api_reference.html#module-langchain_experimental.autonomous_agents)
  - **요리책:** [hugginggpt](https://github.com/langchain-ai/langchain/blob/master/cookbook/hugginggpt.ipynb)

**초록:** 다양한 도메인과 양식의 복잡한 AI 작업을 해결하는 것은 인공지능 일반 지능을 향한 중요한 단계입니다. 다양한 도메인과 양식에 사용할 수 있는 수많은 AI 모델이 있지만, 이들은 복잡한 AI 작업을 자율적으로 처리할 수 없습니다. 대형 언어 모델(LLM)이 언어 이해, 생성, 상호작용 및 추론에서 뛰어난 능력을 보여주었기 때문에, 우리는 LLM이 기존 AI 모델을 관리하여 복잡한 AI 작업을 해결하는 컨트롤러 역할을 할 수 있다고 주장합니다. 이 철학을 바탕으로, 우리는 LLM 기반 에이전트인 HuggingGPT를 소개하며, 이는 LLM(예: ChatGPT)을 활용하여 기계 학습 커뮤니티(예: Hugging Face)의 다양한 AI 모델을 연결하여 AI 작업을 해결합니다. 구체적으로, 우리는 사용자의 요청을 받을 때 ChatGPT를 사용하여 작업 계획을 수행하고, Hugging Face에서 제공되는 기능 설명에 따라 모델을 선택하며, 선택된 AI 모델로 각 하위 작업을 실행하고, 실행 결과에 따라 응답을 요약합니다. ChatGPT의 강력한 언어 능력과 Hugging Face의 풍부한 AI 모델을 활용하여, HuggingGPT는 다양한 양식과 도메인에 걸쳐 광범위한 복잡한 AI 작업을 처리하고 언어, 비전, 음성 및 기타 도전적인 작업에서 인상적인 결과를 달성하여 인공지능 일반 지능 실현을 위한 새로운 길을 열어줍니다.

## 대형 언어 모델을 위한 워터마크

- **arXiv id:** [2301.10226v4](http://arxiv.org/abs/2301.10226v4)  **발행일:** 2023-01-24
- **제목:** 대형 언어 모델을 위한 워터마크
- **저자:** John Kirchenbauer, Jonas Geiping, Yuxin Wen, et al.
- **LangChain:**
  
  - **API 참조:** [langchain_community...OCIModelDeploymentTGI](https://api.python.langchain.com/en/latest/llms/langchain_community.llms.oci_data_science_model_deployment_endpoint.OCIModelDeploymentTGI.html#langchain_community.llms.oci_data_science_model_deployment_endpoint.OCIModelDeploymentTGI), [langchain_huggingface...HuggingFaceEndpoint](https://api.python.langchain.com/en/latest/llms/langchain_huggingface.llms.huggingface_endpoint.HuggingFaceEndpoint.html#langchain_huggingface.llms.huggingface_endpoint.HuggingFaceEndpoint), [langchain_community...HuggingFaceEndpoint](https://api.python.langchain.com/en/latest/llms/langchain_community.llms.huggingface_endpoint.HuggingFaceEndpoint.html#langchain_community.llms.huggingface_endpoint.HuggingFaceEndpoint), [langchain_community...HuggingFaceTextGenInference](https://api.python.langchain.com/en/latest/llms/langchain_community.llms.huggingface_text_gen_inference.HuggingFaceTextGenInference.html#langchain_community.llms.huggingface_text_gen_inference.HuggingFaceTextGenInference)

**초록:** 대형 언어 모델의 잠재적 해악은 모델 출력을 워터마킹함으로써 완화될 수 있습니다. 즉, 생성된 텍스트에 인간에게는 보이지 않지만 짧은 토큰 범위에서 알고리즘적으로 감지할 수 있는 신호를 삽입하는 것입니다. 우리는 독점 언어 모델을 위한 워터마킹 프레임워크를 제안합니다. 이 워터마크는 텍스트 품질에 미치는 영향이 미미하게 삽입될 수 있으며, 언어 모델 API나 매개변수에 접근하지 않고도 효율적인 오픈 소스 알고리즘을 사용하여 감지할 수 있습니다. 워터마크는 단어가 생성되기 전에 무작위로 선택된 "녹색" 토큰 집합을 선택하고, 샘플링 중에 녹색 토큰의 사용을 부드럽게 촉진함으로써 작동합니다. 우리는 해석 가능한 p-값을 가진 워터마크 감지를 위한 통계적 검정을 제안하고, 워터마크의 민감성을 분석하기 위한 정보 이론적 프레임워크를 도출합니다. 우리는 Open Pretrained Transformer (OPT) 계열의 수십억 개 매개변수를 가진 모델을 사용하여 워터마크를 테스트하고, 견고성과 보안에 대해 논의합니다.

## 관련 레이블 없이 정확한 제로샷 밀집 검색

- **arXiv id:** [2212.10496v1](http://arxiv.org/abs/2212.10496v1)  **발행일:** 2022-12-20
- **제목:** 관련 레이블 없이 정확한 제로샷 밀집 검색
- **저자:** Luyu Gao, Xueguang Ma, Jimmy Lin, et al.
- **LangChain:**
  
  - **API 참조:** [langchain...HypotheticalDocumentEmbedder](https://api.python.langchain.com/en/latest/chains/langchain.chains.hyde.base.HypotheticalDocumentEmbedder.html#langchain.chains.hyde.base.HypotheticalDocumentEmbedder)
  - **템플릿:** [hyde](https://python.langchain.com/docs/templates/hyde)
  - **요리책:** [hypothetical_document_embeddings](https://github.com/langchain-ai/langchain/blob/master/cookbook/hypothetical_document_embeddings.ipynb)

**초록:** 밀집 검색은 작업과 언어 전반에 걸쳐 효과적이고 효율적인 것으로 입증되었지만, 관련 레이블이 없을 때 효과적인 완전 제로샷 밀집 검색 시스템을 만드는 것은 여전히 어렵습니다. 본 논문에서는 제로샷 학습과 관련성을 인코딩하는 어려움을 인식합니다. 대신, 우리는 가상의 문서 임베딩(HyDE)을 통해 전환할 것을 제안합니다. 쿼리가 주어지면, HyDE는 먼저 지침을 따르는 언어 모델(예: InstructGPT)을 제로샷으로 지시하여 가상의 문서를 생성합니다. 이 문서는 관련성 패턴을 포착하지만 비현실적이며 잘못된 세부정보를 포함할 수 있습니다. 그런 다음, 비지도 대조 학습 인코더(예: Contriever)가 문서를 임베딩 벡터로 인코딩합니다. 이 벡터는 유사한 실제 문서가 벡터 유사성에 따라 검색되는 코퍼스 임베딩 공간에서 이웃을 식별합니다. 이 두 번째 단계는 생성된 문서를 실제 코퍼스에 기반을 두게 하며, 인코더의 밀집 병목이 잘못된 세부정보를 필터링합니다. 우리의 실험은 HyDE가 최신 비지도 밀집 검색기인 Contriever를 상당히 능가하며, 다양한 작업(예: 웹 검색, QA, 사실 검증)과 언어(예: sw, ko, ja)에서 미세 조정된 검색기와 유사한 강력한 성능을 보여줍니다.

## 자연어 논증에서 논리적 오류의 강력하고 설명 가능한 식별

- **arXiv id:** [2212.07425v3](http://arxiv.org/abs/2212.07425v3)  **발행일:** 2022-12-12
- **제목:** 자연어 논증에서 논리적 오류의 강력하고 설명 가능한 식별
- **저자:** Zhivar Sourati, Vishnu Priya Prasanna Venkatesh, Darshan Deshpande, et al.
- **LangChain:**
  
  - **API 참조:** [langchain_experimental.fallacy_removal](https://api.python.langchain.com/en/latest/experimental_api_reference.html#module-langchain_experimental.fallacy_removal)

**초록:** 잘못된 정보, 선전 및 결함 있는 주장의 확산은 인터넷 시대에 더욱 확대되었습니다. 데이터의 양과 논증 규범 위반을 식별하는 미묘함을 고려할 때, 논리적 오류를 식별할 수 있는 신뢰할 수 있는 방법으로 콘텐츠 조정과 같은 정보 분석 작업을 지원하는 것이 필수적입니다. 본 논문에서는 논리적 오류에 대한 이전 이론적 작업을 탐지, 대략적 및 세밀한 분류의 포괄적인 3단계 평가 프레임워크로 형식화합니다. 우리는 평가의 각 단계에 대해 기존 평가 데이터 세트를 조정합니다. 우리는 프로토타입 추론, 인스턴스 기반 추론 및 지식 주입을 기반으로 한 세 가지 강력하고 설명 가능한 방법을 사용합니다. 이 방법들은 언어 모델과 배경 지식 및 설명 가능한 메커니즘을 결합합니다. 또한, 우리는 데이터 증대 및 커리큘럼 학습 전략으로 데이터 희소성 문제를 해결합니다. 우리의 3단계 프레임워크는 선전 탐지와 같은 기존 작업의 이전 데이터 세트와 방법을 본질적으로 통합하여 포괄적인 평가 테스트베드 역할을 합니다. 우리는 이러한 방법을 우리의 데이터 세트에서 광범위하게 평가하며, 그들의 견고성과 설명 가능성에 중점을 둡니다. 우리의 결과는 다양한 구성 요소 및 오류 클래스에 대한 방법의 강점과 약점에 대한 통찰력을 제공하며, 오류 식별이 다양한 클래스를 포착하기 위해 전문적인 형태의 추론을 요구할 수 있는 도전적인 작업임을 나타냅니다. 우리는 논리적 오류 식별에 대한 추가 작업을 지원하기 위해 GitHub에서 우리의 오픈 소스 코드와 데이터를 공유합니다.
## 효과적인 맥락 내 학습을 위한 보완 설명

- **arXiv id:** [2211.13892v2](http://arxiv.org/abs/2211.13892v2)  **발행일:** 2022-11-25
- **제목:** 효과적인 맥락 내 학습을 위한 보완 설명
- **저자:** Xi Ye, Srinivasan Iyer, Asli Celikyilmaz,  et al.
- **LangChain:**
  
  - **API 참조:** [langchain_core...MaxMarginalRelevanceExampleSelector](https://api.python.langchain.com/en/latest/example_selectors/langchain_core.example_selectors.semantic_similarity.MaxMarginalRelevanceExampleSelector.html#langchain_core.example_selectors.semantic_similarity.MaxMarginalRelevanceExampleSelector)

**초록:** 대형 언어 모델(LLM)은 프롬프트의 설명에서 학습하는 놀라운 능력을 보여주었지만, 이러한 설명이 정확히 어떻게 작동하는지 또는 왜 효과적인지에 대한 이해는 제한적이었다. 이 연구는 설명이 맥락 내 학습에 사용되는 메커니즘을 더 잘 이해하는 것을 목표로 한다. 우리는 먼저 설명이 포함된 프롬프트의 성능에 대한 두 가지 다른 요인의 영향을 연구한다: 계산 추적(해결 방법의 분해 방식)과 프롬프트를 표현하는 데 사용되는 자연어. 세 가지 통제된 작업에서 설명을 변형함으로써 두 요인이 모두 설명의 효과성에 기여함을 보여준다. 우리는 또한 주어진 테스트 쿼리를 해결하기 위해 최대한 효과적인 설명 집합을 형성하는 방법을 연구한다. 우리는 LLM이 설명 집합의 보완성으로부터 이익을 얻을 수 있음을 발견한다: 서로 다른 예시가 보여주는 다양한 추론 기술이 더 나은 성과로 이어질 수 있다. 따라서 우리는 관련성과 보완성을 모두 갖춘 예시 집합을 구성하기 위한 최대 한계 관련성 기반의 예시 선택 접근 방식을 제안하며, 이는 여러 LLM의 세 가지 실제 작업에서 맥락 내 학습 성능을 성공적으로 향상시킨다.

## PAL: 프로그램 지원 언어 모델

- **arXiv id:** [2211.10435v2](http://arxiv.org/abs/2211.10435v2)  **발행일:** 2022-11-18
- **제목:** PAL: 프로그램 지원 언어 모델
- **저자:** Luyu Gao, Aman Madaan, Shuyan Zhou,  et al.
- **LangChain:**
  
  - **API 참조:** [langchain_experimental.pal_chain](https://api.python.langchain.com/en/latest/experimental_api_reference.html#module-langchain_experimental.pal_chain), [langchain_experimental...PALChain](https://api.python.langchain.com/en/latest/pal_chain/langchain_experimental.pal_chain.base.PALChain.html#langchain_experimental.pal_chain.base.PALChain)
  - **요리책:** [program_aided_language_model](https://github.com/langchain-ai/langchain/blob/master/cookbook/program_aided_language_model.ipynb)

**초록:** 대형 언어 모델(LLM)은 최근에 몇 가지 예시를 제공받았을 때 산술 및 기호 추론 작업을 수행하는 인상적인 능력을 보여주었다("few-shot prompting"). 이러한 성공의 대부분은 문제 설명을 단계로 분해하여 이해하는 데 LLM을 사용하는 "사고의 연쇄"와 같은 프롬프트 방법에 기인할 수 있다. LLM은 이러한 단계별 분해에 능숙해 보이지만, 문제를 올바르게 분해하더라도 해결 부분에서 논리적 및 산술적 실수를 자주 범한다. 본 논문에서는 자연어 문제를 읽고 중간 추론 단계로 프로그램을 생성하는 LLM을 사용하는 새로운 접근 방식인 프로그램 지원 언어 모델(PAL)을 제시한다. PAL을 사용하면 자연어 문제를 실행 가능한 단계로 분해하는 것이 LLM의 유일한 학습 작업이 되며, 해결은 인터프리터와 같은 런타임에 위임된다. 우리는 BIG-Bench Hard 및 기타 벤치마크의 13개 수학적, 기호적 및 알고리즘적 추론 작업에서 신경 LLM과 기호 인터프리터 간의 시너지를 보여준다. 이러한 자연어 추론 작업에서 LLM을 사용하여 코드를 생성하고 Python 인터프리터를 사용하여 추론하는 것은 훨씬 더 큰 모델보다 더 정확한 결과를 가져온다. 예를 들어, Codex를 사용하는 PAL은 수학 단어 문제의 GSM8K 벤치마크에서 최첨단의 few-shot 정확도를 달성하며, 사고의 연쇄를 사용하는 PaLM-540B를 절대적으로 15% 상회한다. 우리의 코드와 데이터는 http://reasonwithpal.com/ 에서 공개적으로 이용 가능하다.

## ReAct: 언어 모델에서 추론과 행동의 시너지

- **arXiv id:** [2210.03629v3](http://arxiv.org/abs/2210.03629v3)  **발행일:** 2022-10-06
- **제목:** ReAct: 언어 모델에서 추론과 행동의 시너지
- **저자:** Shunyu Yao, Jeffrey Zhao, Dian Yu,  et al.
- **LangChain:**
  
  - **문서:** [docs/integrations/providers/cohere](https://python.langchain.com/docs/integrations/providers/cohere), [docs/integrations/tools/ionic_shopping](https://python.langchain.com/docs/integrations/tools/ionic_shopping)
  - **API 참조:** [langchain...TrajectoryEvalChain](https://api.python.langchain.com/en/latest/evaluation/langchain.evaluation.agents.trajectory_eval_chain.TrajectoryEvalChain.html#langchain.evaluation.agents.trajectory_eval_chain.TrajectoryEvalChain), [langchain...create_react_agent](https://api.python.langchain.com/en/latest/agents/langchain.agents.react.agent.create_react_agent.html#langchain.agents.react.agent.create_react_agent)

**초록:** 대형 언어 모델(LLM)은 언어 이해 및 상호작용 의사 결정 작업에서 인상적인 능력을 보여주었지만, 추론(예: 사고의 연쇄 프롬프트)과 행동(예: 행동 계획 생성)의 능력은 주로 별개의 주제로 연구되어 왔다. 본 논문에서는 LLM을 사용하여 추론 흔적과 작업별 행동을 교차적으로 생성하는 방법을 탐구하여 두 가지 간의 더 큰 시너지를 가능하게 한다: 추론 흔적은 모델이 행동 계획을 유도하고 추적하며 업데이트하는 데 도움을 주고 예외를 처리할 수 있게 하며, 행동은 외부 소스(예: 지식 기반 또는 환경)와 상호작용하여 추가 정보를 수집할 수 있게 한다. 우리는 ReAct라는 이름의 접근 방식을 다양한 언어 및 의사 결정 작업에 적용하고, 최첨단 기준에 대한 효과성을 입증하며, 추론 또는 행동 구성 요소가 없는 방법에 비해 인간의 해석 가능성과 신뢰성을 향상시킨다. 구체적으로, 질문 응답(HotpotQA) 및 사실 검증(Fever)에서 ReAct는 간단한 Wikipedia API와 상호작용하여 사고의 연쇄 추론에서 흔히 발생하는 환각 및 오류 전파 문제를 극복하고, 추론 흔적이 없는 기준보다 더 해석 가능한 인간과 유사한 작업 해결 경로를 생성한다. 두 개의 상호작용 의사 결정 벤치마크(ALFWorld 및 WebShop)에서 ReAct는 각각 절대 성공률 34% 및 10%로 모방 및 강화 학습 방법을 초과하며, 단 하나 또는 두 개의 맥락 내 예시로만 프롬프트된다. 코드가 포함된 프로젝트 사이트: https://react-lm.github.io

## Deep Lake: 딥 러닝을 위한 레이크하우스

- **arXiv id:** [2209.10785v2](http://arxiv.org/abs/2209.10785v2)  **발행일:** 2022-09-22
- **제목:** Deep Lake: 딥 러닝을 위한 레이크하우스
- **저자:** Sasun Hambardzumyan, Abhinav Tuli, Levon Ghukasyan,  et al.
- **LangChain:**
  
  - **문서:** [docs/integrations/providers/activeloop_deeplake](https://python.langchain.com/docs/integrations/providers/activeloop_deeplake)

**초록:** 전통적인 데이터 레이크는 SQL 쿼리를 실행하고, ACID 트랜잭션으로 데이터를 수집하며, 클라우드 저장소에서 페타바이트 규모의 데이터 세트를 시각화함으로써 분석 작업을 위한 중요한 데이터 인프라를 제공한다. 이들은 조직이 데이터 사일로를 해체하고, 데이터 기반 의사 결정을 가능하게 하며, 운영 효율성을 개선하고, 비용을 절감할 수 있도록 한다. 그러나 딥 러닝 사용이 증가함에 따라 전통적인 데이터 레이크는 자연어 처리(NLP), 오디오 처리, 컴퓨터 비전 및 비표 형 데이터 세트를 포함하는 응용 프로그램과 같은 애플리케이션에 잘 설계되어 있지 않다. 본 논문에서는 Activeloop에서 개발한 딥 러닝 응용 프로그램을 위한 오픈 소스 레이크하우스인 Deep Lake를 제시한다. Deep Lake는 일반 데이터 레이크의 이점을 유지하면서 한 가지 주요 차이점이 있다: 이미지, 비디오, 주석 및 표 형 데이터를 텐서 형태로 저장하고, 네트워크를 통해 (a) 텐서 쿼리 언어, (b) 브라우저 내 시각화 엔진 또는 (c) 딥 러닝 프레임워크로 데이터를 신속하게 스트리밍하면서 GPU 활용을 희생하지 않는다. Deep Lake에 저장된 데이터 세트는 PyTorch, TensorFlow, JAX에서 접근할 수 있으며, 수많은 MLOps 도구와 통합된다.

## 마트료시카 표현 학습

- **arXiv id:** [2205.13147v4](http://arxiv.org/abs/2205.13147v4)  **발행일:** 2022-05-26
- **제목:** 마트료시카 표현 학습
- **저자:** Aditya Kusupati, Gantavya Bhatt, Aniket Rege,  et al.
- **LangChain:**
  
  - **문서:** [docs/integrations/providers/snowflake](https://python.langchain.com/docs/integrations/providers/snowflake)

**초록:** 학습된 표현은 현대 ML 시스템의 중심 구성 요소로, 다양한 하위 작업을 수행한다. 이러한 표현을 훈련할 때, 각 하위 작업에 대한 계산 및 통계적 제약이 종종 알려져 있지 않다. 이 맥락에서 경직된 고정 용량 표현은 현재 작업에 대해 과도하거나 부족할 수 있다. 우리는 질문한다: 다양한 계산 자원으로 여러 하위 작업에 적응할 수 있는 유연한 표현을 설계할 수 있을까? 우리의 주요 기여는 다양한 세분화에서 정보를 인코딩하고 단일 임베딩이 하위 작업의 계산 제약에 적응할 수 있도록 하는 마트료시카 표현 학습(MRL)이다. MRL은 기존의 표현 학습 파이프라인을 최소한으로 수정하며, 추론 및 배포 중 추가 비용을 부과하지 않는다. MRL은 독립적으로 훈련된 저차원 표현만큼 정확하고 풍부한 조잡한 표현을 학습한다. 학습된 마트료시카 표현 내의 유연성은 다음을 제공한다: (a) 동일한 수준의 정확도로 ImageNet-1K 분류에 대해 최대 14배 작은 임베딩 크기; (b) ImageNet-1K 및 4K에서 대규모 검색에 대해 최대 14배의 실제 속도 향상; (c) 원래 표현만큼 강력하면서도 긴 꼬리의 few-shot 분류에 대해 최대 2%의 정확도 향상. 마지막으로, 우리는 MRL이 다양한 모달리티(비전(ViT, ResNet), 비전 + 언어(ALIGN) 및 언어(BERT) 전반에 걸쳐 웹 규모 데이터 세트(ImageNet, JFT)로 원활하게 확장됨을 보여준다. MRL 코드 및 사전 훈련된 모델은 https://github.com/RAIVNLab/MRL 에서 오픈 소스된다.

## 저자 리소스 언어를 위한 증류된 문장 표현을 사용한 비텍스트 마이닝

- **arXiv id:** [2205.12654v1](http://arxiv.org/abs/2205.12654v1)  **발행일:** 2022-05-25
- **제목:** 저자 리소스 언어를 위한 증류된 문장 표현을 사용한 비텍스트 마이닝
- **저자:** Kevin Heffernan, Onur Çelebi, Holger Schwenk
- **LangChain:**
  
  - **API 참조:** [langchain_community...LaserEmbeddings](https://api.python.langchain.com/en/latest/embeddings/langchain_community.embeddings.laser.LaserEmbeddings.html#langchain_community.embeddings.laser.LaserEmbeddings)

**초록:** 백분율로 가장 빈번한 언어를 넘어 다국어 표현 학습을 확장하는 것은 도전적이며, 특히 저자원 언어의 긴 꼬리를 다루는 데 어려움이 있다. 유망한 접근 방식은 교차 언어 전이를 수행할 수 있는 올-포-원 다국어 모델을 훈련하는 것이지만, 이러한 모델은 종종 용량이 부족하고 관련 없는 언어 간의 간섭을 겪는다. 대신, 우리는 이러한 접근 방식을 벗어나 여러 언어(가족) 특정 표현을 훈련하는 데 집중하지만, 모든 언어가 여전히 동일한 표현 공간에 인코딩될 수 있도록 한다. 이를 달성하기 위해 우리는 교사-학생 훈련에 집중하여 모든 인코더가 비텍스트 마이닝을 위해 상호 호환 가능하도록 하고, 새로운 언어의 빠른 학습을 가능하게 한다. 우리는 감독 및 자기 감독 훈련을 결합한 새로운 교사-학생 훈련 체계를 도입하여 인코더가 저자원 설정에서 귀중한 단일 언어 훈련 데이터를 활용할 수 있도록 한다. 우리의 접근 방식은 원래 LASER 인코더보다 상당히 뛰어난 성능을 보인다. 우리는 매우 저자원 언어를 연구하고 50개의 아프리카 언어를 처리하며, 이 중 많은 언어는 다른 모델에 의해 다루어지지 않는다. 이러한 언어에 대해 우리는 문장 인코더를 훈련하고 비텍스트를 채굴하며, NMT 시스템을 훈련하여 비텍스트를 검증한다.
## 대규모 언어 모델의 텍스트-투-SQL 기능 평가

- **arXiv id:** [2204.00498v1](http://arxiv.org/abs/2204.00498v1)  **발행일:** 2022-03-15
- **제목:** 대규모 언어 모델의 텍스트-투-SQL 기능 평가
- **저자:** Nitarshan Rajkumar, Raymond Li, Dzmitry Bahdanau
- **LangChain:**
  
  - **API 참조:** [langchain_community...SQLDatabase](https://api.python.langchain.com/en/latest/utilities/langchain_community.utilities.sql_database.SQLDatabase.html#langchain_community.utilities.sql_database.SQLDatabase), [langchain_community...SparkSQL](https://api.python.langchain.com/en/latest/utilities/langchain_community.utilities.spark_sql.SparkSQL.html#langchain_community.utilities.spark_sql.SparkSQL)

**초록:** 우리는 Codex 언어 모델의 텍스트-투-SQL 기능에 대한 경험적 평가를 수행합니다. 우리는 미세 조정 없이도 Codex가 Spider 벤치마크에서 강력한 기준선임을 발견했습니다. 또한 이 설정에서 Codex의 실패 모드를 분석합니다. 게다가 GeoQuery 및 Scholar 벤치마크에서 프롬프트에 제공된 소수의 도메인 내 예제가 Codex가 이러한 몇 가지 예제로 미세 조정된 최첨단 모델보다 더 나은 성능을 발휘할 수 있게 한다는 것을 보여줍니다.

## 지역 전형 샘플링

- **arXiv id:** [2202.00666v5](http://arxiv.org/abs/2202.00666v5)  **발행일:** 2022-02-01
- **제목:** 지역 전형 샘플링
- **저자:** Clara Meister, Tiago Pimentel, Gian Wiher,  et al.
- **LangChain:**
  
  - **API 참조:** [langchain_huggingface...HuggingFaceEndpoint](https://api.python.langchain.com/en/latest/llms/langchain_huggingface.llms.huggingface_endpoint.HuggingFaceEndpoint.html#langchain_huggingface.llms.huggingface_endpoint.HuggingFaceEndpoint), [langchain_community...HuggingFaceEndpoint](https://api.python.langchain.com/en/latest/llms/langchain_community.llms.huggingface_endpoint.HuggingFaceEndpoint.html#langchain_community.llms.huggingface_endpoint.HuggingFaceEndpoint), [langchain_community...HuggingFaceTextGenInference](https://api.python.langchain.com/en/latest/llms/langchain_community.llms.huggingface_text_gen_inference.HuggingFaceTextGenInference.html#langchain_community.llms.huggingface_text_gen_inference.HuggingFaceTextGenInference)

**초록:** 오늘날의 확률적 언어 생성기는 기본 모델이 표준 메트릭, 예를 들어 당혹감에서 잘 수행되지만 일관되고 유창한 텍스트를 생성하는 데 부족합니다. 이러한 불일치는 지난 몇 년 동안 언어 생성 커뮤니티를 혼란스럽게 했습니다. 이 작업에서는 자연어 생성을 이산 확률적 과정으로 추상화하는 것이 정보 이론적 분석을 가능하게 하여 확률적 언어 생성기의 행동에 대한 새로운 통찰력을 제공할 수 있다고 주장합니다. 예를 들어, 높은 확률의 텍스트가 왜 지루하거나 반복적일 수 있는지에 대한 것입니다. 인간은 정보를 전달하는 수단으로 언어를 사용하며, 이를 동시에 효율적이고 오류를 최소화하는 방식으로 수행하려고 합니다. 실제로 심리언어학 연구는 인간이 이 무의식적인 목표를 염두에 두고 문자열의 각 단어를 선택한다고 제안합니다. 우리는 이 기준을 충족하는 문자열 집합을 공식적으로 정의합니다: 각 단어가 예상 정보 내용에 가까운 정보 내용을 가지는 문자열입니다. 즉, 우리의 모델의 조건부 엔트로피입니다. 그런 다음 우리는 확률적 모델에서 생성할 때 이 기준을 적용하기 위한 간단하고 효율적인 절차를 제안합니다. 이를 지역 전형 샘플링이라고 부릅니다. 자동 및 인간 평가 결과, 지역 전형 샘플링은 핵 샘플링 및 top-k 샘플링에 비해 품질 측면에서 경쟁력 있는 성능을 제공하며, 일관되게 퇴화된 반복을 줄입니다.

## 자연어 감독으로부터 전이 가능한 시각 모델 학습

- **arXiv id:** [2103.00020v1](http://arxiv.org/abs/2103.00020v1)  **발행일:** 2021-02-26
- **제목:** 자연어 감독으로부터 전이 가능한 시각 모델 학습
- **저자:** Alec Radford, Jong Wook Kim, Chris Hallacy,  et al.
- **LangChain:**
  
  - **API 참조:** [langchain_experimental.open_clip](https://api.python.langchain.com/en/latest/experimental_api_reference.html#module-langchain_experimental.open_clip)

**초록:** 최첨단 컴퓨터 비전 시스템은 고정된 사전 결정된 객체 범주를 예측하도록 훈련됩니다. 이러한 제한된 형태의 감독은 다른 시각 개념을 지정하기 위해 추가로 레이블이 지정된 데이터가 필요하므로 일반성과 사용성을 제한합니다. 이미지에 대한 원시 텍스트로부터 직접 학습하는 것은 훨씬 더 넓은 감독 소스를 활용하는 유망한 대안입니다. 우리는 어떤 캡션이 어떤 이미지와 함께 가는지를 예측하는 간단한 사전 훈련 작업이 인터넷에서 수집된 4억 개의 (이미지, 텍스트) 쌍 데이터셋에서 SOTA 이미지 표현을 처음부터 학습하는 효율적이고 확장 가능한 방법임을 보여줍니다. 사전 훈련 후, 자연어를 사용하여 학습된 시각 개념을 참조하거나 새로운 개념을 설명할 수 있어 모델을 하위 작업에 제로샷으로 전이할 수 있습니다. 우리는 OCR, 비디오 내 동작 인식, 지리적 위치 파악 및 다양한 세부 객체 분류와 같은 작업을 포함하여 30개 이상의 기존 컴퓨터 비전 데이터셋에서 벤치마킹하여 이 접근 방식의 성능을 연구합니다. 이 모델은 대부분의 작업에 비트리비얼하게 전이되며, 종종 데이터셋 특정 훈련 없이 완전 감독 기준선과 경쟁력을 가집니다. 예를 들어, 우리는 원래 ResNet-50의 정확도를 ImageNet 제로샷에서 일치시킵니다. 우리는 훈련에 사용된 128만 개의 훈련 예제를 사용할 필요가 없습니다. 우리는 우리의 코드와 사전 훈련된 모델 가중치를 https://github.com/OpenAI/CLIP에서 공개합니다.

## CTRL: 제어 가능한 생성을 위한 조건부 변환기 언어 모델

- **arXiv id:** [1909.05858v2](http://arxiv.org/abs/1909.05858v2)  **발행일:** 2019-09-11
- **제목:** CTRL: 제어 가능한 생성을 위한 조건부 변환기 언어 모델
- **저자:** Nitish Shirish Keskar, Bryan McCann, Lav R. Varshney,  et al.
- **LangChain:**
  
  - **API 참조:** [langchain_huggingface...HuggingFaceEndpoint](https://api.python.langchain.com/en/latest/llms/langchain_huggingface.llms.huggingface_endpoint.HuggingFaceEndpoint.html#langchain_huggingface.llms.huggingface_endpoint.HuggingFaceEndpoint), [langchain_community...HuggingFaceEndpoint](https://api.python.langchain.com/en/latest/llms/langchain_community.llms.huggingface_endpoint.HuggingFaceEndpoint.html#langchain_community.llms.huggingface_endpoint.HuggingFaceEndpoint), [langchain_community...HuggingFaceTextGenInference](https://api.python.langchain.com/en/latest/llms/langchain_community.llms.huggingface_text_gen_inference.HuggingFaceTextGenInference.html#langchain_community.llms.huggingface_text_gen_inference.HuggingFaceTextGenInference)

**초록:** 대규모 언어 모델은 유망한 텍스트 생성 능력을 보여주지만, 사용자는 생성된 텍스트의 특정 측면을 쉽게 제어할 수 없습니다. 우리는 스타일, 내용 및 작업 특정 행동을 제어하는 제어 코드에 조건화되도록 훈련된 16억 개의 매개변수를 가진 조건부 변환기 언어 모델인 CTRL을 공개합니다. 제어 코드는 원시 텍스트와 자연스럽게 함께 발생하는 구조에서 파생되어 비지도 학습의 장점을 유지하면서 텍스트 생성에 대한 보다 명시적인 제어를 제공합니다. 이러한 코드는 또한 CTRL이 주어진 시퀀스에 대해 훈련 데이터의 어떤 부분이 가장 가능성이 높은지를 예측할 수 있게 합니다. 이는 모델 기반 소스 귀속을 통해 대량의 데이터를 분석하는 잠재적인 방법을 제공합니다. 우리는 https://github.com/salesforce/ctrl에서 CTRL의 여러 전체 크기 사전 훈련 버전을 공개했습니다.